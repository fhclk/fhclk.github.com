<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="拾荒者">
<meta property="og:url" content="http://fhclk.github.io/page/8/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="fhclk">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fhclk.github.io/page/8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/17/Swagger3%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/17/Swagger3%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">Swagger使用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-17 23:00:02" itemprop="dateCreated datePublished" datetime="2021-08-17T23:00:02+08:00">2021-08-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Swagger3-使用"><a href="#Swagger3-使用" class="headerlink" title="Swagger3 使用"></a>Swagger3 使用</h3><h4 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Swagger 是一个遵循了 OpenAPI 规范的一项技术，而 springfox 则是这项技术的具体实现。</p>
<h4 id="开启Swagger"><a href="#开启Swagger" class="headerlink" title="开启Swagger"></a>开启Swagger</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableOpenApi</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MallApplication</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        SpringApplication.run(MallApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="配置摘要信息"><a href="#配置摘要信息" class="headerlink" title="配置摘要信息"></a>配置摘要信息</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.builders.RequestHandlerSelectors;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.spi.DocumentationType;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.spring.web.plugins.Docket;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SwaggerConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Docket <span class="title function_">createRestApi</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Docket</span>(DocumentationType.OAS_30)</span><br><span class="line">                .apiInfo(apiInfo())</span><br><span class="line">                .select()</span><br><span class="line">                .apis(RequestHandlerSelectors.basePackage(<span class="string">&quot;com.macro.mall.controller&quot;</span>))</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> ApiInfo <span class="title function_">apiInfo</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ApiInfoBuilder</span>()</span><br><span class="line">                .title(<span class="string">&quot;SwaggerUI演示&quot;</span>)</span><br><span class="line">                .description(<span class="string">&quot;mall&quot;</span>)</span><br><span class="line">                .version(<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="访问Swagger"><a href="#访问Swagger" class="headerlink" title="访问Swagger"></a>访问Swagger</h4><p><a target="_blank" rel="noopener" href="http://localhost:8080/swagger-ui/">http://localhost:8080/swagger-ui/</a></p>
<h3 id="Swagger2使用"><a href="#Swagger2使用" class="headerlink" title="Swagger2使用"></a>Swagger2使用</h3><h4 id="添加依赖-1"><a href="#添加依赖-1" class="headerlink" title="添加依赖"></a>添加依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger-ui<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h4 id="开启Swagger-1"><a href="#开启Swagger-1" class="headerlink" title="开启Swagger"></a>开启Swagger</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableSwagger2</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MallTinyApplication</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        SpringApplication.run(MallTinyApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="配置摘要信息-1"><a href="#配置摘要信息-1" class="headerlink" title="配置摘要信息"></a>配置摘要信息</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.builders.ApiInfoBuilder;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.builders.RequestHandlerSelectors;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.service.ApiInfo;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.spi.DocumentationType;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.spring.web.plugins.Docket;</span><br><span class="line"><span class="keyword">import</span> springfox.documentation.swagger2.annotations.EnableSwagger2;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableSwagger2</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SwaggerConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Docket <span class="title function_">createRestApi</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Docket</span>(DocumentationType.SWAGGER_2)</span><br><span class="line">                .apiInfo(apiInfo())</span><br><span class="line">                .select()</span><br><span class="line">                .apis(RequestHandlerSelectors.basePackage(<span class="string">&quot;com.macro.mall&quot;</span>))</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ApiInfo <span class="title function_">apiInfo</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ApiInfoBuilder</span>()</span><br><span class="line">                .title(<span class="string">&quot;SwaggerUI演示&quot;</span>)</span><br><span class="line">                .description(<span class="string">&quot;mall&quot;</span>)</span><br><span class="line">                .version(<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="访问Swagger-1"><a href="#访问Swagger-1" class="headerlink" title="访问Swagger"></a>访问Swagger</h4><p><a target="_blank" rel="noopener" href="http://localhost:8080/swagger-ui.html">http://localhost:8080/swagger-ui.html</a></p>
<h3 id="生产环境"><a href="#生产环境" class="headerlink" title="生产环境"></a>生产环境</h3><p>生产环境中要关闭接口文档的显示</p>
<p>在application.properties或application.yml中设置</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">springfox:</span></span><br><span class="line">  <span class="attr">documentation:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span> <span class="comment">#在生产环境中要设置swagger-ui的enabled值为false,用来关闭文档的显示</span></span><br></pre></td></tr></table></figure>

<h3 id="Swagger注解的使用说明"><a href="#Swagger注解的使用说明" class="headerlink" title="Swagger注解的使用说明"></a>Swagger注解的使用说明</h3><h4 id="Api"><a href="#Api" class="headerlink" title="@Api"></a>@Api</h4><blockquote>
<p>@Api：用在请求的类上，表示对类的说明</p>
<p>​		tags &#x3D; “说明该类的作用”， 可以在UI界面上看到的注解“</p>
<p>​		value &#x3D; ”该参数没有什么意义，在UI上也可以看到，所以不需要配置“</p>
</blockquote>
<h4 id="ApiOperation"><a href="#ApiOperation" class="headerlink" title="@ApiOperation"></a>@ApiOperation</h4><blockquote>
<p>@ApiOperation：用在请求的方法上，说明方法用途、作用</p>
<p>​		value &#x3D; ”说明方法的用途、作用“</p>
<p>​		notes &#x3D; ”方法的备注说明“</p>
</blockquote>
<h4 id="ApiImplicitParams"><a href="#ApiImplicitParams" class="headerlink" title="@ApiImplicitParams"></a>@ApiImplicitParams</h4><blockquote>
<p>@ApiImplicitParams：用在请求方法上，表示一组参数说明</p>
<p>​		@ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面</p>
<p>​				name：参数名</p>
<p>​				value：参数的汉字说明、解释</p>
<p>​				required：参数是否必须传</p>
<p>​				paramType：参数放在哪个地方</p>
<p>​						header  &#x3D;&#x3D;&#x3D;&gt; 请求参数的获取： @RequestHeader</p>
<p>​						query    &#x3D;&#x3D;&#x3D;&gt; 请求参数的获取： @RequestParam</p>
<p>​						path（用于restful接口） &#x3D;&#x3D;&#x3D;&gt; 请求参数的获取：@PathVariable</p>
<p>​						div（不常用）</p>
<p>​						form（不常用）</p>
<p>​				dataType：参数类型，默认String，其他值Integer</p>
<p>​				defaultValue：参数的默认值</p>
</blockquote>
<h4 id="ApiResponses"><a href="#ApiResponses" class="headerlink" title="@ApiResponses"></a>@ApiResponses</h4><blockquote>
<p>@ApiResponses：用在请求方法上，表示一组响应</p>
<p>​		@ApiResponse：用在@ApiResponses中，一般表达一个错误的响应信息</p>
<p>​				code：数字，例如：400</p>
<p>​				message：信息</p>
<p>​				response：抛出的异常类</p>
</blockquote>
<h4 id="ApiModel"><a href="#ApiModel" class="headerlink" title="@ApiModel"></a>@ApiModel</h4><blockquote>
<p>@ApiModel：用于响应类上，表示一个返回相应数据的信息</p>
</blockquote>
<h4 id="ApiModelProperty"><a href="#ApiModelProperty" class="headerlink" title="@ApiModelProperty"></a>@ApiModelProperty</h4><blockquote>
<p>@ApiModelProperty：用在属性上，描述相应类的属性</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Api(tags = &quot;商品品牌管理&quot;)</span></span><br><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/brand&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PmsBrandController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> PmsBrandService pmsBrandService;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LoggerFactory.getLogger(PmsBrandController.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ApiOperation(value = &quot;获取所有商品列表&quot;)</span></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;listAll&quot;, method = RequestMethod.GET)</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="keyword">public</span> CommonResult&lt;List&lt;PmsBrand&gt;&gt; <span class="title function_">getBrandList</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> CommonResult.success(pmsBrandService.listAllBrand());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ApiOperation(&quot;添加品牌&quot;)</span></span><br><span class="line">    <span class="meta">@RequestMapping(value = &quot;/create&quot;, method = RequestMethod.POST)</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="keyword">public</span> CommonResult <span class="title function_">createBrand</span><span class="params">(<span class="meta">@RequestBody</span> PmsBrand pmsBrand)</span> &#123;</span><br><span class="line">        CommonResult commonResult;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> pmsBrandService.createBrand(pmsBrand);</span><br><span class="line">        <span class="keyword">if</span> (count == <span class="number">1</span>) &#123;</span><br><span class="line">            commonResult = CommonResult.success(pmsBrand);</span><br><span class="line">            LOGGER.debug(<span class="string">&quot;createbrand success: &#123;&#125;&quot;</span>, pmsBrand);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            commonResult = CommonResult.failed(<span class="string">&quot;操作失败&quot;</span>);</span><br><span class="line">            LOGGER.debug(<span class="string">&quot;createbrand failed: &#123;&#125;&quot;</span>, pmsBrand);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> commonResult;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ApiOperation(&quot;更新指定id的品牌信息&quot;)</span></span><br><span class="line">    <span class="meta">@PostMapping(value = &quot;/update/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="keyword">public</span> CommonResult <span class="title function_">updateBrand</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id, <span class="meta">@RequestBody</span> PmsBrand pmsBrandDto, BindingResult result)</span> &#123;</span><br><span class="line">        CommonResult commonResult;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> pmsBrandService.updateBrand(id, pmsBrandDto);</span><br><span class="line">        <span class="keyword">if</span> (count == <span class="number">1</span>) &#123;</span><br><span class="line">            commonResult = CommonResult.success(pmsBrandDto);</span><br><span class="line">            LOGGER.debug(<span class="string">&quot;updateBrand success: &#123;&#125;&quot;</span>, pmsBrandDto);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            commonResult = CommonResult.failed(<span class="string">&quot;操作失败&quot;</span>);</span><br><span class="line">            LOGGER.debug(<span class="string">&quot;updateBrand failed: &#123;&#125;&quot;</span>, pmsBrandDto);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> commonResult;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/15/Hadoop-Yarn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/15/Hadoop-Yarn/" class="post-title-link" itemprop="url">Hadoop-Yarn</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-15 09:07:01" itemprop="dateCreated datePublished" datetime="2021-08-15T09:07:01+08:00">2021-08-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="YARN概述"><a href="#YARN概述" class="headerlink" title="YARN概述"></a>YARN概述</h1><p>YARN （Yet Another Resource Negotiator，另一种资源协调者），是一个通用的资源管理系统和调度平台，可为上层应用提供统一的资源管理和调度。</p>
<h1 id="YARN架构、组件"><a href="#YARN架构、组件" class="headerlink" title="YARN架构、组件"></a>YARN架构、组件</h1><h2 id="YARN架构图"><a href="#YARN架构图" class="headerlink" title="YARN架构图"></a>YARN架构图</h2><img src="/2021/08/15/Hadoop-Yarn/image-20221213153344431.png" alt="image-20221213153344431" style="zoom:80%;">

<h2 id="YARN组件"><a href="#YARN组件" class="headerlink" title="YARN组件"></a>YARN组件</h2><p><strong>ResourceManager（RM）</strong></p>
<p>YARN集群中的主角色，决定系统中所有应用程序之间资源分配的最终权限，即最终仲裁者。接收用户的作业提交，并通过NM分配、管理各个机器上的计算资源。</p>
<p><strong>NodeManager（NM）</strong></p>
<p>YARN中的从角色，一台机器上一个，负责管理本机器上的计算资源。根据RM命令，启动Container容器、监视容器的资源使用情况。并且向RM主角色汇报资源使用情况。</p>
<p><strong>ApplicationMaster（AM）</strong></p>
<p>用户提交的每个应用程序均包含一个AM。负责程序内部各阶段的资源申请，监督程序的执行情况。</p>
<p><strong>Client</strong></p>
<p><strong>Container容器</strong></p>
<h1 id="程序提交YARN交互流程"><a href="#程序提交YARN交互流程" class="headerlink" title="程序提交YARN交互流程"></a>程序提交YARN交互流程</h1><h2 id="核心交互流程"><a href="#核心交互流程" class="headerlink" title="核心交互流程"></a>核心交互流程</h2><ul>
<li>MR作业提交  Client -&gt; RM</li>
<li>资源的申请  MrAppMaster -&gt; RM</li>
<li>MR作业状态汇报 Container （Map|Reduce Task） -&gt; Container (MrAppMaster)</li>
<li>节点的状态汇报 NM -&gt; RM</li>
</ul>
<h2 id="整体概述"><a href="#整体概述" class="headerlink" title="整体概述"></a>整体概述</h2><p>当用户向YARN中提交一个应用程序后，YARN将分成两个阶段运行该应用程序。</p>
<p>第一阶段：客户申请资源启动运行本次程序的ApplicationMaster。</p>
<p>第二阶段：ApplicationMaster根据本次程序内部具体情况，为它申请资源，并监控它的整个运行过程，直到运行完成。</p>
<p><img src="/2021/08/15/Hadoop-Yarn/image-20221213154706877.png" alt="image-20221213154706877"></p>
<h2 id="MR提交YARN交互流程"><a href="#MR提交YARN交互流程" class="headerlink" title="MR提交YARN交互流程"></a>MR提交YARN交互流程</h2><ol>
<li>用户通过客户端向YARN中ResourceManager提交应用程序。</li>
<li>ResourceManager为该应用程序分配第一个Container（容器），并与对应的NodeManager通信，要求它在这个Container中启动这个应用程序的ApplicationMaster。</li>
<li>ApplicationMaster启动成功后，首先向ResourceManager注册并保持通信，这样用户可以直接通过ResourceManager查看应用程序的运行状态。</li>
<li>AM为本次程序内部的各个Task任务向RM申请资源，并监控它的运行状态。</li>
<li>一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。</li>
<li>NodeManager为任务设置好运行环境后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</li>
<li>各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可以随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</li>
<li>应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</li>
</ol>
<h1 id="YARN资源调度器Scheduler"><a href="#YARN资源调度器Scheduler" class="headerlink" title="YARN资源调度器Scheduler"></a>YARN资源调度器Scheduler</h1><h2 id="YARN资源调度器Scheduler-1"><a href="#YARN资源调度器Scheduler-1" class="headerlink" title="YARN资源调度器Scheduler"></a>YARN资源调度器Scheduler</h2><p>YARN调度程序的工作是根据一些定义的策略为应用程序分配资源。<br>在YARN中，负责给应用程序分配资源的就是Scheduler，它是ResourceManager的核心组件之一。Scheduler完全专用于调度作业，它无法跟踪应用程序的状态。<br>一般而言，调度是一个难题，并且没有一个“最佳”策略，为此，YARN提供了多种调度器和可配置的策略供选择。</p>
<h2 id="调度器策略"><a href="#调度器策略" class="headerlink" title="调度器策略"></a>调度器策略</h2><h3 id="三种调度器"><a href="#三种调度器" class="headerlink" title="三种调度器"></a>三种调度器</h3><h4 id="FIFO-Scheduler（先进先出调度器）"><a href="#FIFO-Scheduler（先进先出调度器）" class="headerlink" title="FIFO Scheduler（先进先出调度器）"></a>FIFO Scheduler（先进先出调度器）</h4><p>先提交的应用先运行。调度工作不考虑优先级和范围，适用于负载较低的小规模集群<br>优点：无需配置、先到先得、易于执行<br>缺点：任务的优先级不会变高，因此优先级高的作业需要等待，不适合共享集群。很少使用</p>
<h4 id="Capacity-Scheduler（容量调度器）（YARN默认）"><a href="#Capacity-Scheduler（容量调度器）（YARN默认）" class="headerlink" title="Capacity Scheduler（容量调度器）（YARN默认）"></a>Capacity Scheduler（容量调度器）（YARN默认）</h4><p>允许多个组织共享整个集群资源，每个组织可以获得集群的一部分计算能力。通过为每个组织分配专门的队列，然后再为每个队列分配一定的集群资源，这样整个集群可以通过设置多个队列的方式给多个组织提供服务了。<br>Capacity可以理解成一个个的资源队列，这个资源队列是用户自己去分配的。队列内部又可以垂直划分，这样一个组织内部的多个成员就可以共享这个队列资源了，在一个队列内部，资源的调度是采用先进先出策略。<br>Capacity Scheduler调度器以队列为单位划分资源。简单通俗点来说，就是一个个队列有独立的资源，队列的结构和资源是可以进行配置的。<br><strong>特性优势</strong></p>
<ul>
<li>层次化的队列设计</li>
<li>容量保证</li>
<li>安全</li>
<li>弹性分配</li>
</ul>
<p>	</p>
<h4 id="Fair-Scheduler（公平调度器）"><a href="#Fair-Scheduler（公平调度器）" class="headerlink" title="Fair Scheduler（公平调度器）"></a>Fair Scheduler（公平调度器）</h4><p>提供了YARN应用程序公平的共享大型集群中资源的另一种方式。使所有应用在平均情况下随着时间的流逝可以获得相等的资源份额。<br>设计目标是为所有的应用分配公平的资源（对公平的定义通过参数来设置）。<br>公平调度可以在多个队列间工作，允许资源共享和抢占。<br><strong>特性优势</strong></p>
<ul>
<li>分层队列</li>
<li>基于用户或组的队列映射</li>
<li>资源抢占</li>
<li>保证最小配额</li>
<li>允许资源共享</li>
<li>默认不限制每个队列和用户可以同时运行应用的数量</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/14/Hadoop-MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/14/Hadoop-MapReduce/" class="post-title-link" itemprop="url">Hadoop-MapReduce</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-14 10:17:09" itemprop="dateCreated datePublished" datetime="2021-08-14T10:17:09+08:00">2021-08-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分布式计算分而治之思想"><a href="#分布式计算分而治之思想" class="headerlink" title="分布式计算分而治之思想"></a>分布式计算分而治之思想</h1><h2 id="分布式计算"><a href="#分布式计算" class="headerlink" title="分布式计算"></a>分布式计算</h2><p>分布式计算是一种计算方法，它将应用分解成许多小的部分，分配给多台计算机进行处理。从而节约整体计算时间，提高计算效率。</p>
<h2 id="MapReduce思想"><a href="#MapReduce思想" class="headerlink" title="MapReduce思想"></a>MapReduce思想</h2><p>MapReduce思想核心：<strong>先分再合，分而治之</strong>。即把一个复杂的问题，按照一定的“分解”方法分为等价的规模较小的若干部分，然后逐个解决，分别找出各部分的结果，然后把各部分的结果组成整个问题的最终结果。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213101954806.png" alt="image-20221213101954806"></p>
<ul>
<li>Map表示第一阶段，负责“拆分”：即把复杂的任务分解成若干个“简单的子任务”来处理。可以进行拆分的前提是这些小任务可以并行计算，彼此间几乎没有依赖关系。</li>
<li>Reduce表示第二阶段，负责“合并”：即对map阶段的结果进行全局汇总。</li>
<li>这两个阶段合起来就是MapReduce思想的体现。</li>
</ul>
<h2 id="大数据处理场景"><a href="#大数据处理场景" class="headerlink" title="大数据处理场景"></a>大数据处理场景</h2><p>采用MapReduce分而治之策略，首先Map阶段进行拆分，把大数据拆分成若个份小数据，多个程序同时并行计算产生中间结果；然后Reduce聚合阶段，通过程序对并行的结果进行最终的汇总计算，得出最终结果。</p>
<p><strong>不可拆分的计算任务或相互间有依赖关系的数据无法进行并行计算</strong></p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213102715695.png" alt="image-20221213102715695"></p>
<h2 id="构建抽象编程模型"><a href="#构建抽象编程模型" class="headerlink" title="构建抽象编程模型"></a>构建抽象编程模型</h2><ul>
<li><p>MapReduce借鉴了函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型。</p>
<p>map：对一组数据元素进行某种重复式的处理</p>
<p>reduce：对Map的中间结果进行某种进一步的结果处理</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213103050117.png" alt="image-20221213103050117"></p>
</li>
<li><p>MapReduce中定义了如下的Map和Reduce两个抽象的编程接口，由用户去编程实现：</p>
<p>map：（k1; v1) -&gt; (k2; v2)</p>
<p>reduce：(k2: [v2]) -&gt; (k3; v3)</p>
</li>
<li><p>通过以上两个编程接口，可以看出MapReduce处理的数据类型是&lt;key, value&gt;键值对。</p>
</li>
</ul>
<h2 id="统一架构，隐藏底层细节"><a href="#统一架构，隐藏底层细节" class="headerlink" title="统一架构，隐藏底层细节"></a>统一架构，隐藏底层细节</h2><p>MapReduce设计并统一了计算框架，隐藏了绝大多数系统层面的处理细节。</p>
<h1 id="MapReduce介绍"><a href="#MapReduce介绍" class="headerlink" title="MapReduce介绍"></a>MapReduce介绍</h1><p>Hadoop MapReduce是一个分布式计算框架，用于轻松编写分布式应用程序，这些应用程序以可靠，容错的方式并行处理大型硬件集群（多节点）上的大量数据（TB级别）。</p>
<p>MapReduce是一种面向海量数据处理的一种指导思想，也是一种用于大规模数据进行分布式计算的编程模型。</p>
<p><strong>MapReduce特点</strong></p>
<ul>
<li><p>易于编程</p>
<p>提供了用于二次开发的接口</p>
</li>
<li><p>良好的扩展</p>
<p>可以通过增加机器（计算节点）来扩展它的计算能力</p>
</li>
<li><p>高容错性</p>
<p>分布式搭建和部署，当某一个节点出现故障时，可以把上面的任务转移到另一个节点上运行，不影响整个任务。这个过程Hadoop内部完成</p>
</li>
<li><p>适合海量数据的离线处理</p>
<p>可以处理GB、TB、PB级别数据</p>
</li>
</ul>
<p><strong>MapReduce局限性</strong></p>
<ul>
<li>实时计算性能差</li>
<li>不能进行流式计算</li>
</ul>
<h1 id="MapReduce实例进程"><a href="#MapReduce实例进程" class="headerlink" title="MapReduce实例进程"></a>MapReduce实例进程</h1><p>一个完整的MapReduce程序在分布式运行时有三类</p>
<ul>
<li>MRAppMaster：负责整个MR程序的过程调度及状态协调</li>
<li>MapTask：负责map阶段的整个数据处理流程</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213110013345.png" alt="image-20221213110013345"></p>
<h1 id="MapReduce阶段组成"><a href="#MapReduce阶段组成" class="headerlink" title="MapReduce阶段组成"></a>MapReduce阶段组成</h1><ul>
<li>一个MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，或者只有Map阶段。</li>
<li>不能有很多个Map阶段、多个Reduce阶段的情形。</li>
<li>如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序串行运行。</li>
</ul>
<img src="/2021/08/14/Hadoop-MapReduce/image-20221213111404853.png" alt="image-20221213111404853" style="zoom: 80%;">



<h1 id="MapReduce数据类型"><a href="#MapReduce数据类型" class="headerlink" title="MapReduce数据类型"></a>MapReduce数据类型</h1><p>整个MapReduce程序中，数据都是以KV兼职对的形式流转的。</p>
<p>在实际编程解决各种业务问题中，需要考虑每个阶段的输入输出kv分别是什么。</p>
<p>MapReduce中内置了很多默认属性，比如排序、分组等，都和数据的k有关。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213113122471.png" alt="image-20221213113122471"></p>
<h1 id="MapReduce执行流程"><a href="#MapReduce执行流程" class="headerlink" title="MapReduce执行流程"></a>MapReduce执行流程</h1><h2 id="MapReduce整体执行流程图"><a href="#MapReduce整体执行流程图" class="headerlink" title="MapReduce整体执行流程图"></a>MapReduce整体执行流程图</h2><p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213142024380.png" alt="image-20221213142024380"></p>
<h2 id="Map阶段执行流程"><a href="#Map阶段执行流程" class="headerlink" title="Map阶段执行流程"></a>Map阶段执行流程</h2><ul>
<li>第一阶段：把输入目录下文件按照一定的标准逐个进行逻辑切片，形成切片规划。默认Split size &#x3D; Block size （128M），每一个切片由一个MapTask处理。（getSplits）</li>
<li>第二阶段：对切片中的数据按照一定的规则读取解析返回&lt;key, value&gt;对。默认是按行读取数据。key是每一行的起始位置偏移量，value是本行的文本内容。（TextInutFormat）</li>
<li>第三阶段：调用Mapper类中的map方法处理数据。每读取解析出来的一个&lt;key, value&gt;，调用一次map方法。</li>
<li>第四阶段：按照一定的规则对map输出的键值对进行分区partition。默认不分区，因为只有一个reducetask。分区的数量就是reducetask运行的数量。</li>
<li>第五阶段：Map输出数据写入内存缓冲区，达到比例溢出到磁盘上。溢出spill的时候根据key进行排序sort。默认根据key字典排序。</li>
<li>第六阶段：对所有溢出文件进行最终的merge合并，成为一个文件。</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213142808652.png" alt="image-20221213142808652"></p>
<h2 id="Reduce阶段执行流程"><a href="#Reduce阶段执行流程" class="headerlink" title="Reduce阶段执行流程"></a>Reduce阶段执行流程</h2><ul>
<li>第一阶段：ReduceTask会主动从MapTask复制拉取属于需要自己处理的数据。</li>
<li>第二阶段：把拉取来的数据，全部进行merge合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</li>
<li>第三阶段：对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法。最后把这些输出的键值对写入到HDFS文件中。</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213143229439.png" alt="image-20221213143229439"></p>
<h2 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h2><h3 id="shuffle概念"><a href="#shuffle概念" class="headerlink" title="shuffle概念"></a>shuffle概念</h3><p>Shuffle的本意是洗牌、混洗的意思，把一组有规则地数据尽量打乱成无规则地数据。</p>
<p>在MapReduce中，Shuffle更像是洗牌的逆过程，指的是将map端的无规则输出按指定的规则“打乱”成具有一定规则的数据，以便reduce端接收处理。</p>
<p>一般把从Map产生输出开始到Reduce取得数据作为输入之前的过程称之为shuffle。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213144448734.png" alt="image-20221213144448734"></p>
<h3 id="Map端Shuffle"><a href="#Map端Shuffle" class="headerlink" title="Map端Shuffle"></a>Map端Shuffle</h3><p>Collect阶段：将MapTask的结果收集输出到默认大小为100M的环形缓冲区，保存之前会对key进行分区的计算，默认Hash分区。</p>
<p>Spill阶段：当内存的数据达到一定的阈值的时候，就会将数据写入磁盘，在将数据写入磁盘之前需要对数据进行一次排序的操作，如果配置了combiner，还会将有相同分区号和key的数据进行排序。</p>
<p>Merge阶段：把所有溢出的文件进行一次合并操作，以确保一个MapTask最终只产生一个中间数据文件。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213144901309.png" alt="image-20221213144901309"></p>
<h3 id="Reduce端Shuffle"><a href="#Reduce端Shuffle" class="headerlink" title="Reduce端Shuffle"></a>Reduce端Shuffle</h3><p>Copy阶段：ReduceTask启动Fetcher线程到已经完成MapTask的节点上复制一份属于自己的数据。</p>
<p>Merge阶段：在ReduceTask远程复制数据的同时，会在后台开启两个线程对内存到本地的数据文件进行合并操作。</p>
<p>Sort阶段：在对数据进行合并的同时，会进行排序操作，由于MapTask阶段已经对数据进行了局部的排序，ReduceTask只需保证Copy的数据的最终整体有效性即可。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213145258144.png" alt="image-20221213145258144"></p>
<h3 id="shuffle机制弊病"><a href="#shuffle机制弊病" class="headerlink" title="shuffle机制弊病"></a>shuffle机制弊病</h3><p>Shuffle是MapReduce成的核心与精髓，是MapReduce的灵魂所在。</p>
<p>Shuffle也是MapReduce被诟病最多的地方。MapReduce相比较于Spark、Flink计算引擎慢的原因，根Shuffle机制有很大的关系。Shuffle频繁涉及到数据在内存、磁盘之间的多次往复。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/13/Hadoop-HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/13/Hadoop-HDFS/" class="post-title-link" itemprop="url">Hadoop-HDFS</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-13 10:07:09" itemprop="dateCreated datePublished" datetime="2021-08-13T10:07:09+08:00">2021-08-13</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>数据</strong>：指存储的内容本身，比如文件、视频、图片等，这些数据底层最终是存储在磁盘等存储介质上的，一般用户无需关心，只需要基于目录树进行增删改查即可，实际针对数据的操作有文件系统完成。</p>
<p><strong>元数据</strong>：</p>
<p>元数据（metadata）又称之为解释性数据，记录数据的数据。</p>
<p>文件系统元数据一般指文件大小、最后修改时间、底层存储位置、属性、所属用户、权限等信息。</p>
<h2 id="分布式存储系统核心属性"><a href="#分布式存储系统核心属性" class="headerlink" title="分布式存储系统核心属性"></a>分布式存储系统核心属性</h2><ul>
<li><p>分布式存储</p>
<p>问题：数据量大，单机存储遇到瓶颈。</p>
<p>解决：</p>
<p>单机纵向扩展：增加磁盘</p>
<p>多机横向扩展：增加机器</p>
</li>
<li><p>元数据记录</p>
<p>问题：文件分布在不同机器上不利于查找</p>
<p>解决：</p>
<p>元数据记录下文件及其存储位置信息（文件名、大小、存储机器IP），快速定位文件位置</p>
</li>
<li><p>分块机制</p>
<p>问题：文件过大导致单机存不下、上传下载效率低</p>
<p>解决：文件分块存储在不同的机器，针对块并行操作提高效率</p>
</li>
<li><p>副本机制</p>
<p>问题：硬件出现故障，输入容易丢失</p>
<p>解决：不同机器设置备份，冗余存储，保障数据安全</p>
</li>
</ul>
<h1 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h1><p>HDFS（Hadoop Distributed File System），Hadoop分布式文件系统，其主要是解决大数据如何存储问题，适于存储大型数据（TB和PB），它使用多台计算机存储文件，并且提供统一的访问接口，像访问一个普通文件系统一样使用分布式文件系统。</p>
<h2 id="HDFS应用场景"><a href="#HDFS应用场景" class="headerlink" title="HDFS应用场景"></a>HDFS应用场景</h2><p>适合场景：</p>
<p>大文件、数据流式访问、一次写入多次读取、低成本部署（廉价PC）、高容错</p>
<p>不适合场景：</p>
<p>小文件、数据交互式访问、频繁任意修改、低延迟处理</p>
<h2 id="HDFS重要特性"><a href="#HDFS重要特性" class="headerlink" title="HDFS重要特性"></a>HDFS重要特性</h2><ul>
<li>主从架构</li>
<li>分块存储</li>
<li>副本机制</li>
<li>元数据记录</li>
<li>抽象统一的目录树结构（namespace）</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212155509725.png" alt="image-20221212155509725"></p>
<h3 id="主从架构"><a href="#主从架构" class="headerlink" title="主从架构"></a>主从架构</h3><ul>
<li>HDFS集群是标准的master&#x2F;slave主从架构集群</li>
<li>一般一个HDFS集群是有一个Namenode和一定数目的Datanode组成</li>
<li>Namenode是HDFS主节点，Datanode是HDFS从节点，两种角色各司其职，共同协调完成分布式的文件存储服务</li>
</ul>
<h3 id="分块存储"><a href="#分块存储" class="headerlink" title="分块存储"></a>分块存储</h3><ul>
<li>HDFS中的文件在物理上是分块存储（block）的，默认大小是128M，不足128M则本身就是一块。</li>
<li>块的大小可以通过配置参数来规定，参数位于hdfs-default.xml中： dfs.blocksize</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212160026689.png" alt="image-20221212160026689"></p>
<h3 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h3><ul>
<li>文件的所有block都会有副本。副本系数可以在文件创建的时候指定，也可以在之后通过命令改变</li>
<li>副本数由参数dfs.replication控制，默认是3，也就是会额外再复制2份，连同本身供3份</li>
</ul>
<h3 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h3><p>HDFS中，Namenode管理的元数据有两种类型：</p>
<p><strong>文件自身属性信息</strong></p>
<p>文件名称、权限、修改时间、文件大小、复制因子、数据块大小</p>
<p><strong>文件块位置映射信息</strong></p>
<p>记录文件块和DataNode之间的映射信息，即那块位于哪个节点上。</p>
<h3 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h3><p>HDFS支持传统的层次型文件组织结构。用户可以创建目录，然后将文件保存在这些目录里，文件系统名字空间的层次结构和大多数现有的文件系统类似，用户可以创建、修改、移动或重命名文件。</p>
<p>Namenode负责维护文件系统的namespace名称空间，任何文件系统名称空间或属性的修改都将被Namenode记录下来。</p>
<p>HDFS会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs:&#x2F;&#x2F;namenode:port&#x2F;dir&#x2F;file.data</p>
<h3 id="数据块存储"><a href="#数据块存储" class="headerlink" title="数据块存储"></a>数据块存储</h3><p>文件的各个block的具体存储管理由Datanode节点承担。</p>
<p>每一个block都可以在多个Datanode上存储。</p>
<h1 id="HDFS-shell"><a href="#HDFS-shell" class="headerlink" title="HDFS shell"></a>HDFS shell</h1><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs [generic options]</span><br></pre></td></tr></table></figure>



<h2 id="文件系统协议"><a href="#文件系统协议" class="headerlink" title="文件系统协议"></a>文件系统协议</h2><p>本地文件系统： file:&#x2F;&#x2F;&#x2F;</p>
<p>分布式文件系统： hdfs:&#x2F;&#x2F;&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls file:/// #操作本地文件系统</span><br><span class="line">hadoop fs -ls hdfs:///node1:8020/  #操作HDFS分布式文件系统</span><br><span class="line">hadoop hs -ls / #直接根目录，没有指定协议，将加载fs.defaultFS值</span><br></pre></td></tr></table></figure>



<p>hdfs dfs 只能操作HDFS文件系统相关（包括Local FS间的操作），常用。</p>
<p>hadoop fs可操作任意文件系统，不仅仅是hdfs文件系统，适用范围更广。</p>
<h1 id="HDFS工作流程与机制"><a href="#HDFS工作流程与机制" class="headerlink" title="HDFS工作流程与机制"></a>HDFS工作流程与机制</h1><h2 id="HDFS集群角色与职责"><a href="#HDFS集群角色与职责" class="headerlink" title="HDFS集群角色与职责"></a>HDFS集群角色与职责</h2><h3 id="主角色：namenode"><a href="#主角色：namenode" class="headerlink" title="主角色：namenode"></a>主角色：namenode</h3><p>NameNode是Hadoop分布式文件系统的核心，架构中的主角色。</p>
<p>NameNode维护和管理文件系统元数据，包括名称空间目录树结构、文件和块的位置信息、访问权限等信息。</p>
<p>NameNode成为了访问HDFS的唯一入口。</p>
<p>NameNode内部通过内存和磁盘文件两种方式管理元数据。</p>
<p>其中磁盘上的元数据文件包括Fsimage内存元数据镜像文件和edits log（Journal）编辑日志。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212162816232.png" alt="image-20221212162816232"></p>
<h3 id="从角色：datanode"><a href="#从角色：datanode" class="headerlink" title="从角色：datanode"></a>从角色：datanode</h3><p>DataNode具体负责数据块存储。</p>
<p>DataNode的数量决定了HDFS集群的整体数据存储能力。通过和NameNode配合维护着数据块。</p>
<h3 id="主角色辅助角色：secondarynamenode"><a href="#主角色辅助角色：secondarynamenode" class="headerlink" title="主角色辅助角色：secondarynamenode"></a>主角色辅助角色：secondarynamenode</h3><p>SecondaryNameNode充当NameNode的辅助节点，但不能替代NameNode。</p>
<p>主要是帮助主角色进行元数据文件的合并动作。</p>
<h3 id="namenode职责"><a href="#namenode职责" class="headerlink" title="namenode职责"></a>namenode职责</h3><p>NameNode仅存储HDFS的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</p>
<p>NameNode知道HDFS中任何给定文件的快列表及其位置。使用此信息NameNode知道如何从块中构建文件。</p>
<p>NameNode不持久化存储每个文件中各个块所在的datanode的位置信息，这些信息会在系统启动时从DataNode重建。</p>
<p>NameNode是Hadoop集群中的单点故障。</p>
<p>NameNode所在机器通常会配置有大量内存（RAM）</p>
<h3 id="datanode职责"><a href="#datanode职责" class="headerlink" title="datanode职责"></a>datanode职责</h3><p>DataNode负责最终数据块block的存储。是集群的从角色，也称为Slave。</p>
<p>DataNode启动时，会将自己注册到NameNode并汇报自己负责持有的块列表。</p>
<p>当某个DataNode关闭时，不会影响数据的可用性。NameNode将安排由其他DataNode管理的块进行副本复制。</p>
<p>DataNode所在机器通常配置有大量的硬盘空间，因为实际数据存储在DataNode中。</p>
<h2 id="HDFS写数据流程（上传文件）"><a href="#HDFS写数据流程（上传文件）" class="headerlink" title="HDFS写数据流程（上传文件）"></a>HDFS写数据流程（上传文件）</h2><h3 id="Pipeline管道"><a href="#Pipeline管道" class="headerlink" title="Pipeline管道"></a>Pipeline管道</h3><p>Pipeline是HDFS在上传文件写数据过程中采用的一种数据传输方式。</p>
<p>客户端将数据写入第一个数据节点，第一个数据节点保存数据之后再将块复制到第二个数据节点，后者保存后将其复制到第三个数据节点。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212230023760.png" alt="image-20221212230023760"></p>
<p>数据以管道的方式，顺序的沿着一个方向传输，这样能够充分利用每个机器的带宽，避免网络瓶颈和高延迟时的连接，最小化推送所有数据的延时。</p>
<p>在线性推送模式下，每台机器所有的出口带宽都用于以最快的速度传输数据，而不是在多个接受者之间分配带宽。</p>
<h3 id="ACK应答响应"><a href="#ACK应答响应" class="headerlink" title="ACK应答响应"></a>ACK应答响应</h3><p>ACK（Acknowledge character）即是确认字符，在数据通信中，接收方发送给发送方的一种传输类控制字符。表示发来的数据已确认接收无误。</p>
<p>在HDFS pipeline管道传输数据的过程中，传输的反方向会进行ACK校验，确保数据传输安全。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212230559137.png" alt="image-20221212230559137"></p>
<h3 id="默认3副本存储策略"><a href="#默认3副本存储策略" class="headerlink" title="默认3副本存储策略"></a>默认3副本存储策略</h3><p>默认副本存储策略是由BlockPlacementPolicyDefault指定。</p>
<ul>
<li>第一块副本：优先客户端本地，否则随机</li>
<li>第二块副本：不同于第一块副本的不同机架</li>
<li>第三块副本：第二块副本相同机架不通过机器</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212232028347.png" alt="image-20221212232028347"></p>
<h3 id="写数据完整流程图"><a href="#写数据完整流程图" class="headerlink" title="写数据完整流程图"></a>写数据完整流程图</h3><p><img src="/2021/08/13/Hadoop-HDFS/image-20221212225725826.png" alt="image-20221212225725826"></p>
<h3 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h3><ol>
<li>HDFS客户端创建对象实例DistributedFileSystem，该对象中封装了与HDFS文件系统操作相关的方法。</li>
<li>调用DistributedFileSystem对象的create()方法，通过RPC请求NameNode创建文件。NameNode执行各种检查判断：目标文件是否存在、父目录是否存在、客户端是否具有创建该文件的权限。检查通过，NameNode就会为本次请求记下一条记录，返回FSDataOutputStream输出流对象给客户端用于写数据。</li>
<li>客户端通过FSDataOutputStream输出流开始写入数据。</li>
<li>客户端写入数据时，将数据分成一个个数据包（packet默认64K），内部组件DataStreamer请求NameNode挑选出适合存储数据副本的一组DataNode地址，默认是3副本存储。DataStreamer将数据包流式传输到pipeline的第一个DataNode，该DataNode存储数据包并将它们发送到pipeline的第二个DataNode。同样，第二个DataNode存储数据包并且发送给第三个DataNode。</li>
<li>传输的反方向上，会通过ACK机制校验数据包传输是否成功。</li>
<li>客户端完成数据写入后，在FSDataOutputStream输出流上调用close()方法关闭。</li>
<li>DistributedFileSystem联系NameNode告知其文件写入完成，等待NameNode确认。因为NameNode已经知道文件是由哪些块组成（DataStream请求分配数据块），因此仅需等待最小复制块即可成功返回。最小复制是由参数dfs.namenode.replication.min指定，默认是1。</li>
</ol>
<h2 id="HDFS读数据流程（下载文件）"><a href="#HDFS读数据流程（下载文件）" class="headerlink" title="HDFS读数据流程（下载文件）"></a>HDFS读数据流程（下载文件）</h2><h3 id="读数据完整流程图"><a href="#读数据完整流程图" class="headerlink" title="读数据完整流程图"></a>读数据完整流程图</h3><p><img src="/2021/08/13/Hadoop-HDFS/image-20221213094517559.png" alt="image-20221213094517559"></p>
<h3 id="读数据流程"><a href="#读数据流程" class="headerlink" title="读数据流程"></a>读数据流程</h3><ol>
<li>HDFS客户端创建对象实例DistributedFileSystem，调用该对象的open()方法来打开希望读取的文件。</li>
<li>DistributedFileSystem使用RPC调用namenode来确定文件中前几块的块位置（分批次读取）信息。对于每个块，namenode返回具体有该模块所有副本的datanode位置地址列表，并且该地址列表是排序好的，与客户端的网络拓扑距离近的排序靠前。</li>
<li>DistributedFileSystem将FSDataInputStream输入流返回到客户端以供其读取数据。</li>
<li>客户端在FSDataInputStream输入流上调用read()方法。然后，已存储DataNode地址的InputStream连接到文件中第一个块的最近的DataNode。数据从DataNode流回客户端，结果客户端可以在流上重复调用read()。</li>
<li>当该块结束时，FSDataInputStream将关闭与DataNode的连接，然后寻找下一个block块的最佳datanode位置。这些操作对用户来说是透明的。所以用户感觉起来它一直在读取一个连续的流。客户端从流中读取数据时，也会根据需要询问NameNode来检索下一批数据块的DataNode位置信息。</li>
<li>一旦客户端完成读取，就对FSDataInputStream调用close()方法。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/12/Hadoop-%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/12/Hadoop-%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">Hadoop-部署</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-12 11:13:02" itemprop="dateCreated datePublished" datetime="2021-08-12T11:13:02+08:00">2021-08-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>操作系统：Centos 7.7</p>
<p>安装目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /export/server</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Hadoop集群分布式安装"><a href="#Hadoop集群分布式安装" class="headerlink" title="Hadoop集群分布式安装"></a>Hadoop集群分布式安装</h1><h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><table>
<thead>
<tr>
<th>主机</th>
<th>角色</th>
</tr>
</thead>
<tbody><tr>
<td>node1</td>
<td>NN    DN   RM  NM</td>
</tr>
<tr>
<td>node2</td>
<td>SNN  DN           NM</td>
</tr>
<tr>
<td>node3</td>
<td>DN          NM</td>
</tr>
</tbody></table>
<h2 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h2><blockquote>
<p>3台机器都需要操作</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主机名</span> </span><br><span class="line">cat /etc/hostname</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hosts映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.88.151 node1.itcast.cn node1</span><br><span class="line">192.168.88.152 node2.itcast.cn node2</span><br><span class="line">192.168.88.153 node3.itcast.cn node3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JDK 1.8安装  上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下</span></span><br><span class="line">cd /export/server/</span><br><span class="line">tar zxvf jdk-8u241-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">	</span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="meta prompt_">	</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新加载环境变量文件</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">集群时间同步</span></span><br><span class="line">ntpdate ntp5.aliyun.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">防火墙关闭</span></span><br><span class="line">firewall-cmd --state	#查看防火墙状态</span><br><span class="line">systemctl stop firewalld.service  #停止firewalld服务</span><br><span class="line">systemctl disable firewalld.service  #开机禁用firewalld服务</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh免密登录（只需要配置node1至node1、node2、node3即可）</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">node1生成公钥私钥 (一路回车)</span></span><br><span class="line">ssh-keygen  </span><br><span class="line"><span class="meta prompt_">	</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">node1配置免密登录到node1 node2 node3</span></span><br><span class="line">ssh-copy-id node1</span><br><span class="line">ssh-copy-id node2</span><br><span class="line">ssh-copy-id node3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><p>上传Hadoop安装包到node1 &#x2F;export&#x2F;server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br></pre></td></tr></table></figure>



<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>修改配置文件(配置文件路径 hadoop-3.3.0&#x2F;etc&#x2F;hadoop)</p>
<ul>
<li><p>hadoop-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件最后添加</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line"></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root </span><br></pre></td></tr></table></figure>
</li>
<li><p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置Hadoop本地保存数据路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/data/hadoop-3.3.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS web UI用户身份 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 整合hive 用户代理设置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 文件系统垃圾桶保存时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node2:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施物理内存限制 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn历史服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node1:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史日志保存的时间 7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>workers</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node1.itcast.cn</span><br><span class="line">node2.itcast.cn</span><br><span class="line">node3.itcast.cn</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="同步到node2和node3节点"><a href="#同步到node2和node3节点" class="headerlink" title="同步到node2和node3节点"></a>同步到node2和node3节点</h2><p>分发同步hadoop安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server</span><br><span class="line"></span><br><span class="line">scp -r hadoop-3.3.0 root@node2:$PWD</span><br><span class="line">scp -r hadoop-3.3.0 root@node3:$PWD</span><br></pre></td></tr></table></figure>



<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>将hadoop添加到环境变量（3台机器）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop-3.3.0</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">别忘了scp给其他两台机器哦</span></span><br></pre></td></tr></table></figure>



<h2 id="Hadoop集群启动"><a href="#Hadoop集群启动" class="headerlink" title="Hadoop集群启动"></a>Hadoop集群启动</h2><ul>
<li><p>（&#x3D;&#x3D;首次启动&#x3D;&#x3D;）格式化namenode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>脚本一键启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# start-dfs.sh </span><br><span class="line">Starting namenodes on [node1]</span><br><span class="line">Last login: Thu Nov  5 10:44:10 CST 2020 on pts/0</span><br><span class="line">Starting datanodes</span><br><span class="line">Last login: Thu Nov  5 10:45:02 CST 2020 on pts/0</span><br><span class="line">Starting secondary namenodes [node2]</span><br><span class="line">Last login: Thu Nov  5 10:45:04 CST 2020 on pts/0</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Last login: Thu Nov  5 10:45:08 CST 2020 on pts/0</span><br><span class="line">Starting nodemanagers</span><br><span class="line">Last login: Thu Nov  5 10:45:44 CST 2020 on pts/0</span><br></pre></td></tr></table></figure>
</li>
<li><p>Web  UI页面</p>
<ul>
<li>HDFS集群：<a target="_blank" rel="noopener" href="http://node1:9870/">http://node1:9870/</a></li>
<li>YARN集群：<a target="_blank" rel="noopener" href="http://node1:8088/">http://node1:8088/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>运行hadoop3官方自带mr示例出错。</p>
<ul>
<li><p>错误信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</span><br><span class="line"></span><br><span class="line">Please check whether your etc/hadoop/mapred-site.xml contains the below configuration:</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>解决  mapred-site.xml,增加以下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h1 id="Hadoop编译安装（了解）"><a href="#Hadoop编译安装（了解）" class="headerlink" title="Hadoop编译安装（了解）"></a>Hadoop编译安装（了解）</h1><ul>
<li><p>安装编译相关的依赖</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc gcc-c++ make autoconf automake libtool curl lzo-devel zlib-devel openssl openssl-devel ncurses-devel snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop libXtst zlib -y</span><br><span class="line"></span><br><span class="line">yum install -y doxygen cyrus-sasl* saslwrapper-devel*</span><br></pre></td></tr></table></figure>
</li>
<li><p>手动安装cmake </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">yum卸载已安装cmake 版本低</span></span><br><span class="line">yum erase cmake</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar zxvf CMake-3.19.4.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/CMake-3.19.4</span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证</span></span><br><span class="line">[root@node4 ~]# cmake -version</span><br><span class="line">cmake version 3.19.4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果没有正确显示版本 请断开SSH连接 重写登录</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>手动安装snappy</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载已经安装的</span></span><br><span class="line"></span><br><span class="line">rm -rf /usr/local/lib/libsnappy*</span><br><span class="line">rm -rf /lib64/libsnappy*</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传解压</span></span><br><span class="line">tar zxvf snappy-1.1.3.tar.gz </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/snappy-1.1.3</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装</span></span><br><span class="line">[root@node4 snappy-1.1.3]# ls -lh /usr/local/lib |grep snappy</span><br><span class="line">-rw-r--r-- 1 root root 511K Nov  4 17:13 libsnappy.a</span><br><span class="line">-rwxr-xr-x 1 root root  955 Nov  4 17:13 libsnappy.la</span><br><span class="line">lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so -&gt; libsnappy.so.1.3.0</span><br><span class="line">lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so.1 -&gt; libsnappy.so.1.3.0</span><br><span class="line">-rwxr-xr-x 1 root root 253K Nov  4 17:13 libsnappy.so.1.3.0</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装配置JDK 1.8</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压安装包</span></span><br><span class="line">tar zxvf jdk-8u65-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">java -version</span><br><span class="line"></span><br><span class="line">java version &quot;1.8.0_241&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_241-b07)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装配置maven</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压安装包</span></span><br><span class="line">tar zxvf apache-maven-3.5.4-bin.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export MAVEN_HOME=/export/server/apache-maven-3.5.4</span><br><span class="line">export MAVEN_OPTS=&quot;-Xms4096m -Xmx4096m&quot;</span><br><span class="line">export PATH=:$MAVEN_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">[root@node4 ~]# mvn -v</span><br><span class="line">Apache Maven 3.5.4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加maven 阿里云仓库地址 加快国内编译速度</span></span><br><span class="line">vim /export/server/apache-maven-3.5.4/conf/settings.xml</span><br><span class="line"></span><br><span class="line">&lt;mirrors&gt;</span><br><span class="line">     &lt;mirror&gt;</span><br><span class="line">           &lt;id&gt;alimaven&lt;/id&gt;</span><br><span class="line">           &lt;name&gt;aliyun maven&lt;/name&gt;</span><br><span class="line">           &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;</span><br><span class="line">           &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</span><br><span class="line">      &lt;/mirror&gt;</span><br><span class="line">&lt;/mirrors&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装ProtocolBuffer 3.7.1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载之前版本的protobuf</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar zxvf protobuf-3.7.1.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/protobuf-3.7.1</span><br><span class="line">./autogen.sh</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">[root@node4 protobuf-3.7.1]# protoc --version</span><br><span class="line">libprotoc 3.7.1</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传解压源码包</span></span><br><span class="line">tar zxvf hadoop-3.3.0-src.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译</span></span><br><span class="line">cd /root/hadoop-3.3.0-src</span><br><span class="line"></span><br><span class="line">mvn clean package -Pdist,native -DskipTests -Dtar -Dbundle.snappy -Dsnappy.lib=/usr/local/lib</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">参数说明：</span></span><br><span class="line"></span><br><span class="line">Pdist,native ：把重新编译生成的hadoop动态库；</span><br><span class="line">DskipTests ：跳过测试</span><br><span class="line">Dtar ：最后把文件以tar打包</span><br><span class="line">Dbundle.snappy ：添加snappy压缩支持【默认官网下载的是不支持的】</span><br><span class="line">Dsnappy.lib=/usr/local/lib ：指snappy在编译机器上安装后的库路径</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译之后的安装包路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/root/hadoop-3.3.0-src/hadoop-dist/target</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">Hadoop-基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-10 21:10:22" itemprop="dateCreated datePublished" datetime="2021-08-10T21:10:22+08:00">2021-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hadoop介绍"><a href="#Hadoop介绍" class="headerlink" title="Hadoop介绍"></a>Hadoop介绍</h1><p>Hadoop是指Apache的一款开源软件，Java实现。它允许用户使用简单的编程模型实现跨机器集群对海量数据进行分布式计算处理。</p>
<h2 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h2><p>HDFS（分布式文件存储系统）：解决海量数据存储</p>
<p>YARN（集群资源管理和任务调度框架）：解决资源调度任务</p>
<p>MapReduce（分布式计算框架）：解决海量数据计算</p>
<h2 id="Hadoop特性"><a href="#Hadoop特性" class="headerlink" title="Hadoop特性"></a>Hadoop特性</h2><ol>
<li><p>scalability（扩容能力）</p>
<p>Hadoop是在可用的计算机集群间分配数据并完成计算任务的，这些集群可方便灵活的方式扩展到数以千计的节点</p>
</li>
<li><p>Economical （成本低）</p>
<p>Hadoop集群允许通过部署普通廉价的机器组成集群来处理大数据，以至于成本很低，看重的集群整体能力</p>
</li>
<li><p>efficiency（效率高）</p>
<p>通过并发数据，Hadoop可以在节点之间动态并行的移动数据，使得速度非常快</p>
</li>
<li><p>reliablility（可靠性）</p>
<p>能自动维护数据的多份复制，并且在任务失败后能自动的重新部署计算任务</p>
</li>
</ol>
<h2 id="Hadoop集群概述"><a href="#Hadoop集群概述" class="headerlink" title="Hadoop集群概述"></a>Hadoop集群概述</h2><p>Hadoop集群包括两个集群：HDFS集群、YARN集群。</p>
<p>两个集群逻辑上分离、通常物理上在一起。它们相互之间没有依赖、互不影响。某些角色进程部署在同一台物理服务器上。</p>
<p>两个集群都是标准的主从架构集群。</p>
<p><img src="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/image-20221212112847844.png" alt="image-20221212112847844"></p>
<p>Hadoop集群 &#x3D; HDFS集群 + YARN集群</p>
<p><img src="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/hdfs-yarn%E9%9B%86%E7%BE%A4.png" alt="hdfs-yarn集群"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/07/14/Spring-Boot-%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/14/Spring-Boot-%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95/" class="post-title-link" itemprop="url">Spring Boot 知识清单</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-14 14:44:55" itemprop="dateCreated datePublished" datetime="2021-07-14T14:44:55+08:00">2021-07-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Spring-Ioc-容器"><a href="#Spring-Ioc-容器" class="headerlink" title="Spring Ioc 容器"></a>Spring Ioc 容器</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/" class="post-title-link" itemprop="url">高可用系统架构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-29 23:01:33" itemprop="dateCreated datePublished" datetime="2021-05-29T23:01:33+08:00">2021-05-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV13NhmAVDZqAAKvYM6OQbU322.png"></p>
<ol>
<li>互联网系统可用性度量，即如何用指标来衡量系统的可用性，以及进行可用性管理时的一些手段。</li>
<li>高可用架构策略，主要包括负载均衡、备份与失效转移、消息队列隔离、限流与降级、异地多活这样几种架构方法。</li>
<li>高可用运维，如何在开发测试发布以及系统运行过程中，保障系统的高可用，包括自动化部署、自动化监控、自动化测试、预发布测试这几个方面。</li>
</ol>
<p><strong>系统高可用的挑战</strong></p>
<p>一个互联网应用想要完整地呈现在最终用户的面前，需要经过很多个环节，任何一个环节出了问题，都有可能会导致系统不可用。</p>
<p>比如说 DNS 被劫持，域名解析就失败了，系统虽然完好无损，但用户依然不能访问系统。再比如，CDN 服务不可用，前面提过，CDN 服务是用户访问的第一跳，对于大型互联网系统而言，主要的静态资源都是通过 CDN 返回的。如果 CDN 服务不可用，那么大量的用户请求就会到达互联网数据中心，会给互联网数据中心带来巨大的请求负载压力，可能直接导致系统崩溃。还有就是应用服务器及数据库宕机、网络交换机宕机、磁盘损坏、网卡松掉，这样的硬件故障；机房停电了、空调失灵了、光缆被挖掘机挖断了，这些环境故障。以及程序代码 bug 引起的故障，等等。</p>
<p>每种故障都是系统不可用的原因之一，在设计系统相关架构的时候，要考虑各个方面的因素。除了系统本身故障导致的可用性问题，还有外部因素导致的系统不可用。比如说系统被黑客攻击了；业务上要做一次大的促销，或者要做一个秒杀的活动，因此带来的访问压力冲击；以及第三方合作伙伴服务不可用等等，各种带来系统故障的原因。</p>
<p>系统的高可用架构，说的就是如何去应对这些挑战。</p>
<h1 id="互联网应用可用性的度量"><a href="#互联网应用可用性的度量" class="headerlink" title="互联网应用可用性的度量"></a>互联网应用可用性的度量</h1><p>业界通常用多少个 9 来说明互联网应用的可用性。比如说 QQ 的可用性是 4 个 9，就是说 QQ 的服务 99.99% 可用，这句话的意思是 QQ 的服务要保证在其所有的运行时间里只有 0.01% 不可用，也就是说一年大概有 53 分钟不可用。这个 99.99% 就叫做系统的可用性指标，这个值的计算公式是：年度可用性指标&#x3D; 1 −（不可用时间&#x2F;年度总时间）×100%。</p>
<p>一般说来，两个 9 表示系统基本可用，年度停机时间小于 88 小时；3 个 9 是较高可用，年度停机时间小于 9 个小时；4 个 9 是具有自动恢复能力的高可用，年度停机时间小于 53 分钟；5 个 9 指极高的可用性，年度停机时间小于 5 分钟。事实上对于一个复杂的大型互联网系统而言，对可用性的影响因素是非常多的，能够达到 4 个 9 甚至 5 个 9 的可用性，除了具备过硬的技术、大量的设备资金投入、有责任心的工程师，有时候还需要好运气。</p>
<p>我们熟悉的互联网产品的可用性大多是 4 个 9，淘宝、支付宝、微信，差不多都是这样。我们用可用性来描述一个系统是否整体可用，但是实际上很少会出现整个系统在几分钟几个小时内全部不可用的情况，更多的时候是一部分用户全部不可用，或者是全部的用户一部分功能不可用。可用性指标是对系统整体可用性的一个度量。</p>
<h1 id="高可用策略"><a href="#高可用策略" class="headerlink" title="高可用策略"></a>高可用策略</h1><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>首先是应用服务器的负载均衡。负载均衡核心要解决的就是通过一个负载均衡服务器，将用户的请求分发给多个应用服务器，将多个应用服务器构建成一个集群，共同对外提供服务。这样的架构可以提高系统的处理能力，以解决高并发用户请求下的系统性能问题。</p>
<p>事实上，负载均衡还可以实现系统的高可用。因为用户的请求是通过负载均衡服务器请求分发到不同的应用服务器上的。那么当某个应用服务器宕机的时候，负载均衡服务器可以通过响应超时或者其它的心跳策略，发现这个应用服务器不可用，就可以将请求转发给其它的服务器，保证用户的请求总是能够成功的，整个系统对外看起来是可用的。从而使某个应用的服务器宕机，不会影响到整个系统的可用性。</p>
<p>这里面需要注意的一个点是，当我们提到一个应用服务器不可用的时候，并不仅仅是指应用服务器的硬件故障，或者是系统故障导致的系统宕机，更多的可能是应用程序在发布，因为应用程序要发布，必须要关闭以前的应用程序进程，拷贝新的程序代码，重新启动应用程序，这个时间可能需要几分钟或者十几分钟的时间，那么这段时间这台应用服务器对外看起来就是不可用的。</p>
<p>而这样的发布在互联网场景中是非常频繁的，一周有几次，甚至一天都有几次这样的发布。应用服务器是需要频繁停机的。所以在架构设计的时候，你不光要考虑到真正的服务器硬件或者系统故障导致的宕级，还要考虑到应用程序发布导致的系统停机，而这个可能更加频繁。</p>
<h3 id="负载均衡实现方法"><a href="#负载均衡实现方法" class="headerlink" title="负载均衡实现方法"></a>负载均衡实现方法</h3><h4 id="HTTP-重定向负载均衡"><a href="#HTTP-重定向负载均衡" class="headerlink" title="HTTP 重定向负载均衡"></a>HTTP 重定向负载均衡</h4><p>比较简单的一种是 HTTP 重定向负载均衡，也就是来自用户的 HTTP 请求到达负载均衡服务器以后，负载均衡服务器根据某种负载均衡算法计算一个新的服务器，通过 HTTP 重定向响应，将新的 IP 地址发送给用户浏览器，用户浏览器收到重定向响应以后，重新发送请求到真正的应用服务器，以此来实现负载均衡。工作原理如下图所示。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV13TjWAcbwLAAOWnFopnts060.png"></p>
<p>HTTP 重定向负载均衡的优点是它的设计比较简单，最简单的 HTTP 重定向负载均衡服务器，可能只需要几十行代码就可以完成。但是它的缺点是，用户完成一次访问需要两次请求数据中心，一次请求负载均衡服务器，一次是请求应用服务器；另一个问题是因为响应要重定向到真正的应用服务器，所以需要把应用服务器的 IP 地址暴露给外部用户，这样可能会导致安全性的问题。</p>
<h4 id="DNS-负载均衡"><a href="#DNS-负载均衡" class="headerlink" title="DNS 负载均衡"></a>DNS 负载均衡</h4><p>另一种实现负载均衡的策略是 DNS 负载均衡。我们知道浏览器访问我们数据中心的时候，通常是用域名进行访问，HTTP 协议则必须知道 IP 地址才能建立通信连接，那么域名是如何转换成 IP 地址的呢？就是通过 DNS 服务器来完成。当用户从浏览器发起发起 HTTP 请求的时候，他输入域名，首先要到 DNS 域名服务器进行域名解析，解析得到 IP 地址以后，用户才能够根据 IP 地址建立 HTTP 连接，访问真正的数据中心的应用服务器，那么就可以在 DNS 域名解析的时候进行负载均衡，不同的浏览器进行解析的时候，返回不同的 IP 地址，从而实现负载均衡。工作原理如下图所示。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l13NhuAay7PAANuWKPiFK8545.png"></p>
<p>目前主要的 DNS 服务商和 DNS 软件都支持 DNS 域名解析负载均衡。DNS 域名解析负载均衡的主要问题有两个方面。一方面它依然是要将 Web 服务器的 IP 地址暴露给浏览器，产生安全问题。另一方面，很多时候，DNS 域名解析服务器是在互联网应用系统之外的一个服务器，它由域名解析服务商提供，不在我们的控制范围之内，所以当我们的服务器不可用的时候，DNS 域名解析服务器并不知道，它依然会将用户请求分发过来。而且域名解析并不是每一次请求都进行解析的，即使我们去域名解析服务商的机器上去更新了域名解析对应的 IP 列表，这个更新也不会立即生效，依然会有大量的请求到达我们的应用服务器。那么这些已经宕机的、不可用的服务器就无法完成用户的需求，在用户看起来就是我们的系统不可用。</p>
<p>虽然 DNS 域名解析负载均衡有这样的一些问题，但是在实践中大型互联网系统几乎都使用域名解析负载均衡，主要原因是在于，这些大型互联网系统，比如像淘宝、Facebook、百度这些系统，根据域名解析出来的 IP 地址，并不是真正的 Web 服务器 IP 地址，是负载均衡服务器的 IP 地址，也就是说这些大型互联网系统，它们都采用了两级负载均衡机制，DNS 域名解析进行一次负载均衡解析出来的 IP 地址是负载均衡服务器的 IP 地址，然后由负载均衡服务器，再做一次负载均衡，将用户的请求分发到应用服务器，这样的话，我们的应用服务器的 IP 地址就不会暴露出去。同时由于负载均衡服务器通常是比较高可用的，也不存在应用程序发布的问题，所以很少有可用性方面的问题。</p>
<h4 id="反向代理负载均衡"><a href="#反向代理负载均衡" class="headerlink" title="反向代理负载均衡"></a>反向代理负载均衡</h4><p>负载均衡的另外一种实现是反向代理负载均衡。我们前面提到用户请求到达数据中心以后，最先到达的就是反向代理服务器。反向代理服务器，除了可以提供请求的缓存功能以外，还可以进行负载均衡，将用户的请求分发到不同的服务器上面去。反向代理是工作在 HTTP 协议层上的一个服务器，所以它代理的也是 HTTP 的请求和响应。而 HTTP 协议相对说来，作为互联网第七层的一个协议，它的协议比较重，效率比较低，所以反向代理负载均衡通常用在小规模的互联网系统上，只有几台或者十几台服务器的规模。工作原理如图所示。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV13TleAGkEbAAMjmfjdqT4222.png"></p>
<h4 id="IP-层负载均衡（四层负载均衡）"><a href="#IP-层负载均衡（四层负载均衡）" class="headerlink" title="IP 层负载均衡（四层负载均衡）"></a>IP 层负载均衡（四层负载均衡）</h4><p>如果规模再大一点的集群，通常就不会再使用反向代理服务器进行负载均衡。在七层网络通讯之下的另外一种负载均衡方法是在 IP 层进行负载均衡，IP 层是网络通讯协议的第四层，所以有时候叫四层负载均衡。它的主要工作原理是当用户的请求到达负载均衡服务器以后，负载均衡服务器会拿到 TCP&#x2F;IP 的数据包，对数据包的 IP 地址进行转换，修改 IP 地址，将其修改为 Web 服务器的 IP 地址，然后把数据包重新发送出去。如下图所示。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV13ToGAOH4DAANP56h82n8245.png"></p>
<p>因为 IP 地址已经是 Web 服务器的 IP 地址，所以这个数据包会重新路由到应用服务器上，以此来实现负载均衡。IP 层负载均衡，比我们刚才提到的工作在第七层的反向代理负载均衡效率要高得多。但是它依然有一个缺陷，就是不管是请求还是响应的数据包都要通过负载均衡服务器进行 IP 地址转换，才能够正确地进行数据分发，或者正确地响应到用户的客户端浏览器。请求的数据通常比较小，一个 URL 或者是一个简单的表单，但是响应的数据不管是 HTML 还是图片，JS、CSS 这样的资源文件通常都会比较大，因此负载均衡服务器会成为响应数据的流量瓶颈。</p>
<h4 id="数据链路层负载均衡"><a href="#数据链路层负载均衡" class="headerlink" title="数据链路层负载均衡"></a>数据链路层负载均衡</h4><p>为了解决这个问题，将负载均衡的数据传输，再往下放一层，放到了数据链路层，实现数据链路层的负载均衡。在这一层上，负载均衡服务器并不修改数据包的 IP 地址，而是修改网卡的 MAC 地址。而应用服务器和负载均衡服务器都使用相同的虚拟 IP 地址，这样 IP 路由就不会受到影响，但是网卡会根据自己的 MAC 地址选择负载均衡发送到自己的网卡的数据包，交给对应的应用服务器去处理，处理结束以后，当他把响应的数据包发送到网络上的时候，因为 IP 地址没有修改过，所以这个响应会直接到达用户的浏览器，而不会再经过负载均衡服务器。工作原理如下图所示。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l13NhuABboPAANF16k_Zus646.png"></p>
<p>这种通信方式我们从上图看是一个三角形，所以也被形象地称为三角模式。数据链路层的负载均衡是目前大型互联网系统中使用得最多的负载均衡方案。在 Linux 内核中也支持数据链路层负载均衡，也就是说可以用一台 Linux 服务器去配置实现数据链路层负载均衡，通过负载均衡实现应用服务器的高可用。</p>
<h2 id="数据库复制与失效转移"><a href="#数据库复制与失效转移" class="headerlink" title="数据库复制与失效转移"></a>数据库复制与失效转移</h2><p>数据库的高可用要比应用服务器复杂很多，因为应用服务器是无状态的，请求可以分发到任何一台服务器去处理，而数据库上必须存储有正确的数据才能将请求分发给它。对于数据库的高可用，通常是使用数据库复制与失效转移来完成的。我们在分布式数据库存储这一讲中提到过 MySQL 的主主复制，以及 MySQL 的主从复制。</p>
<p>因为有数据复制，所以用户请求可以访问到不同的从服务器上，当某一台从服务器宕机的时候，系统的读操作不会受到影响，实现数据库读操作高可用。而如果实现了主主复制，那么当主服务器宕机的时候，写请求连接到另外一台主服务器上，实现数据库的写操作高可用，而数据库部署的时候，可以同时部署如下图所示这样的主主复制和主从复制，也就是实现数据库的读写都高可用。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV13XS-ABhWJAAXmqw3pev8732.png"></p>
<h2 id="消息队列隔离"><a href="#消息队列隔离" class="headerlink" title="消息队列隔离"></a>消息队列隔离</h2><p>系统高可用的另一种策略是使用消息队列实现异步解耦，即消息队列隔离。我们在分布式消息队列一讲中也提到过这种架构方式的高可用。</p>
<p>一方面，消息的生产者和消费者通过消息队列进行隔离，那么如果消费者出现故障的时候，生产者可以继续向消息队列发送消息，而不会感知到消费者的故障，等消费者恢复正常以后再去到消息队列中消费消息，所以从用户处理的视角看，系统一直是可用的。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l13NhyAZztaAACvmUe0VZI668.png"></p>
<p>另一方面，由于分布式消息队列具有削峰填谷的作用，所以在高并发的时候，消息的生产者可以将消息缓存在分布式消息队列中，消费者可以慢慢地到消息队列中去处理，而不会将瞬时的高并发负载压力直接施加到整个系统上，导致系统崩溃。</p>
<h2 id="限流和降级"><a href="#限流和降级" class="headerlink" title="限流和降级"></a>限流和降级</h2><p>系统高可用的另一个策略是限流和降级。主要针对的是，在高并发场景下，如果系统的访问量超过了系统的承受能力，如何对系统进行保护？</p>
<p>限流是指对进入系统的用户请求进行限流处理，如果访问量超过了系统的最大处理能力，就会丢弃一部分的用户请求，保证整个系统可用，保证大部分用户是可以访问系统的。这样虽然有一部分用户的请求被丢弃，产生了部分不可用，但还是好过整个系统崩溃，所有的用户都不可用要好。</p>
<p>保护系统的另一种手段就是降级。有一些系统功能是非核心的，但是实际它也给系统产生了非常大的压力，比如说在电商系统中有“确认收货”这个功能，对于大多数互联网电商应用，我们即使是不去确认收货，超时它会自动确认收货。</p>
<p>但实际上确认收货这个操作是一个非常重的操作，因为它要更改订单状态，完成支付确认，并进行评价等一系列操作。这些操作都是一些非常重的、对数据库压力很大的操作。如果在系统高并发的时候去完成这些操作，那么会对系统雪上加霜，使系统的处理能力更加恶化。解决办法就是在系统高并发的时候，比如说像淘宝“双11“这样的时候，当天可能整天系统都处于一种极限的高并发访问压力之下，这一天就可以将确认收货、评价这些非核心的功能关闭，将宝贵的系统资源留下来，给正在购物的人，让他们去完成交易。</p>
<h2 id="异地多活机房架构"><a href="#异地多活机房架构" class="headerlink" title="异地多活机房架构"></a>异地多活机房架构</h2><p>系统高可用的另一个策略是异地多活的架构。我们前面提到的各种高可用策略，都还是针对一个机房内的系统架构，但是如果整个机房都不可用，比如说机房所在城市遭遇了地震，机房遭遇了火灾或者停电，这样的话，不管我们前面的设计和系统多么的高可用，整个机房都不可访问，看起来系统依然是不可用的。</p>
<p>为了解决这个问题，同时也为了提高系统的处理能力和改善用户体验。很多大型互联网应用都采用了异地多活的多机房架构策略，也就是说将数据中心分布在多个不同地点的机房里，这些机房都可以对外提供服务，用户可以连接任何一个机房进行访问。这样每个机房都可以提供完整的系统服务，即使某一个机房不可使用，系统也不会宕机，依然保持可用。</p>
<p>异地多活的架构考虑的一个重点是，用户请求如何分发到不同的机房去。这个主要可以在域名解析的时候完成，也就是用户进行域名解析的时候，会根据就近原则或者其它一些策略，完成用户请求的分发。</p>
<p>另一个至关重要的技术点是，因为是多个机房都可以独立对外提供服务，所以也就意味着每个机房都要有完整的数据记录，所以用户在任何一个机房完成的数据操作，都必须要同步传输给其它的机房，需要进行数据实时同步。</p>
<p>目前远程数据库同步的解决方法有很多，最需要关注的是数据冲突问题。同一条数据，同时在两个数据中心被修改了，该如何解决？为了解决这种数据冲突的问题，很多异地多活的多机房架构实际上采用的是类似 MySQL 的主主模式，也就是说多个机房在某个时刻是有一个主机房的，某些请求只能到达主机房才能被处理，其它的机房不处理这一类请求，以此来避免关键数据的冲突。</p>
<h1 id="高可用运维"><a href="#高可用运维" class="headerlink" title="高可用运维"></a>高可用运维</h1><h2 id="自动化测试"><a href="#自动化测试" class="headerlink" title="自动化测试"></a>自动化测试</h2><p>除了高可用的架构，还有保障系统高可用的运维。</p>
<p>其中一种高可用的运维是自动化测试。对于一个成熟的互联网系统，任何一次代码变更，都可能需要执行大量的回归测试，才能够保证系统没有 bug，而这种更新又是非常频繁的，如果依赖手工操作，测试效率和测试资源都难以满足如此大量的回归测试需求。所以对于成熟的互联网产品，很多时候采用自动化测试，通过自动化脚本自动对 APP 或者是服务接口进行测试。</p>
<p>一开始的时候要写自动化的测试脚本，工作量会比较大，投入也会比较大。但是随着脚本的不断的积累，自动化测试的成本会比手工测试的成本要更低。一般说来，在实践中，对于比较成熟的互联网产品，也就是说每次变更相对影响比较小的互联网产品，使用自动化测试是比较划算的。自动化测试和手工测试的总体成本对比如下图。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV13NhyADh9_AACC0HK0g6k701.png"></p>
<h2 id="自动化监控"><a href="#自动化监控" class="headerlink" title="自动化监控"></a>自动化监控</h2><p>还有一种是自动化监控。系统在线上运行的时候，必须要实时的监控系统的各项指标，包括业务指标和技术指标。业务指标包括用户访问量、订单量、查询量这些主要的业务指标，技术指标包括 CPU、磁盘、内存的使用率等。通过这些指标可以实时监控业务是否正常，系统是否正常。如果指标不正常，通过监控报警的手段，通知相关的人员，还可以在自动化监控的基础上去，触发自动化的运维工具，进行自动化的系统修复。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l13XWCAMVCMAAXGZAuzLs8203.png"></p>
<h2 id="预发布"><a href="#预发布" class="headerlink" title="预发布"></a>预发布</h2><p>高可用运维的另一种手段是预发布。虽然在系统上线之前，系统在代码更新以后，要经过测试才会上线，但是还有一些情况在测试环境是无法复现的。比如对第三方服务的调用，数据库结构的变更，以及一些线上的配置参数变更等等，只有线上才能够发现。</p>
<p>但是一旦发布到线上以后，如果有这些问题，就会导致系统不可用，解决方法就是进行预发布。在线上的服务器集群里面有一台服务器，是专门的预发布服务器，这台服务器不配置在负载均衡服务器，也就是说外部的用户是无法访问到这台服务器的，但是这台服务器跟其它的应用服务器，使用的配置、连接的数据库、连接的第三方服务都是完全一样的，它是一个完全线上的一个服务器，而这个服务器只有内部的工程师才可以访问到。</p>
<p>在系统发布的时候，先发布到这台预发布服务器上，然后工程师通过域名绑定的方式，直接访问这台服务器，进行一些关键的业务操作，看系统是否正常。如果正常，那么就将代码同步到其它的服务器上，这时候外部服务器才能够访问到最新的代码。如果发现问题，那么就可以重新进行修复。这个问题虽然是线上的，但是并不会影响到外部用户的使用。预发布的工作原理如下图。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l13XaiAV3hlAAV3nLAn3Pg963.png"></p>
<h2 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h2><p>对于大型互联网系统，虽然有前面的各种保障措施，但还是可能发生上线以后用户报告出现故障，对于用户报告的故障或者监控到的故障，就需要对系统进行回滚到原来的代码，系统退回到前一个版本。但是对于大型互联网系统而言，它的服务器特别多，可能有数万台服务器，这个时候即使是进行系统回滚，也可能要花很长的时间。这段时间系统一直处于某种不可用的故障状态。</p>
<p>为了避免上述情况，大型互联网系统，会使用一种灰度发布的手段，也就是说每天都只发布一部分服务器，如果出现问题，那么只需要回滚这一部分服务器就可以。发布以后观察一天，第二天再发布一部分服务器。如果没有故障报告，那么就继续发布，如果有故障报告就进行回滚，减少故障的影响力和影响时间。灰度发布流程如下图。</p>
<p><img src="/2021/05/29/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l13Nh2AMDiGAAEHM7DJ1so485.png"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>系统可用性是通过可用性指标来进行衡量的。当我们说一个系统 4 个 9 可用的时候，就是指这个系统 99.99% 的时间都是可用的，也就意味着一年中的不可用时间只占 53 分钟。</p>
<p>为了对故障进行管理和考核，很多互联网企业还引入了故障分这样一个手段。保障系统高可用的主要策略有应用服务器的负载均衡、数据库的备份与失效转移、消息队列隔离，限流、降级以及异地多活的多机房架构。</p>
<p>除了这些高可用的架构策略，还通过一系列的自动化手段，实现运维的高可用，包括自动化测试、自动化监控，预发布以及灰度发布这些手段。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/" class="post-title-link" itemprop="url">高性能系统架构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-26 22:33:30" itemprop="dateCreated datePublished" datetime="2021-05-26T22:33:30+08:00">2021-05-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>高性能系统架构，主要包括两部分内容，性能测试与性能优化。性能优化又可以细分为硬件优化、中间件优化、架构优化及代码优化，知识架构图如下。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FGAao36AARTQx90mWg993.png"></p>
<h1 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h1><p>先看系统的性能测试。性能测试是性能优化的前提和基础，也是性能优化结果的检查和度量标准。</p>
<p>关于性能测试有一句著名的论断，叫作“你不能优化一个你未经测试的系统，你也不能优化一个你不了解的系统”。所以要进行性能优化，首先要进行性能测试，看系统的当前各项性能指标是什么样子的，问题在哪里，从哪些方面进行优化。</p>
<p>而具体在优化的时候，又必须要了解系统。系统的架构是什么样子的？系统的关键技术点、瓶颈点在哪里？为何会产生这样的瓶颈点？以及如何对它进行优化？也就是说必须要在了解系统的基础之上才能进行优化。所以性能测试以及了解系统，是性能优化的两个关键前提。</p>
<p>关于性能的标准，在不同的视角下，性能的度量标准是不同的，性能优劣也是不同的，性能标准有主观和客观两种视角。</p>
<ul>
<li>主观标准是说使用者在体验上的快慢，用户在使用系统的时候，它主观上感觉快还是慢，那么就会得到一个性能好还是差的主观标准；</li>
<li>客观标准，也就是在客观上性能指标到底是好还是差。</li>
</ul>
<p>主观标准和客观标准，虽然它们本质上是统一的，但是也并不是完全一致的。比如客观性能指标相同的两个系统，其中一个系统通过页面渲染，通过一些动画提示，通过更良好的用户交互体验，可以使用户主观感觉系统响应更快。而另一个如果没有做任何交互上的设计优化，仅仅是直接向用户输出内容，那么用户可能会感觉等得更久一些，在主观体验上性能也更差一点。</p>
<h2 id="客观性能指标"><a href="#客观性能指标" class="headerlink" title="客观性能指标"></a>客观性能指标</h2><p>在客观视角上，性能优劣的指标主要有响应时间、并发数、吞吐量以及性能计数器。这些指标通常也是我们技术上要进行优化的主要指标，后面我们的性能讨论主要是围绕这些客观上的性能指标展开的。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FGAT4ltAAC76OJyduE387.png"></p>
<h3 id="响应时间"><a href="#响应时间" class="headerlink" title="响应时间"></a>响应时间</h3><p>第一重要的就是响应时间。所谓响应时间是指应用系统从发出请求开始到收到最后响应数据所需要的时间。响应时间是系统最重要的性能指标，最直接地反映了系统的快慢。</p>
<h3 id="并发数"><a href="#并发数" class="headerlink" title="并发数"></a>并发数</h3><p>第二个指标是并发数。并发数是指系统同时处理的请求数，这个数字反映了系统的负载特性。对于互联网系统而言，并发数就是同时访问系统的用户数，也就是指同时提交请求的用户数目。和并发用户数相对应的还有在线用户数，也就是当前登录系统在使用系统的用户数，当前登录系统在使用系统的用户数并不是并发用户数，因为登录系统在使用的时候，它可能在查看页面内容，在填写页面信息，这个时候只要不提交请求，虽然它当前在系统上是在线的，但是它并不是并发用户数，而是在线用户数。另外，还有系统总用户数，指可能访问系统的总用户数。一般说来，系统的总用户数远大于在线用户数，在线用户数远大于并发用户数，对系统性能产生影响的主要是并发用户数。</p>
<h3 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h3><p>另一个性能指标是吞吐量。吞吐量是指单位时间内系统处理请求的数量，体现的是系统的处理能力。我们一般用每秒的请求数、每秒的事务数这样的一些指标来衡量，也就是 HPS、TPS 这些，HPS 是每秒的 HTTP 数目，TPS 是每秒事务数。还可以用 QPS，即每秒的查询数来表示，总之，就是单位时间内处理的请求数目。</p>
<p>吞吐量、响应时间和并发数三者之间是有关联性的，响应时间足够快，那么单位时间的吞吐量也会相应的提高。比如说响应时间如果是 100ms，对于一个并发用户，并发数是 1，那么 TPS 就可以是 10。如果响应时间是 500ms，用户并发数还是 1，那么 TPS 吞吐量就变成了 2。</p>
<h3 id="性能计数器"><a href="#性能计数器" class="headerlink" title="性能计数器"></a>性能计数器</h3><p>最后一个性能指标是性能计数器。指的是服务器或者操作系统性能的一些指标数据，包括系统负载 System Load、对象和线程数、内存使用、CPU 使用、磁盘和网络 I&#x2F;O 使用等指标。这些指标是系统监控的重要参数，反映系统负载和处理能力的一些关键指标，通常这些指标和性能是强相关的。这些指标很高，成为瓶颈，通常也预示着性能可能会出现问题。在实践中会对这些性能指标设置一些报警的阈值。当监控系统发现性能计数器超过阈值的时候，就会向运维和开发人员报警，以便及时发现、处理系统的性能问题。</p>
<h2 id="性能测试方法"><a href="#性能测试方法" class="headerlink" title="性能测试方法"></a>性能测试方法</h2><p>再来看性能测试的方法。通常我们说性能测试的时候指的是一个总称，是广义上的性能测试，具体可以分为狭义上的性能测试、负载测试、压力测试和稳定性测试。</p>
<h3 id="性能测试-1"><a href="#性能测试-1" class="headerlink" title="性能测试"></a>性能测试</h3><p>狭义的性能测试是指以系统设计初期规划的性能指标为预期目标，对系统不断施加压力，验证系统在资源可接受的范围内是否达到了性能的预期。所以性能测试主要是测试系统的性能是否达到了设计预期这样一个目标，对系统的压力相对比较小的。</p>
<h3 id="负载测试"><a href="#负载测试" class="headerlink" title="负载测试"></a>负载测试</h3><p>负载测试，则是对系统不断施加并发请求，增加系统的压力，直到系统的某项或多项指标达到安全临界值。比如某种系统资源已经呈现饱和状态，这个时候继续对系统施加压力，系统的处理能力不但不能提高，反而会下降。所以简单说，负载测试是指通过不断施加负载压力，寻找系统最优的处理能力，最好的性能状态，达到最大的性能指标。通常说来，负载测试的结果比性能测试的结果高一点。</p>
<h3 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h3><p>第三个压力测试，是指在超过安全负载的情况下，对系统继续施加压力，直到系统崩溃，或者不再处理任何请求，以此获得系统的最大压力承受能力。压力测试也就是，将系统压崩溃需要多大的负载压力或者是并发请求压力，测试系统在最坏的情况下可以承受多大的访问压力。</p>
<h3 id="稳定性测试"><a href="#稳定性测试" class="headerlink" title="稳定性测试"></a>稳定性测试</h3><p>稳定性测试则是指被测试的系统在特定的硬件、软件和网络环境条件下，给系统施加一定的业务压力，使系统运行较长一段时间，以此检测系统是否稳定。在生产环境中，请求压力是不均匀的、呈现波浪的特性，因此为了更好地模拟生产环境，稳定性测试也应该不均匀地对系统施加压力，看系统在这种持续的、长时间的、不均匀的访问压力之下，能否稳定地提供响应特性，系统性能是否保持稳定。</p>
<h2 id="性能特性曲线"><a href="#性能特性曲线" class="headerlink" title="性能特性曲线"></a>性能特性曲线</h2><h3 id="吞吐量特性曲线"><a href="#吞吐量特性曲线" class="headerlink" title="吞吐量特性曲线"></a>吞吐量特性曲线</h3><p>前面提到的，性能测试、负载测试和压力测试，它的测试曲线如下图所示。横轴是系统资源或者并发用户数，对于性能测试，系统资源和并发用户数本质上是一样的，因为随着并发用户数的增加，系统资源消耗是线性增加的。纵轴是它的吞吐量 TPS。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FKAS8JDAAA5sOCVW7U667.png"></p>
<p>在性能测试阶段，随着并发访问逐渐的增加，系统资源的不断消耗，TPS 是在不断上升的。</p>
<p>到了负载测试阶段，这种上升的斜率会变小，直到达到了系统负载能力的最大点，也就是 c 点。而过了 c 点以后继续施加压力，继续提高并发请求的数量，系统资源消耗进一步增加，TPS 吞吐量不增反降，会呈现下降趋势。直到到达了某个点，d 点，系统超过了它的最大承受能力，系统崩溃。</p>
<p>压力测试的时候，吞吐量之所以会下降，是因为更多的并发请求、更多的用户请求进入系统以后，系统已经无法正常处理这样多的用户请求，系统的资源消耗情况会更加恶化，系统不能够有效地处理用户的正常请求，却又不得不分配出大量的资源，来调度用户的访问请求。这时候系统资源虽然被更多的消耗，但是响应时间在不断地加长，它的 TPS 在下降。</p>
<h3 id="响应时间特性曲线"><a href="#响应时间特性曲线" class="headerlink" title="响应时间特性曲线"></a>响应时间特性曲线</h3><p>和 TPS 相对应的响应时间曲线则是相反的，如下图。随着并发用户数的增加，以及系统资源的不断消耗，系统的响应时间在不断增加。在性能测试阶段，系统的响应时间几乎没有太多的变化，但是到了负载测试的时候，系统的响应时间就开始增加，当超过了它最大负载点——c 点以后继续增加压力，系统的响应时间会急剧增加，系统的性能状况急剧恶化，最后到达了它的崩溃点——d 点。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FKASZUpAABGou72PvU546.png"></p>
<p>一般说来，性能测试是通过增加并发数，不断测试各项性能指标获得的。如下图性能测试结果表所示，并发数不断地增加，响应时间也不断地增加，TPS 先增加后下降，而错误率超过了某些点以后开始增加，后来增速加剧，同时系统的负载也在不断增加。通过这个表，绘制出来的性能特性曲线就如上面的图中所示。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FKAAfBmAAB9uSBuVK8399.png"></p>
<p>性能测试就是要测试出性能特性曲线，看当前的系统是否达到了性能目标，以及系统最好的性能特性是什么，能达到的最大负载压力是多大。从而做到对自己的系统心中有数，面对高并发访问的时候，心中不慌，从容应对。</p>
<h1 id="系统性能优化"><a href="#系统性能优化" class="headerlink" title="系统性能优化"></a>系统性能优化</h1><p>现在我们已经了解了系统的各项性能指标，那么如何对系统进行性能优化呢？</p>
<h2 id="分层优化系统性能"><a href="#分层优化系统性能" class="headerlink" title="分层优化系统性能"></a>分层优化系统性能</h2><p>通常当说起对系统性能进行优化的时候，大家一般想到的是对系统内自己写的代码进行优化，或者大不了对系统的架构进行优化，但实际上对系统的性能优化可以有更高层次的思考。如下图所示，将系统的性能优化分为七层，可以在不同的层面对系统进行性能优化。</p>
<img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FOAA3IjAAB3BX2DxEA853.png" style="zoom:67%;">

<p><strong>第一层是机房与骨干网络的性能优化</strong></p>
<p>对于高并发的、大流量的、海量用户访问的一个互联网应用而言，通常它可能是全球级的，它的用户可能分布在全球各个地方，我们知道，即使是以光的速度进行传输，从地球的另一面对一个数据中心进行数据访问，它的一次请求响应的网络通讯时间都需要几百毫秒的时间，而我们对一个成熟的应用进行性能优化，通常是难以获得几百毫秒的响应时间优化的。所以对于大型互联网应用，它们通常会进行全球各地的多机房部署，就近为当地用户提供访问服务，即使是只针对国内的用户使用的一些大型互联网应用，为了提高不同地区的用户的访问体验，也会进行多机房架构设计。比如说像新浪微博，它们在上海、北京和广州建设了 3 个机房，分别为中国不同地域的用户提供服务。</p>
<p>所以机房与骨干网络的性能优化，主要手段就是采用异地多活的多机房架构，同时为了联通这些异地多活的多机房架构，会建设自己专用的骨干网络，并且自主进行 CDN 建设。</p>
<p> <strong>第二层是对服务器内的硬件进行优化</strong></p>
<p>我们前面讨论过系统伸缩，有垂直伸缩和水平伸缩两种，互联网应用主要使用的是水平伸缩。但是某些情况下，垂直伸缩实际上带来的性能优化也是不可忽视的。在成本允许的情况下，考虑使用垂直伸缩，提高服务器硬件的性能，对系统性能的提升会有很大的好处。</p>
<p>比如说我们用 SSD 硬盘代替传统的机械硬盘，就可以使磁盘的访问读写特性得到数量级的提升。</p>
<p>如下图所示，这是一个 Spark 性能优化的案例。因为 Spark 是一个大数据处理平台，所以需要处理大量的数据，在作业处理过程中，不同的服务器之间需要传输大量的数据。经过性能指标分析，我们发现，在一次作业运行中，大量的时间消耗在网络传输上。对这种情况进行性能优化，如果要是从程序或者代码的层面进行优化，那么主要手段就是使用数据压缩，将数据压缩以后进行传输，这样可以减少数据的传输量，减少网络传输的性能压力，降低网络传输花费的时间。但是对数据进行压缩和解压缩，需要消耗大量的 CPU 资源，事实上大数据计算通常也是 CPU 密集型，将宝贵的 CPU 资源花费在数据压缩和解压缩上，最后的性能结果可能会变的更差。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FSAF3twAAqCeMbFh7k344.png"></p>
<p>是我们可以对硬件进行优化，如上图例子中看到的。在优化前，我们使用的是如图这种 1G 的网卡，里面的曲线表示的是网卡读写性能，在某些阶段，网卡的读写传输能力已经达到了它的极限，需要几十秒的时间去完成数据传输，然后再进入下一个计算阶段。</p>
<p>我们通过硬件优化的方法，将网卡更换为 10G 网卡，如下图，得到了这样一条网卡传输的性能曲线，我们看到系统在最大的数据传输压力情况下，它依然没有触发到网卡处理能力的极限，而网络传输的时间也从以前的几十秒缩短到了十多秒。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FSAdCteAAfH9mPJTG0835.png"></p>
<p><strong>第三层是操作系统的性能优化</strong></p>
<p>这里我们再看一个案例，依然是 Spark 的性能优化案例。下图中是 CPU 的使用率，我们看到其中红色的是用户程序使用的，表示的是 CPU 的用户态，紫色部分是 CPU 的系统态，红色部分是 User 状态，紫色部分是 sys 状态。紫色部分表示的是当前 CPU 被操作系统占据，执行操作系统的指令。但是为什么在一个大数据处理作业过程中，有这样多的 CPU 时间花费在系统处理上？</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FWAPdkpAAUqPYDnK5Y840.png"></p>
<p>经过进一步的性能分析，发现部分 Linux 版本在缺省状况下打开了 tranparent huge page 这样一个参数，当我们关闭参数的时候，发现处于 sys 状态 CPU 的消耗得到了极大的优化，也就是下图。如图所示，关闭 tranparent huge page 后，处于 sys 状态消耗的指标，也就是紫色部分消耗的 CPU 指标得到了极大的改善，而整个的系统作业时间也从 200 多秒优化到了 150 多秒。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FaAQQ6UAAV1CX0sQzQ629.png"></p>
<p><strong>第四层是虚拟机的性能优化</strong></p>
<p>目前主流的像 Java、C# 这样的一些互联网 Web 应用，都是运行在虚拟机之上的，那么对虚拟机的性能优化也会对系统的整个性能产生巨大的影响。</p>
<p>最典型的就是垃圾回收器对系统的性能优化，如下图，我们看到 Java 的几种不同垃圾回收器，从最早的串行垃圾回收器，到目前比较新的 G1、ZGC 等垃圾回收器，每一类的垃圾回收器都会对系统性能有不同的影响。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FaAVg3hAAD9go8QaCc049.png"></p>
<p>在互联网应用中使用的主要的垃圾回收器是 CMS 垃圾回收器。CMS 垃圾回收线程和用户的线程在很多时候是并发运行的，这也是 CMS 被称为并发垃圾回收器的原因。因为用户线程和垃圾回收线程并发运行，所以在垃圾回收的时候对用户的性能影响相对比较小一点。而在未来，主流的垃圾回收器应该是 G1。</p>
<p> <strong>在虚拟机之下是基础组件的性能优化</strong></p>
<p>我们的 Web 应用主要是运行和部署在 Web 容器组件上，比如像 Java 运行在 Tomcat、Jetty 或者 JBoss（WildFly）这样的 Web 容器之中，那么 Web 容器本身的性能也一定会对我们这些系统性能产生很大的影响。举一个现实的例子，在阿里巴巴曾经使用 Jetty 代替 JBoss，通过这样一种替换，实现了系统性能的极大的提升，特别是节省了大量的服务器，在替换后，阿里巴巴全站下线 1&#x2F;3 的应用服务器。主要原因是 Jetty 比 JBoss 的架构更轻量，配置更加简单，使用较少的 Jetty 容器，就可以实现原来 JBoss 能够提供的处理能力，如下图所示。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FeATNuvAABfOcH0V-c484.png"></p>
<p><strong>在基础组件性能优化之下才是软件架构性能优化</strong></p>
<p>事实上我们整个课程都是围绕着架构性能优化的各种工具和技术展开的。在这里面我们精简一下，抽象了关于软件架构性能优化的三板斧。这三板斧也是互联网系统架构的最主要的三个技术，分别是缓存、异步和集群。</p>
<ul>
<li>缓存</li>
</ul>
<p>通过缓存可以减少数据库的负载压力。缓存使用内存中的数据，比数据库访问磁盘中的数据要有更好的性能，同时缓存中存储着的计算结果数据，也比数据库中存储的原始数据计算速度更快，资源消耗更小。此外还有一点，缓存减少了数据库的负载压力，从而可以使数据库提供更多的数据访问，支撑更大的系统访问压力，从而提升整体的系统性能。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FeAdFGqAADGs_s5Cdc778.png"></p>
<ul>
<li>异步</li>
</ul>
<p>通过异步的方式，通过分布式消息队列，使系统不同应用之间、不同服务之间异步调用，可以使调用者尽快的返回用户响应，使系统能够得到更好的响应特性。同时分布式消息队列的异步架构，还有削峰填谷的作用，在访问高峰期，通过异步将用户请求数据写入到消息队列中，在访问低谷的时候还在继续消费处理这些消息，避免对数据库等产生较大的负载访问压力，使系统能够维持在一个较好地响应曲线上。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FiAdXLtAANVmFs1B1Y252.png"></p>
<ul>
<li>集群</li>
</ul>
<p>通过负载均衡的手段，将多种应用服务器构建成一个集群，共同提供服务，以提高系统整个的处理能力，提升系统的响应性能。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FmACK5mAArv3sxMRd8581.png"></p>
<p>** 在性能优化的最底层才是软件代码的性能优化**</p>
<p>关于代码的性能优化，有这样一些实践可供参考。</p>
<ul>
<li>第一点是遵循面向对象的设计原则与设计模式编程，避免烂代码。</li>
</ul>
<p>很多时候，我们应用程序性能不好，并不是性能上有什么技术挑战或者是缺陷，仅仅就是因为代码太烂了，系统之间调用耦合严重，很多已经不用的代码，无法清理下线，执行逻辑混乱，导致系统性能差。使用良好的原则与模式编程，编写清晰、灵活、健壮的代码对性能优化有长远的好处。</p>
<ul>
<li>第二点是并发编程，可以在程序并发运行的时候使用多线程。</li>
<li>第三点是资源的复用。</li>
</ul>
<p>对于一些比较昂贵的资源，比如说线程或者数据库连接，通过线程池或者数据库连接池对外提供服务。通过资源池复用对象或者是线程，供应用程序使用，应用程序每次需要资源的时候，从资源池获取，用完了放回到资源池中继续复用，而不是每次使用的时候都去创建，用完了以后就销毁。</p>
<ul>
<li>第四点是用异步编程。</li>
</ul>
<p>在程序内部使用消费者，生产者，以队列数据结构的方式，实现程序内的异步架构，以此来提高系统性能。</p>
<ul>
<li>第五点是要使用正确的数据结构进行编程。</li>
</ul>
<p>要熟悉数组、链表、栈、队列、Hash 表、树等常用数据结构，熟悉它们的特性、优缺点以及使用场景，正确地使用它们来管理和访问程序数据。</p>
<h1 id="性能优化案例"><a href="#性能优化案例" class="headerlink" title="性能优化案例"></a>性能优化案例</h1><p>我们以 Spark 为例，看一个代码的性能优化案例。如下图，我们通过对 CPU 的性能指标的分析发现，在 Spark 作业过程中有一个计算阶段 Stage，运行时间特别长，消耗时间 14 秒。CPU 和网络也都有一定的开销，研究应用代码，发现这段代码仅仅是做了一个数组的初始化，不应该需要花这么长的时间，那么时间究竟花在哪里呢？</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FmAWTLOAArpts6MmoU383.png"></p>
<p>进一步对 Spark 的源代码进行分析，发现 Spark 的任务初始化加载应用代码的时候，每一个执行器 Executor 都要加载一次可执行的应用代码，当时每台服务器启动了 48 个 Executor，每个应用程序的代码包是 17M，所以每一个服务器需要下载 48×17M，而集群有 5 台服务器。通过网络传输这么大的代码包，导致网络阻塞，性能劣化。后来我们对 Spark 的源代码进行了优化，主要优化手段就是在 Executor 加载应用程序的时候，启动了本地文件的缓存模式，先检查本地文件中是否有需要执行的应用程序代码，如果没有，远程从 Driver 服务器上去加载，如果有直接拷贝本地代码到自己的执行路径下，通过这种优化，我们使第一个运行阶段，从 14 秒下降到了不到 1 秒，如下图所示。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgotOV142FqAS0ldAAeQwDnCKvo591.png"></p>
<p>优化代码如下图所示，在 Spark 源码增加基于缓存的文件加载函数，十多行代码，获得极大的性能提升。</p>
<p><img src="/2021/05/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/CgoB5l142FuAHq_eAAfw9xZF3Us688.png"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>性能优化的前提和基础是性能测试，通过性能测试，了解系统的性能特性才能进行优化，而性能测试主要就是要测试出来系统的性能曲线，通过对性能曲线进行分析，了解系统的瓶颈点和系统资源消耗，再进行性能优化。性能优化的时候需要建立一个整体的思维，要从整体系统的层面去思考优化，而不只是仅仅关注自己的代码，或者是自己设计的架构。</p>
<p>最上层的优化是硬件优化，包括骨干网络、数据中心服务器硬件这样的优化；然后是基础组件的性能优化，包括操作系统、虚拟机、应用中间件这几个方面；这之后才是架构的优化，包括核心的三板斧，缓存、异步和集群；最后才是代码的优化，代码优化的主要手段，有并发、复用、异步以及正确的数据结构，当然最重要的是设计清晰、易维护、易懂、简单、灵活的代码，也就是说最重要的是要遵循面向对象的设计原则和设计模式进行编程。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/" class="post-title-link" itemprop="url">分布式微服务</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-21 18:11:48" itemprop="dateCreated datePublished" datetime="2021-05-21T18:11:48+08:00">2021-05-21</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13JL6AA3PDAAJgEBDy948831.png"></p>
<h1 id="单体系统的困难"><a href="#单体系统的困难" class="headerlink" title="单体系统的困难"></a>单体系统的困难</h1><h2 id="编译部署困难"><a href="#编译部署困难" class="headerlink" title="编译部署困难"></a>编译部署困难</h2><p>在微服务出现之前，互联网应用系统主要是单体系统，也就是说一个网站的整个系统由一个应用构成。如果是 Java，就打包成一个 war 包，一个 war 包包含整个应用系统，系统更新的时候，即使只是更新其中极小的一部分，也要重新打包整个 war 包，发布整个系统。</p>
<h2 id="代码分支管理困难"><a href="#代码分支管理困难" class="headerlink" title="代码分支管理困难"></a>代码分支管理困难</h2><p>因为单体应用非常庞大，所以代码模块也是由多个团队共同维护的。但最后还是要编译成一个单体应用，统一发布。这就要求把各个团队的代码 merge 在一起，这个过程很容易发生代码冲突。而 merge 的时候又是网站要进行发布的时候，发布过程本来就复杂，再加上代码 merge 带来的问题，各种情况纠缠在一起，极易出错。所以，在单体应用时代每一次网站发布都需要搞到深更半夜。</p>
<h2 id="数据库连接耗尽"><a href="#数据库连接耗尽" class="headerlink" title="数据库连接耗尽"></a>数据库连接耗尽</h2><p>对于一个巨型的应用而言。因为有大量的用户进行访问，所以必须把应用部署到大规模的服务器集群上。然后每个应用都需要与数据库建立连接，大量的应用服务器连接到数据库，会对数据库的连接产生巨大的压力，某些情况下甚至会耗尽数据库的连接。</p>
<h2 id="新增业务困难"><a href="#新增业务困难" class="headerlink" title="新增业务困难"></a>新增业务困难</h2><p>巨无霸单体应用的另一个挑战是新增业务困难。因为所有的业务都耦合在一个单一的大系统里，通常随着时间的发展，这个系统会变得非常的复杂，里面的各种结构也非常乱，想要维护这样一个系统是非常困难和复杂的。</p>
<h1 id="SOA-架构"><a href="#SOA-架构" class="headerlink" title="SOA 架构"></a>SOA 架构</h1><p>如下图所示，在面向服务的体系架构里面，服务的提供者向注册中心注册自己的服务，而服务的使用者向注册中心去发现服务。发现服务以后，根据服务注册中心提供的访问接口和访问路径对服务发起请求，由服务的提供者完成请求返回结果给调用者。现在的微服务或者分布式服务，其实也是 SOA 架构的一种实现。但是在早期的 SOA 架构实践中，服务的注册与服务的调用都非常复杂，服务调用效率也比较低。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13XFuAJnqQAAGRIgov63M066.png"></p>
<h1 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h1><p>简化了 SOA 架构中的调用规范和服务规范，形成了我们现在所熟悉的分布式微服务架构。</p>
<p>如下图，所谓的微服务架构就是将一个单体的巨无霸系统拆分成一组可复用的服务，基于这些服务构成的应用系统。图中左边是早期的单体应用系统架构，里面的各个模块互相调用、耦合，所有的系统和模块打包在一起，最后组成一个庞大的巨无霸系统。右边是微服务架构，根据服务的粒度和可复用的级别，对服务进行拆分，以独立部署服务的方式，对外提供服务调用。而应用系统也按照用途和场景的不同，依赖这些可复用的服务，进行逻辑组合，构建成自己的业务系统。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgotOV13JL6AQIB7AAQuqpCR5Ns064.png"></p>
<p>通过这样一种方式，系统变得比较简单，复用级别也比较高，同时也解决了前面提出的单体巨无霸的几个重要问题。因为每一个服务或是应用系统，代码都比较简单，所以编译和部署、开发和测试，都比较简单和快速。而且这些服务都是独立维护和部署的，它的代码分支也是独立的，不会和其他的代码分支一起进行管理，减少了代码冲突的可能性。发布的时候，也是每个服务独立发布，只要做好服务的版本控制和接口兼容，应用系统不需要跟随服务一起更新发布。</p>
<p>在微服务体系中，连接数据库的是具体的服务，应用系统不需要自己去连接数据库，只需要调用组合服务，对服务进行编排。所以对数据库的连接也相对比以前更少一些。最主要的是当需要开发新业务的时候，使用这种方式不需要对原有的单体系统进行各种重构和代码修改，只需要开发一个新的业务系统，组合调用现有的微服务，就可以组合出来一个新的产品功能，可以快速开发新产品。</p>
<h1 id="微服务框架"><a href="#微服务框架" class="headerlink" title="微服务框架"></a>微服务框架</h1><h2 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h2><p>Dubbo 是阿里开源的，比较早也比较有影响力的一个分布式微服务框架。如下图所示，在 Dubbo 架构中，最核心的模块有 3 个部分，一个是服务的提供者，一个是服务的消费者，还有一个是服务的注册中心。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13JL6AOLBoAAFOGse3TxA656.png"></p>
<p>服务的提供者顾名思义就是微服务的具体提供者，通过微服务容器对外提供服务。而服务的消费者就是应用系统或是其他的微服务。</p>
<p>应用系统通过组合多个微服务，构成自己的业务逻辑，实现自己的产品功能。具体过程是服务的提供者程序在 Dubbo 的服务容器中启动，服务管理容器向服务注册中心进行注册，声明服务提供者所要提供的接口参数和规范，并且注册自己所在服务器的 IP 地址和端口，如下图所示。</p>
<p>而服务的消费者如果想要调用某个服务，只需依赖服务提供者的接口进行编程。而服务接口通过 Dubbo 框架的代理访问机制，调用 Dubbo 的服务框架客户端，服务框架客户端会根据服务接口声明，去注册中心查找对应的服务提供者启动在哪些服务器上，并且将这个服务器列表返回给客户端。客户端根据某种负载均衡策略，选择某一个服务器通过远程通讯模块发送具体的服务调用请求。</p>
<p>服务调用请求，通过 Dubbo 底层自己的远程通讯模块，也就是 RPC 调用方式，将请求发送到服务的提供者服务器，服务提供者服务器收到请求以后，将该请求发送给服务提供者程序，完成服务的执行，并将服务执行处理结果通过远程调用通讯模块 RPC 返回给服务消费者客户端，服务消费者客户端将结果返回给服务调用程序，从而完成远程服务的调用，获得服务处理的结果。</p>
<p>Dubbo 使用 Java 进行开发，并且通过服务接口的方式对消费者提供服务，所以它的服务调用方式比较简单，可以透明地进行远程微服务调用。服务消费者程序，可以无感知地进行远程微服务调用，对开发者相对比较友好。</p>
<h2 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h2><p>Spring Cloud 微服务框架组件跟 Dubbo 类似，也是由服务的消费者、服务的提供者和注册中心组成。如下图所示，Spring cloud 的服务提供者通过 Spring Boot 启动，然后向服务注册中心 Eureka Server 进行注册，而服务的消费者通过一个 Zuul 网关访问 Eureka Server 进行服务的发现，获得自己想要调用的远程服务对应的服务地址。获得地址以后，通过 HTTP 的方式向远程的服务提供者发起调用请求。服务提供者完成服务处理后，将处理结果通过 HTTP 返回。从而实现了远程的微服务调用。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13XGWAObX2AAO4kBq0A-0497.png"></p>
<p>Spring Cloud 还包含了一组服务调用监控组件，主要是 Hystrix，通过 Hystrix 可以监控服务调用，还在此基础上实现了熔断、降级、超时管理等一系列高可用策略。</p>
<h2 id="微服务的架构策略"><a href="#微服务的架构策略" class="headerlink" title="微服务的架构策略"></a>微服务的架构策略</h2><p>对微服务架构而言，技术现在其实比较成熟。使用什么样的技术去实现一个微服务，本身并没有太多的困难。构建一个微服务架构最困难的还是服务治理，也就是业务划分。策略要点如图所示。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13JL-AbPegAAFtvsEp67I735.png"></p>
<p>一个微服务包含的功能有哪些？服务的边界是什么？服务之间的依赖关系如何？这些关键的问题决定了服务的复用程度，维护的难易程度，开发的便利程度。所以设计微服务架构的时候，首先要关注的是业务，业务要先行，理顺业务模块之间的边界和依赖，做好服务治理和调用依赖管理。</p>
<p>微服务技术是微服务架构的手段，而不是目的。微服务最主要的目的还是实现服务治理——如何划分和管理服务。首先要有独立的功能模块，然后才有分布式的服务。也就是说在软件设计的时候，软件功能模块之间的依赖关系就要清晰、合理、规范、便于维护、便于扩展，便于实现新的功能。服务之间的依赖关系要清晰、参数要简单、耦合关系要少。设计好这样的模块化结构以后，将这些设计好的模块，拆分成独立的微服务进行部署和调用，就可以构建一个良好的微服务系统。如果模块本身就是混乱的、耦合严重的、边界不清晰的、关系复杂的，那么，把它们拆分成独立的微服务进行部署，只会使事情变得更加复杂。</p>
<p>所以进行微服务架构设计之初，就要先做好业务模块的设计和规划。同时，对于那些业务耦合比较严重、逻辑复杂多变的系统，进行微服务重构的时候，也要特别谨慎。如果做不好模块的划分和耦合管理。那么，宁可晚一点进行微服务架构重构，也不要仓促上马，以免最后带来巨大的损失。要使用微服务架构的时候，一定要搞清楚实施微服务的目的究竟是什么，是为了业务复用，是为了开发边界清晰，是为了分布式集群提升性能，还是仅仅想要使用微服务？目的一定要清楚。</p>
<p>跟其他技术不同，微服务具有强业务属性，业务如果本身结构混乱，目标不清晰，仓促使用微服务，可能会使整个系统变得更加复杂和难以控制。所以在使用微服务前，最重要的是要先明确自己的需求：我们到底想用微服务达到什么样的目的？需求清晰了，再去考虑具体的方案和技术。这也是使用大多数技术的时候应有的方法和思路。</p>
<p>如下图所示，最重要的是需求。在日常工作中，我们要根据需求去考虑具体的价值，再根据价值构建我们的设计原则，根据原则寻找最佳实践，最后根据实践去选择最合适的工具。按这样的方式去选择技术做架构设计才是比较成熟和高效的。如果相反，先找到一个工具，然后用工具硬往上套需求，只会导致技术也没用好，业务也没做好，所有人都疲惫不堪，事情变得一团糟，最后还可能反过来怪技术没用。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13JL-AZaBoAABZolkvp1o958.png"></p>
<h1 id="微服务模式"><a href="#微服务模式" class="headerlink" title="微服务模式"></a>微服务模式</h1><h2 id="事件溯源"><a href="#事件溯源" class="headerlink" title="事件溯源"></a>事件溯源</h2><p>第一是事件溯源，因为微服务的调用过程会比较复杂，调用链路可能会比较长。如果某个微服务调用出错，如何进行管理和监控？使用事件溯源这种模式是一种解决办法。</p>
<p>所谓的事件溯源是指将用户的请求处理过程，每一次的状态变化都记录到事件日志中，并按照时间序列进行持久化的存储，也就是说，把所有的变更操作都按日志的方式，按时间化序列进行记录。</p>
<p>使用事件溯源的好处有如下两点。</p>
<p> 可以精确地复现用户的状态变化。</p>
<p>用户执行了哪些操作，使它成为现在这样一种状况，然后通过事件溯源的方式，追溯以往的操作和动作，从而进行复核和审计。当用户投诉的时候，当状态不一致的时候，可以通过事件溯源中的日志进行审计和查找。</p>
<p> 可以有效监控用户的状态变化，并在此基础上实现分布式的事务。</p>
<p>我们传统的事务使用数据库事务进行实现，可以将多个数据库操作统一提交，或者统一回滚，保持数据的一致性，但是在分布式状况下，对数据的操作是分布在多个独立部署的服务进行处理。这个时候就无法使用数据库的事务进行管理。</p>
<p>那么，如何在这种情况下实行分布式系统的事务？</p>
<p>事件溯源是一种办法。因为事件溯源将所有的数据变更都按日志的方式记录起来，所以如果日志不完整，我们就知道事务不完整，可以对事务进行重组或者补偿操作，从而使数据变得一致。</p>
<h2 id="查询与命令职责分离-CQRS"><a href="#查询与命令职责分离-CQRS" class="headerlink" title="查询与命令职责分离 CQRS"></a>查询与命令职责分离 CQRS</h2><p>这种模式在服务接口层面将查询操作（也就是读操作）和命令操作（也就是写操作）隔离开来，在服务层实现读写分离。</p>
<p>使用 CQRS 模式，主要的好处是可以有更清晰的领域模型，根据操作的方式不同，使用不同的领域模型。还可以分别进行读写优化，从而实现更好的性能。</p>
<p>我们知道在读操作中主要使用的优化方式是缓存操作。那么，我们可以将接口层面的查询操作即读操作，尽量多地通过缓存来返回。而写操作也就是命令操作，主要的性能优化方式是使用消息队列。那么，我们可以将数据的更新操作，尽量通过消息队列，通过异步化的方式进行处理，以改善性能。</p>
<p>因为使用 CQRS 查询和命令分离的方式，我们可以在接口层面上使用不同的优化手段。查询操作不会修改数据库，那么所有来自于查询接口的服务，可以统一连接到只读数据库中，防止误操作破坏数据，可以更好地保护数据，同时使用 CQRS，还可以更好地实现刚才的事件溯源机制。因为查询操作是无须进行事件溯源的，所有的事件溯源都可以统一设置在命令服务接口上。</p>
<h2 id="断路器"><a href="#断路器" class="headerlink" title="断路器"></a>断路器</h2><p>使用微服务的时候，你还需要关注一个事情：服务的不可用。</p>
<p>当某个服务实例出现故障的时候，它的响应延迟或者失败率增加的时候，继续调用这个服务实例会导致请求者阻塞。请求阻塞以后会导致资源消耗增加，最后可能会导致请求者也失败和崩溃，进而出现服务的级联崩溃，也就是服务请求者的请求者也失败，最后会导致整个系统全部失败，即雪崩现象。</p>
<p>在这种情况下，可以使用断路器对故障服务进行隔离。断路器有三种状态：关闭、打开、半开。当服务出现故障的时候，通过断路器阻断对故障服务实例的调用，避免它的故障扩散开来。在 Spring Cloud 中可以使用 Hystrix 实现断路器。</p>
<h2 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h2><p>还有一件需要关注的事情是：微服务调用的超时机制如何设置。</p>
<p>如果使用统一的超时设置，那么当下游调用者超时的时候，上游调用者一定也已经超时了，因为服务调用是阻塞的。所以，下游调用的超时一定会反应在上游调用者上。因此在设置超时的时候，要设置上游调用者的超时时间大于下游调用者的超时时间之和，相同的超时设置是没有意义的，如下图所示。</p>
<p><img src="/2021/05/21/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/CgoB5l13TbyALL87AABEVzYnfn8013.png"></p>
<h1 id="微服务最佳实践"><a href="#微服务最佳实践" class="headerlink" title="微服务最佳实践"></a>微服务最佳实践</h1><p>之所以要使用微服务，是因为传统的单体巨无霸系统带来的挑战和困难，包括编译和部署的困难、连接的困难、打包代码冲突的困难，以及复用的困难、新增业务的困难。</p>
<p>而具体的微服务框架基本上都是由三个核心部分组成的：服务的提供者、服务的调用者和服务的注册中心。服务的提供者向注册中心注册自己的服务，而服务的调用者通过注册中心发现服务，并进行远程调用。</p>
<p>另外，很多微服务架构中还包括一个监控者的角色，通过监控者进行服务的管理和流量的控制。</p>
<p>使用微服务最重要的是做好业务的模块化设计，模块之间要低耦合，高聚合，模块之间的依赖关系要清晰简单。只有这样的模块化设计，才能够构建出良好的微服务架构。如果系统本身就是一团遭，强行将它们拆分在不同的微服务里，只会使系统变得更加混乱。</p>
<p>使用微服务的时候，有几个重要的使用模式，需要关注：一个是事件溯源，一个是命令与查询隔离，还有一个是断路器以及关于超时如何进行设置。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">162</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
