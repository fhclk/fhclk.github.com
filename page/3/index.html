<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="拾荒者">
<meta property="og:url" content="http://fhclk.github.io/page/3/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="fhclk">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fhclk.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/26/HBase%E8%BF%9B%E9%98%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/26/HBase%E8%BF%9B%E9%98%B6/" class="post-title-link" itemprop="url">HBase进阶</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-26 20:11:21" itemprop="dateCreated datePublished" datetime="2022-02-26T20:11:21+08:00">2022-02-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-04 15:46:19" itemprop="dateModified" datetime="2023-01-04T15:46:19+08:00">2023-01-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Master架构"><a href="#Master架构" class="headerlink" title="Master架构"></a>Master架构</h1><p><img src="/2022/02/26/HBase%E8%BF%9B%E9%98%B6/image-20221227113711659.png" alt="image-20221227113711659"></p>
<p>Master，主要进程，具体实现类为HMaster，通常部署在namenode上。</p>
<h2 id="Meta表格介绍"><a href="#Meta表格介绍" class="headerlink" title="Meta表格介绍"></a>Meta表格介绍</h2><p><strong>禁止修改此表</strong></p>
<p>全称 hbase：meta，只是在 list 命令中被过滤掉了，本质上和 HBase 的其他表格一样。</p>
<p>RowKey：</p>
<p>([table],[region start key],[region id]) 即 表名，region 起始位置和 regionID。</p>
<p>列：</p>
<p>info：regioninfo 为 region 信息，存储一个 HRegionInfo 对象。</p>
<p>info：server 当前 region 所处的 RegionServer 信息，包含端口号。</p>
<p>info：serverstartcode 当前 region 被分到 RegionServer 的起始时间。</p>
<p>如果一个表处于切分的过程中，即 region 切分，还会多出两列 info：splitA 和 info：splitB，存储值也是 HRegionInfo 对象，拆分结束后，删除这两列。</p>
<p>注意：在客户端对元数据进行操作的时候才会连接 master，如果对数据进行读写，直接连接zookeeper 读取目录&#x2F;hbase&#x2F;meta-region-server 节点信息，会记录 meta 表格的位置。直接读取即可，不需要访问 master，这样可以减轻 master 的压力，相当于 master 专注 meta 表的写操作，客户端可直接读取 meta 表。</p>
<p>在 HBase 的 2.3 版本更新了一种新模式：Master Registry。客户端可以访问 master 来读取meta 表信息。加大了 master 的压力，减轻了 zookeeper 的压力。</p>
<h2 id="RegionServer架构"><a href="#RegionServer架构" class="headerlink" title="RegionServer架构"></a>RegionServer架构</h2><p><img src="/2022/02/26/HBase%E8%BF%9B%E9%98%B6/image-20221227115325700.png" alt="image-20221227115325700"></p>
<p>Region Server，主要进程，具体实现类为HRegionServer，通常部署在dataNode上。</p>
<h3 id="MemStore"><a href="#MemStore" class="headerlink" title="MemStore"></a>MemStore</h3><p>写缓存，由于 HFile 中的数据要求是有序的，所以数据是先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到 HFile，每次刷写都会形成一个新的 HFile，写入到对应的文件夹 store 中。 </p>
<h3 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h3><p>由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入 MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</p>
<h3 id="BlockCache"><a href="#BlockCache" class="headerlink" title="BlockCache"></a>BlockCache</h3><p>读缓存，每次查询出的数据会缓存在 BlockCache 中，方便下次查询。</p>
<h2 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h2><p><img src="/2022/02/26/HBase%E8%BF%9B%E9%98%B6/image-20221227115624551.png" alt="image-20221227115624551"></p>
<p>写流程从客户端创建连接开始，到最终刷写落盘到HDFS上结束。</p>
<p>写流程顺序正如 API 编写顺序，首先创建 HBase 的重量级连接</p>
<p>（1）首先访问 zookeeper，获取 hbase:meta 表位于哪个 Region Server；</p>
<p>（2）访问对应的 Region Server，获取 hbase:meta 表，将其缓存到连接中，作为连接属性 MetaCache，由于 Meta 表格具有一定的数据量，导致了创建连接比较慢；之后使用创建的连接获取 Table，这是一个轻量级的连接，只有在第一次创建的时候会检查表格是否存在访问 RegionServer，之后在获取 Table 时不会访问 RegionServer；</p>
<p>（3）调用Table的put方法写入数据，此时还需要解析RowKey，对照缓存的MetaCache，查看具体写入的位置有哪个 RegionServer；</p>
<p>（4）将数据顺序写入（追加）到 WAL，此处写入是直接落盘的，并设置专门的线程控制 WAL 预写日志的滚动（类似 Flume）；</p>
<p>（5）根据写入命令的 RowKey 和 ColumnFamily 查看具体写入到哪个 MemStory，并且在 MemStory 中排序；</p>
<p>（6）向客户端发送 ack；</p>
<p>（7 ）等达到 MemStore 的刷写时机后，将数据刷写到对应的 store 中。</p>
<h2 id="MemStore-Flush"><a href="#MemStore-Flush" class="headerlink" title="MemStore Flush"></a>MemStore Flush</h2><p><strong>MemStore 刷写由多个线程控制，条件互相独立：</strong></p>
<p>主要的刷写规则是控制刷写文件的大小，在每一个刷写线程中都会进行监控</p>
<p>（1）当某个 memstroe 的大小达到了 hbase.hregion.memstore.flush.size（默认值 128M），其所在 region 的所有 memstore 都会刷写。</p>
<p>当 memstore 的大小达到了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase.hregion.memstore.flush.size（默认值 128M）</span><br><span class="line">hbase.hregion.memstore.block.multiplier（默认值 4）</span><br></pre></td></tr></table></figure>

<p>时，会刷写同时阻止继续往该 memstore 写数据（由于线程监控是周期性的，所有有可能面对数据洪峰，尽管可能性比较小）</p>
<p>（2）由 HRegionServer 中的属性 MemStoreFlusher 内部线程 FlushHandler 控制。标准为LOWER_MARK（低水位线）和 HIGH_MARK（高水位线），意义在于避免写缓存使用过多的内存造成 OOM。</p>
<p>当 region server 中 memstore 的总大小达到低水位线</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java_heapsize</span><br><span class="line">hbase.regionserver.global.memstore.size（默认值 0.4）</span><br><span class="line">hbase.regionserver.global.memstore.size.lower.limit（默认值 0.95），</span><br></pre></td></tr></table></figure>

<p>region 会按照其所有 memstore 的大小顺序（由大到小）依次进行刷写。直到 region server中所有 memstore 的总大小减小到上述值以下。</p>
<p>当 region server 中 memstore 的总大小达到高水位线</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java_heapsize</span><br><span class="line">hbase.regionserver.global.memstore.size（默认值 0.4）</span><br></pre></td></tr></table></figure>

<p>时，会同时阻止继续往所有的 memstore 写数据。</p>
<p>（3）为了避免数据过长时间处于内存之中，到达自动刷写的时间，也会触发 memstore flush。由 HRegionServer 的属性 PeriodicMemStoreFlusher 控制进行，由于重要性比较低，5min才会执行一次。</p>
<p>自动刷新的时间间隔由该属性进行配置 hbase.regionserver.optionalcacheflushinterval（默认1 小时）。</p>
<p>（4）当 WAL 文件的数量超过 hbase.regionserver.max.logs，region 会按照时间顺序依次进行刷写，直到 WAL 文件数量减小到 hbase.regionserver.max.log 以下（该属性名已经废弃，现无需手动设置，最大值为 32）。</p>
<h2 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h2><h3 id="HFile结构"><a href="#HFile结构" class="headerlink" title="HFile结构"></a>HFile结构</h3><p>在了解读流程之前，需要先知道读取的数据是什么样子的。</p>
<p>HFile 是存储在 HDFS 上面每一个 store 文件夹下实际存储数据的文件。里面存储多种内容。包括数据本身（keyValue 键值对）、元数据记录、文件信息、数据索引、元数据索引和一个固定长度的尾部信息（记录文件的修改情况）。</p>
<p>键值对按照块大小（默认 64K）保存在文件中，数据索引按照块创建，块越多，索引越大。每一个 HFile 还会维护一个布隆过滤器（就像是一个很大的地图，文件中每有一种 key，就在对应的位置标记，读取时可以大致判断要 get 的 key 是否存在 HFile 中）。</p>
<p>KeyValue 内容如下:</p>
<p>rowlength ———–→ key 的长度</p>
<p>row —————–→ key 的值</p>
<p>columnfamilylength –→ 列族长度</p>
<p>columnfamily ——–→ 列族</p>
<p>columnqualifier —–→ 列名</p>
<p>timestamp ———–→ 时间戳（默认系统时间）</p>
<p>keytype ————-→ Put</p>
<p>由于 HFile 存储经过序列化，所以无法直接查看。可以通过 HBase 提供的命令来查看存储在 HDFS 上面的 HFile 元数据内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 hbase]$ bin/hbase hfile -m -f /hbase/data/命名空间/表名/regionID/列族/HFile名</span><br></pre></td></tr></table></figure>

<h3 id="读流程-1"><a href="#读流程-1" class="headerlink" title="读流程"></a>读流程</h3><p><img src="/2022/02/26/HBase%E8%BF%9B%E9%98%B6/image-20221227164519768.png" alt="image-20221227164519768"></p>
<p>写流程从客户端创建连接开始，到合并数据并返回客户端结束。</p>
<p>创建连接同写流程。</p>
<p>（1）创建 Table 对象发送 get 请求。</p>
<p>（2）优先访问 Block Cache，查找是否之前读取过，并且可以读取 HFile 的索引信息和布隆过滤器。</p>
<p>（3）不管读缓存中是否已经有数据了（可能已经过期了），都需要再次读取写缓存和store 中的文件。</p>
<p>（4）最终将所有读取到的数据合并版本，按照 get 的要求返回即可。</p>
<h3 id="合并读取数据优化"><a href="#合并读取数据优化" class="headerlink" title="合并读取数据优化"></a>合并读取数据优化</h3><p>每次读取数据都需要读取三个位置，最后进行版本的合并。效率会非常低，所有系统需要对此优化。</p>
<p>（1）HFile 带有索引文件，读取对应 RowKey 数据会比较快。</p>
<p>（2）Block Cache 会缓存之前读取的内容和元数据信息，如果 HFile 没有发生变化（记录在 HFile 尾信息中），则不需要再次读取。</p>
<p>（3）使用布隆过滤器能够快速过滤当前 HFile 不存在需要读取的 RowKey，从而避免读取文件。（布隆过滤器使用 HASH 算法，不是绝对准确的，出错会造成多扫描一个文件，对读取数据结果没有影响）</p>
<h2 id="StoreFile-Compaction"><a href="#StoreFile-Compaction" class="headerlink" title="StoreFile Compaction"></a>StoreFile Compaction</h2><p>由于 memstore 每次刷写都会生成一个新的 HFile，文件过多读取不方便，所以会进行文件的合并，清理掉过期和删除的数据，会进行 StoreFile Compaction。</p>
<p>Compaction 分为两种，分别是 Minor Compaction 和 Major Compaction。Minor Compaction会将临近的若干个较小的 HFile 合并成一个较大的 HFile，并清理掉部分过期和删除的数据，有系统使用一组参数自动控制，Major Compaction 会将一个 Store 下的所有的 HFile 合并成一个大 HFile，并且<strong>会</strong>清理掉所有过期和删除的数据，由参数 hbase.hregion.majorcompaction控制，默认 7 天。</p>
<p><img src="/2022/02/26/HBase%E8%BF%9B%E9%98%B6/image-20221227164743255.png" alt="image-20221227164743255"></p>
<p>Minor Compaction 控制机制：</p>
<p>参与到小合并的文件需要通过参数计算得到，有效的参数有 5 个</p>
<p>（1）hbase.hstore.compaction.ratio（默认 1.2F）合并文件选择算法中使用的比率。</p>
<p>（2）hbase.hstore.compaction.min（默认 3） 为 Minor Compaction 的最少文件个数。</p>
<p>（3）hbase.hstore.compaction.max（默认 10） 为 Minor Compaction 最大文件个数。</p>
<p>（4）hbase.hstore.compaction.min.size（默认 128M）为单个 Hfile 文件大小最小值，小于这个数会被合并。</p>
<p>（5）hbase.hstore.compaction.max.size（默认 Long.MAX_VALUE）为单个 Hfile 文件大小最大值，高于这个数不会被合并。小合并机制为拉取整个 store 中的所有文件，做成一个集合。之后按照从旧到新的顺序遍历。</p>
<p>判断条件为：</p>
<p><strong>①</strong> 过小合并，过大不合并</p>
<p><strong>②</strong> 文件大小&#x2F; hbase.hstore.compaction.ratio &lt; (剩余文件大小和) 则参与压缩。所有把比值设置过大，如 10 会最终合并为 1 个特别大的文件，相反设置为 0.4，会最终产生 4 个 storeFile。不建议修改默认值</p>
<p><strong>③</strong> 满足压缩条件的文件个数达不到个数要求（3 &lt;&#x3D; count &lt;&#x3D; 10）则不压缩。</p>
<h2 id="Region-Split"><a href="#Region-Split" class="headerlink" title="Region Split"></a>Region Split</h2><p>Region 切分分为两种，创建表格时候的预分区即自定义分区，同时系统默认还会启动一个切分规则，避免单个 Region 中的数据量太大。</p>
<h3 id="预分区（自定义分区）"><a href="#预分区（自定义分区）" class="headerlink" title="预分区（自定义分区）"></a>预分区（自定义分区）</h3><p>每一个 region 维护着 startRow 与 endRowKey，如果加入的数据符合某个 region 维护的rowKey 范围，则该数据交给这个 region 维护。那么依照这个原则，我们可以将数据所要投放的分区提前大致的规划好，以提高 HBase 性能。</p>
<h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>Region 的拆分是由 HRegionServer 完成的，在操作之前需要通过 ZK 汇报 master，修改对应的 Meta 表信息添加两列 info：splitA 和 info：splitB 信息。之后需要操作 HDFS 上面对应的文件，按照拆分后的 Region 范围进行标记区分，实际操作为创建文件引用，不会挪动数据。刚完成拆分的时候，两个 Region 都由原先的 RegionServer 管理。之后汇报给 Master，由Master将修改后的信息写入到Meta表中。等待下一次触发负载均衡机制，才会修改Region的管理服务者，而数据要等到下一次压缩时，才会实际进行移动。</p>
<p>不管是否使用预分区，系统都会默认启动一套 Region 拆分规则。不同版本的拆分规则有差别。系统拆分策略的父类为 RegionSplitPolicy。</p>
<p>0.94 版本之前 &#x3D;&gt; ConstantSizeRegionSplitPolicy</p>
<p>（ 1 ） 当 1 个 region 中 的 某 个 Store 下 所 有 StoreFile 的 总 大 小 超 过hbase.hregion.max.filesize （10G），该 Region 就会进行拆分。0.94 版本之后，2.0 版本之前 &#x3D;&gt; IncreasingToUpperBoundRegionSplitPolicy</p>
<p>（ 2 ） 当 1 个 region 中 的 某 个 Store 下 所 有 StoreFile 的 总 大 小 超 过Min(initialSize<em>R^3 ,hbase.hregion.max.filesize”)，该 Region 就会进行拆分。其中 initialSize 的默认值为 2</em>hbase.hregion.memstore.flush.size，R 为当前 Region Server 中属于该 Table 的Region 个数（0.94 版本之后）。</p>
<p>具体的切分策略为：</p>
<p>第一次 split：1^3 * 256 &#x3D; 256MB </p>
<p>第二次 split：2^3 * 256 &#x3D; 2048MB </p>
<p>第三次 split：3^3 * 256 &#x3D; 6912MB </p>
<p>第四次 split：4^3 * 256 &#x3D; 16384MB &gt; 10GB，因此取较小的值 10GB </p>
<p>后面每次 split 的 size 都是 10GB 了。</p>
<p>2.0 版本之后 &#x3D;&gt; SteppingSplitPolicy</p>
<p>（3）Hbase 2.0 引入了新的 split 策略：如果当前 RegionServer 上该表只有一个 Region，按照 2 * hbase.hregion.memstore.flush.size 分裂，否则按照 hbase.hregion.max.filesize 分裂。这叫大道至简，学海抽丝。</p>
<h1 id="HBase优化"><a href="#HBase优化" class="headerlink" title="HBase优化"></a>HBase优化</h1><h2 id="RowKey设计优化"><a href="#RowKey设计优化" class="headerlink" title="RowKey设计优化"></a>RowKey设计优化</h2><p>一条数据的唯一标识就是 rowkey，那么这条数据存储于哪个分区，取决于 rowkey 处于哪个一个预分区的区间内，设计 rowkey的主要目的 ，就是让数据均匀的分布于所有的 region中，在一定程度上防止数据倾斜。接下来我们就谈一谈 rowkey 常用的设计方案。</p>
<p>1）生成随机数、hash、散列值</p>
<p>2）时间戳反转</p>
<p>3）字符串拼接 </p>
<h2 id="添加预分区优化"><a href="#添加预分区优化" class="headerlink" title="添加预分区优化"></a>添加预分区优化</h2><p>预分区的分区号同样需要遵守 rowKey 的 scan 原则。所有必须添加在 rowKey 的最前面，前缀为最简单的数字。同时使用 hash 算法将用户名和月份拼接决定分区号。（单独使用用户名会造成单一用户所有数据存储在一个分区）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">添加预分区优化</span><br><span class="line">startKey stopKey</span><br><span class="line">001</span><br><span class="line">001 002</span><br><span class="line">002 003</span><br><span class="line">...</span><br><span class="line">119 120</span><br><span class="line">分区号=&gt; hash(user+date(MM)) % 120</span><br><span class="line">分区号填充 如果得到 1 =&gt; 001</span><br><span class="line">rowKey 设计格式 =&gt; 分区号 date(yyyy-MM)^A^Auserdate(-dd hh:mm:ss ms)</span><br></pre></td></tr></table></figure>

<h2 id="参数优化"><a href="#参数优化" class="headerlink" title="参数优化"></a>参数优化</h2><h3 id="Zookeeper-会话超时时间"><a href="#Zookeeper-会话超时时间" class="headerlink" title="Zookeeper 会话超时时间"></a>Zookeeper 会话超时时间</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">属性：zookeeper.session.timeout</span><br><span class="line">解释：默认值为 90000 毫秒（90s）。当某个 RegionServer 挂掉，90s 之后 Master 才能察觉到。可适当减小此值，尽可能快地检测 regionserver 故障，可调整至 20-30s。</span><br><span class="line">看你能有都能忍耐超时，同时可以调整重试时间和重试次数</span><br><span class="line">hbase.client.pause（默认值 100ms）</span><br><span class="line">hbase.client.retries.number（默认 15 次）</span><br></pre></td></tr></table></figure>

<h3 id="设置-RPC-监听数量"><a href="#设置-RPC-监听数量" class="headerlink" title="设置 RPC 监听数量"></a>设置 RPC 监听数量</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hbase.regionserver.handler.count</span><br><span class="line">解释：默认值为 30，用于指定 RPC 监听的数量，可以根据客户端的请求数进行调整，读写请求较多时，增加此值。</span><br></pre></td></tr></table></figure>

<h3 id="手动控制-Major-Compaction"><a href="#手动控制-Major-Compaction" class="headerlink" title="手动控制 Major Compaction"></a>手动控制 Major Compaction</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hbase.hregion.majorcompaction</span><br><span class="line">解释：默认值：604800000 秒（7 天）， Major Compaction 的周期，若关闭自动 Major Compaction，可将其设为 0。如果关闭一定记得自己手动合并，因为大合并非常有意义</span><br></pre></td></tr></table></figure>

<h3 id="优化-HStore-文件大小"><a href="#优化-HStore-文件大小" class="headerlink" title="优化 HStore 文件大小"></a>优化 HStore 文件大小</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hbase.hregion.max.filesize</span><br><span class="line">解释：默认值 10737418240（10GB），如果需要运行 HBase 的 MR 任务，可以减小此值，因为一个 region 对应一个 map 任务，如果单个 region 过大，会导致 map 任务执行时间过长。该值的意思就是，如果 HFile 的大小达到这个数值，则这个 region 会被切分为两个 Hfile。</span><br></pre></td></tr></table></figure>

<h3 id="优化-HBase-客户端缓存"><a href="#优化-HBase-客户端缓存" class="headerlink" title="优化 HBase 客户端缓存"></a>优化 HBase 客户端缓存</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hbase.client.write.buffer</span><br><span class="line">解释：默认值 2097152bytes（2M）用于指定 HBase 客户端缓存，增大该值可以减少 RPC调用次数，但是会消耗更多内存，反之则反之。一般我们需要设定一定的缓存大小，以达到减少 RPC 次数的目的。</span><br></pre></td></tr></table></figure>

<h3 id="指定-scan-next-扫描-HBase-所获取的行数"><a href="#指定-scan-next-扫描-HBase-所获取的行数" class="headerlink" title="指定 scan.next 扫描 HBase 所获取的行数"></a>指定 scan.next 扫描 HBase 所获取的行数</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hbase.client.scanner.caching</span><br><span class="line">解释：用于指定 scan.next 方法获取的默认行数，值越大，消耗内存越大。</span><br></pre></td></tr></table></figure>

<h3 id="BlockCache-占用-RegionServer-堆内存的比例"><a href="#BlockCache-占用-RegionServer-堆内存的比例" class="headerlink" title="BlockCache 占用 RegionServer 堆内存的比例"></a>BlockCache 占用 RegionServer 堆内存的比例</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hfile.block.cache.size</span><br><span class="line">解释：默认 0.4，读请求比较多的情况下，可适当调大</span><br></pre></td></tr></table></figure>

<h3 id="MemStore-占用-RegionServer-堆内存的比例"><a href="#MemStore-占用-RegionServer-堆内存的比例" class="headerlink" title="MemStore 占用 RegionServer 堆内存的比例"></a>MemStore 占用 RegionServer 堆内存的比例</h3><p>hbase-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">属性：hbase.regionserver.global.memstore.size</span><br><span class="line">解释：默认 0.4，写请求较多的情况下，可适当调大</span><br></pre></td></tr></table></figure>

<p>Lars Hofhansl（拉斯·霍夫汉斯）大神推荐 Region 设置 20G，刷写大小设置 128M，其它默认。</p>
<h2 id="JVM-调优"><a href="#JVM-调优" class="headerlink" title="JVM 调优"></a>JVM 调优</h2><p>JVM 调优的思路有两部分：一是内存设置，二是垃圾回收器设置。</p>
<p>垃圾回收的修改是使用并发垃圾回收，默认 PO+PS 是并行垃圾回收，会有大量的暂停。理由是 HBsae 大量使用内存用于存储数据，容易遭遇数据洪峰造成 OOM，同时写缓存的数据是不能垃圾回收的，主要回收的就是读缓存，而读缓存垃圾回收不影响性能，所以最终设置的效果可以总结为：防患于未然，早洗早轻松。</p>
<h3 id="设置使用-CMS-收集器"><a href="#设置使用-CMS-收集器" class="headerlink" title="设置使用 CMS 收集器"></a>设置使用 CMS 收集器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+UseConcMarkSweepGC</span><br></pre></td></tr></table></figure>

<h3 id="保持新生代尽量小，同时尽早开启GC"><a href="#保持新生代尽量小，同时尽早开启GC" class="headerlink" title="保持新生代尽量小，同时尽早开启GC"></a>保持新生代尽量小，同时尽早开启GC</h3><p>例如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//在内存占用到 70%的时候开启 GC</span><br><span class="line">-XX:CMSInitiatingOccupancyFraction=70</span><br><span class="line">//指定使用 70%，不让 JVM 动态调整</span><br><span class="line">-XX:+UseCMSInitiatingOccupancyOnly</span><br><span class="line">//新生代内存设置为 512m</span><br><span class="line">-Xmn512m</span><br><span class="line">//并行执行新生代垃圾回收</span><br><span class="line">-XX:+UseParNewGC</span><br><span class="line">// 设 置 scanner 扫 描 结 果 占 用 内 存 大 小 ， 在 hbase-site.xml 中，设置</span><br><span class="line">hbase.client.scanner.max.result.size(默认值为 2M)为 eden 空间的 1/8</span><br><span class="line">（大概在 64M）</span><br><span class="line">// 设置多个与 max.result.size * handler.count 相乘的结果小于 Survivor </span><br><span class="line">Space(新生代经过垃圾回收之后存活的对象)</span><br></pre></td></tr></table></figure>



<h1 id="HBase-使用经验法则"><a href="#HBase-使用经验法则" class="headerlink" title="HBase 使用经验法则"></a>HBase 使用经验法则</h1><p>官方给出了权威的使用法则：</p>
<ol>
<li>Region 大小控制 10-50G</li>
<li>cell 大小不超过 10M（性能对应小于 100K 的值有优化），如果使用 mob（Medium sized Objects 一种特殊用法）则不超过 50M。</li>
<li>1 张表有 1 到 3 个列族，不要设计太多。最好就 1 个，如果使用多个尽量保证不会同时读取多个列族。</li>
<li>1 到 2 个列族的表格，设计 50-100 个 Region。</li>
<li>列族名称要尽量短，不要去模仿 RDBMS（关系型数据库）具有准确的名称和描述。</li>
<li>如果 RowKey 设计时间在最前面，会导致有大量的旧数据存储在不活跃的 Region中，使用的时候，仅仅会操作少数的活动 Region，此时建议增加更多的 Region 个数。</li>
<li>如果只有一个列族用于写入数据，分配内存资源的时候可以做出调整，即写缓存不会占用太多的内存。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/24/HBase%E5%AE%9E%E6%93%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/24/HBase%E5%AE%9E%E6%93%8D/" class="post-title-link" itemprop="url">HBase实操</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-24 20:01:22" itemprop="dateCreated datePublished" datetime="2022-02-24T20:01:22+08:00">2022-02-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-04 13:42:44" itemprop="dateModified" datetime="2023-01-04T13:42:44+08:00">2023-01-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="HBase安装部署"><a href="#HBase安装部署" class="headerlink" title="HBase安装部署"></a>HBase安装部署</h1><h2 id="Hadoop部署"><a href="#Hadoop部署" class="headerlink" title="Hadoop部署"></a>Hadoop部署</h2><p>安装部署Hadoop，并启动</p>
<h2 id="Zookeeper部署"><a href="#Zookeeper部署" class="headerlink" title="Zookeeper部署"></a>Zookeeper部署</h2><p>安装部署Zookeeper，并启动</p>
<h2 id="HBase部署"><a href="#HBase部署" class="headerlink" title="HBase部署"></a>HBase部署</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ol>
<li><p>解压HBase</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 server]# tar -zxvf hbase-2.5.2-bin.tar.gz </span><br></pre></td></tr></table></figure>


</li>
<li><p>配置环境变量</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 server]# vim /etc/profile</span><br></pre></td></tr></table></figure>

<p>在文件末尾添加</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_HOME=/export/server/hbase-2.5.2</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure>

<p>使环境变量生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 server]# source /etc/profile</span><br></pre></td></tr></table></figure>



<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol>
<li><p>编辑hbase-2.5.2&#x2F;conf下的hbase-env.sh文件，末尾添加</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241/</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure>


</li>
<li><p>编辑hbase-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- HBase数据在HDFS中的存放的路径 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1.itcast.cn:8020/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- ZooKeeper的地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1.itcast.cn,node2.itcast.cn,node3.itcast.cn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- ZooKeeper快照的存储位置 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/server/zookeeper-3.7.1/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  V2.1版本，在分布式情况下, 设置为false --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.unsafe.stream.capability.enforce<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>修改regionservers ，<code>vim regionservers </code></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">node1.itcast.cn</span></span><br><span class="line"><span class="attr">node2.itcast.cn</span></span><br><span class="line"><span class="attr">node3.itcast.cn</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>解决 HBase 和 Hadoop 的 log4j 兼容性问题，修改 HBase 的 jar 包，使用 Hadoop 的 jar 包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 conf]# mv /export/server/hbase-2.5.2/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar /export/server/hbase-2.5.2/lib/client-facing-thirdparty/slf4j-api-1.7.33.jar.bak</span><br></pre></td></tr></table></figure>
</li>
<li><p>发送到其他服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 server]# scp -r ./hbase-2.5.2/ root@node2:/export/server/</span><br><span class="line">(base) [root@node1 server]# scp -r ./hbase-2.5.2/ root@node3:/export/server/</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动HBase</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动zookeeper</span></span><br><span class="line">(base) [root@node1 ~]# ./bin/zk.sh start</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动hdfs</span></span><br><span class="line">(base) [root@node1 ~]# start-dfs.sh</span><br><span class="line">(base) [root@node1 ~]# start-hbase.sh</span><br></pre></td></tr></table></figure>


</li>
<li><p>验证是否启动成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 logs]# hbase shell</span><br><span class="line">SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line">SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.</span><br><span class="line">SLF4J: Failed to load class &quot;org.slf4j.impl.StaticMDCBinder&quot;.</span><br><span class="line">SLF4J: Defaulting to no-operation MDCAdapter implementation.</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details.</span><br><span class="line">HBase Shell</span><br><span class="line">Use &quot;help&quot; to get list of supported commands.</span><br><span class="line">Use &quot;exit&quot; to quit this interactive shell.</span><br><span class="line">For Reference, please visit: http://hbase.apache.org/2.0/book.html#shell</span><br><span class="line">Version 2.5.2, r3e28acf0b819f4b4a1ada2b98d59e05b0ef94f96, Thu Nov 24 02:06:40 UTC 2022</span><br><span class="line">Took 0.0015 seconds                                                                                                                                                                       </span><br><span class="line">hbase:001:0&gt; </span><br></pre></td></tr></table></figure>
</li>
<li><p>打开web查看</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://node1.itcast.cn:16010/master-status</span><br></pre></td></tr></table></figure></li>
</ol>
<p>注意：</p>
<p>如果在启动时，日志文件中报如下错误（原因是hbase和Hadoop有冲突包）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">2022-12-26 17:28:44,670 ERROR [RS-EventLoopGroup-1-2] util.NettyFutureUtils (NettyFutureUtils.java:lambda$addListener$0(58)) - Unexpected error caught when processing netty</span><br><span class="line">java.lang.IllegalArgumentException: object is not an instance of declaring class</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.ProtobufDecoder.&lt;init&gt;(ProtobufDecoder.java:64)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.processWriteBlockResponse(FanOutOneBlockAsyncDFSOutputHelper.java:348)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.access$100(FanOutOneBlockAsyncDFSOutputHelper.java:120)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper$4.operationComplete(FanOutOneBlockAsyncDFSOutputHelper.java:430)</span><br><span class="line">        at org.apache.hadoop.hbase.util.NettyFutureUtils.lambda$addListener$0(NettyFutureUtils.java:56)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:184)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:35)</span><br><span class="line">        at org.apache.hadoop.hbase.util.NettyFutureUtils.addListener(NettyFutureUtils.java:52)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.initialize(FanOutOneBlockAsyncDFSOutputHelper.java:424)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper.access$300(FanOutOneBlockAsyncDFSOutputHelper.java:120)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper$5.operationComplete(FanOutOneBlockAsyncDFSOutputHelper.java:482)</span><br><span class="line">        at org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper$5.operationComplete(FanOutOneBlockAsyncDFSOutputHelper.java:477)</span><br><span class="line">        at org.apache.hadoop.hbase.util.NettyFutureUtils.lambda$addListener$0(NettyFutureUtils.java:56)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.fulfillConnectPromise(AbstractEpollChannel.java:653)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:691)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:489)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:397)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)</span><br><span class="line">        at org.apache.hbase.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure>

<p>解决方法：将hadoop下的slf4j*.jar拷贝到hbase下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node2 client-facing-thirdparty]#  cp /export/server/hadoop-3.3.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar /export/server/hbase-2.5.2/lib/client-facing-thirdparty/</span><br></pre></td></tr></table></figure>

<p>修改hbase-env.sh文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">export</span> <span class="string">HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP=&quot;true&quot;</span></span><br></pre></td></tr></table></figure>

<p>重启hbase</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# stop-hbase.sh</span><br><span class="line">(base) [root@node1 ~]# start-hbase.sh</span><br></pre></td></tr></table></figure>



<h1 id="HBase-Shell操作"><a href="#HBase-Shell操作" class="headerlink" title="HBase Shell操作"></a>HBase Shell操作</h1><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><h3 id="进入-HBase-客户端命令行"><a href="#进入-HBase-客户端命令行" class="headerlink" title="进入 HBase 客户端命令行"></a>进入 HBase 客户端命令行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# hbase shell</span><br></pre></td></tr></table></figure>

<h3 id="查看帮助命令"><a href="#查看帮助命令" class="headerlink" title="查看帮助命令"></a>查看帮助命令</h3><p>能够展示 HBase 中所有能使用的命令，主要使用的命令有 namespace 命令空间相关，DDL 创建修改表格，DML 写入读取数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hbase:006:0&gt; help</span><br><span class="line">hbase:008:0&gt; help &#x27;create_namespace&#x27;</span><br><span class="line">Create namespace; pass namespace name,</span><br><span class="line">and optionally a dictionary of namespace configuration.</span><br><span class="line">Examples:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">  hbase&gt; </span><span class="language-bash">create_namespace <span class="string">&#x27;ns1&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">  hbase&gt; </span><span class="language-bash">create_namespace <span class="string">&#x27;ns1&#x27;</span>, &#123;<span class="string">&#x27;PROPERTY_NAME&#x27;</span>=&gt;<span class="string">&#x27;PROPERTY_VALUE&#x27;</span>&#125;</span></span><br></pre></td></tr></table></figure>

<h2 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h2><h3 id="创建命名空间"><a href="#创建命名空间" class="headerlink" title="创建命名空间"></a>创建命名空间</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase:011:0&gt; create_namespace &#x27;bigdata&#x27;</span><br><span class="line">Took 0.1728 seconds</span><br></pre></td></tr></table></figure>

<h3 id="查看所有命名空间"><a href="#查看所有命名空间" class="headerlink" title="查看所有命名空间"></a>查看所有命名空间</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hbase:012:0&gt; list_namespace</span><br><span class="line">NAMESPACE                                                                    </span><br><span class="line">bigdata                                                                                 </span><br><span class="line">default                                                                                 </span><br><span class="line">hbase                                                                           </span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.0370 seconds </span><br></pre></td></tr></table></figure>

<h2 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h2><h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><p>在 bigdata 命名空间中创建表格 student，两个列族。info 列族数据维护的版本数为 5 个，如果不写默认版本数为 1。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hbase:017:0&gt; create &#x27;bigdata:student&#x27;, &#123;NAME =&gt; &#x27;info&#x27;, VERSIONS =&gt; 5&#125;, &#123;NAME =&gt; &#x27;msg&#x27;&#125;</span><br><span class="line">Created table bigdata:student</span><br><span class="line">Took 0.6948 seconds                                                                                                                                                                       </span><br><span class="line">=&gt; Hbase::Table - bigdata:student</span><br></pre></td></tr></table></figure>

<p>如果创建表格只有一个列族，没有列族属性，可以简写。</p>
<p>如果不写命名空间，使用默认的命名空间 default。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hbase:019:0&gt; create &#x27;student1&#x27;,&#x27;info&#x27;</span><br><span class="line">Created table student1</span><br><span class="line">Took 0.6286 seconds                                                                                                                                                                       </span><br><span class="line">=&gt; Hbase::Table - student1</span><br></pre></td></tr></table></figure>

<p><strong>HBase列蔟的数量应该越少越好</strong></p>
<ul>
<li><p>两个及以上的列蔟HBase性能并不是很好</p>
</li>
<li><p>一个列蔟所存储的数据达到flush的阈值时，表中所有列蔟将同时进行flush操作</p>
</li>
<li><p>这将带来不必要的I&#x2F;O开销，列蔟越多，对性能影响越大</p>
</li>
</ul>
<h3 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h3><p>查看表有两个命令：list 和 describe</p>
<p><strong>list</strong></p>
<p>查看所有的表名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hbase:020:0&gt; list</span><br><span class="line">TABLE                                                                            </span><br><span class="line">bigdata:student                                                                                     </span><br><span class="line">student1                                                                           </span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0113 seconds                                                                                                                                                                       </span><br><span class="line">=&gt; [&quot;bigdata:student&quot;, &quot;student1&quot;]</span><br></pre></td></tr></table></figure>

<p><strong>describe</strong></p>
<p>查看一个表的详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase:023:0&gt; describe &#x27;student1&#x27;</span><br><span class="line">Table student1 is ENABLED                                                                            </span><br><span class="line">student1, &#123;TABLE_ATTRIBUTES =&gt; &#123;METADATA =&gt; &#123;&#x27;hbase.store.file-tracker.impl&#x27; =&gt; &#x27;DEFAULT&#x27;&#125;&#125;&#125;        </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                                     </span><br><span class="line">&#123;NAME =&gt; &#x27;info&#x27;, INDEX_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, VERSIONS =&gt; &#x27;1&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, REPLICATION_SCOPE =</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="string">&#x27;0&#x27;</span>, BLOOMFILTER =&gt; <span class="string">&#x27;ROW&#x27;</span>, IN_MEMORY =&gt; <span class="string">&#x27;false&#x27;</span>, COMPRESSION =&gt; <span class="string">&#x27;NONE&#x27;</span>, BLOCKCACHE =&gt; <span class="string">&#x27;true&#x27;</span>, BLOCKSIZE =&gt; <span class="string">&#x27;65536 B (64KB)&#x27;</span>&#125;</span>                                                            </span><br><span class="line"></span><br><span class="line">1 row(s)</span><br><span class="line">Quota is disabled</span><br><span class="line">Took 0.1416 seconds</span><br></pre></td></tr></table></figure>

<h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><p>表名创建时写的所有和列族相关的信息，都可以后续通过 alter 修改，包括增加删除列族。</p>
<p>（1）增加列族和修改信息都使用覆盖的方法</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hbase:026:0&gt; alter &#x27;student1&#x27;, &#123;NAME =&gt; &#x27;f1&#x27;, VERSIONS =&gt; 3&#125;</span><br><span class="line">Updating all regions with the new schema...</span><br><span class="line">1/1 regions updated.</span><br><span class="line">Done.</span><br><span class="line">Took 2.6222 seconds                                                                                                                                                                       </span><br><span class="line">hbase:028:0&gt; describe &#x27;student1&#x27;</span><br><span class="line">Table student1 is ENABLED                                                                </span><br><span class="line">student1, &#123;TABLE_ATTRIBUTES =&gt; &#123;METADATA =&gt; &#123;&#x27;hbase.store.file-tracker.impl&#x27; =&gt; &#x27;DEFAULT&#x27;&#125;&#125;&#125;          </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                                     </span><br><span class="line">&#123;NAME =&gt; &#x27;f1&#x27;, INDEX_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, VERSIONS =&gt; &#x27;3&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, REPLICATION_SCOPE =&gt; </span><br><span class="line">&#x27;0&#x27;, BLOOMFILTER =&gt; &#x27;ROW&#x27;, IN_MEMORY =&gt; &#x27;false&#x27;, COMPRESSION =&gt; &#x27;NONE&#x27;, BLOCKCACHE =&gt; &#x27;true&#x27;, BLOCKSIZE =&gt; &#x27;65536 B (64KB)&#x27;&#125;                                                              </span><br><span class="line"></span><br><span class="line">&#123;NAME =&gt; &#x27;info&#x27;, INDEX_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, VERSIONS =&gt; &#x27;1&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, REPLICATION_SCOPE =</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="string">&#x27;0&#x27;</span>, BLOOMFILTER =&gt; <span class="string">&#x27;ROW&#x27;</span>, IN_MEMORY =&gt; <span class="string">&#x27;false&#x27;</span>, COMPRESSION =&gt; <span class="string">&#x27;NONE&#x27;</span>, BLOCKCACHE =&gt; <span class="string">&#x27;true&#x27;</span>, BLOCKSIZE =&gt; <span class="string">&#x27;65536 B (64KB)&#x27;</span>&#125;</span>                                                            </span><br><span class="line"></span><br><span class="line">2 row(s)</span><br><span class="line">Quota is disabled</span><br><span class="line">Took 0.0401 seconds </span><br></pre></td></tr></table></figure>

<p>（2）删除信息使用特殊的语法</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方式1</span></span><br><span class="line">hbase:032:0&gt; alter &#x27;student1&#x27;, NAME =&gt; &#x27;f1&#x27;, METHOD =&gt; &#x27;delete&#x27;</span><br><span class="line">Updating all regions with the new schema...</span><br><span class="line">1/1 regions updated.</span><br><span class="line">Done.</span><br><span class="line">Took 1.7268 seconds                                                                                                                                                                       </span><br><span class="line">hbase:033:0&gt; describe &#x27;student1&#x27;</span><br><span class="line">Table student1 is ENABLED                                                                               </span><br><span class="line">student1, &#123;TABLE_ATTRIBUTES =&gt; &#123;METADATA =&gt; &#123;&#x27;hbase.store.file-tracker.impl&#x27; =&gt; &#x27;DEFAULT&#x27;&#125;&#125;&#125;         </span><br><span class="line">COLUMN FAMILIES DESCRIPTION                                                                                                                                                               </span><br><span class="line">&#123;NAME =&gt; &#x27;info&#x27;, INDEX_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, VERSIONS =&gt; &#x27;1&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, REPLICATION_SCOPE =</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="string">&#x27;0&#x27;</span>, BLOOMFILTER =&gt; <span class="string">&#x27;ROW&#x27;</span>, IN_MEMORY =&gt; <span class="string">&#x27;false&#x27;</span>, COMPRESSION =&gt; <span class="string">&#x27;NONE&#x27;</span>, BLOCKCACHE =&gt; <span class="string">&#x27;true&#x27;</span>, BLOCKSIZE =&gt; <span class="string">&#x27;65536 B (64KB)&#x27;</span>&#125;</span>                                                            </span><br><span class="line"></span><br><span class="line">1 row(s)</span><br><span class="line">Quota is disabled</span><br><span class="line">Took 0.0446 seconds </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方式2</span></span><br><span class="line">hbase:032:0&gt; alter &#x27;student1&#x27;, &#x27;delete&#x27; =&gt; &#x27;f1&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><p>shell 中删除表格,需要先将表格状态设置为不可用。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase:043:0&gt; disable &#x27;student1&#x27;</span><br><span class="line">Took 0.3552 seconds                                                                                                                                                                       </span><br><span class="line">hbase:044:0&gt; drop &#x27;student1&#x27;</span><br><span class="line">Took 0.3517 seconds                                                                                                                                                                       </span><br><span class="line">hbase:045:0&gt; list</span><br><span class="line">TABLE                                                                                                                                                                                     </span><br><span class="line">bigdata:student                                                                                                                                                                           </span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0080 seconds                                                                                                                                                                       </span><br><span class="line">=&gt; [&quot;bigdata:student&quot;]</span><br></pre></td></tr></table></figure>



<h2 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h2><h3 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h3><p>在 HBase 中如果想要写入数据，只能添加结构中最底层的 cell。可以手动写入时间戳指定 cell 的版本，推荐不写默认使用当前的系统时间。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase:058:0&#x27; put &#x27;bigdata:student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;,&#x27;zhangsan&#x27;</span><br><span class="line">hbase:059:0&#x27; put &#x27;bigdata:student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;,&#x27;lisi&#x27;</span><br><span class="line">hbase:060:0&#x27; pub &#x27;bigdata:student&#x27;,&#x27;1001&#x27;,&#x27;info:age&#x27;,&#x27;18&#x27;</span><br></pre></td></tr></table></figure>

<p>如果重复写入相同 rowKey，相同列的数据，会写入多个版本进行覆盖。</p>
<h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><p>读取数据的方法有两个：get 和 scan。</p>
<p><strong>get</strong></p>
<p>最大范围是一行数据，也可以进行列的过滤，读取数据的结果为多行 cell。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase:063:0&#x27; get &#x27;bigdata:student&#x27;,&#x27;1001&#x27;</span><br><span class="line">hbase:064:0&#x27; get &#x27;bigdata:student&#x27;,&#x27;1001&#x27;, &#123;COLUMN =&gt; &#x27;info:name&#x27;&#125;</span><br></pre></td></tr></table></figure>

<p>也可以修改读取 cell 的版本数，默认读取一个。最多能够读取当前列族设置的维护版本数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase:066:0&gt;get &#x27;bigdata:student&#x27;,&#x27;1001&#x27; , &#123;COLUMN =&gt; &#x27;info:name&#x27;, VERSIONS =&gt; 6&#125;</span><br></pre></td></tr></table></figure>

<p><strong>scan</strong></p>
<p>scan 是扫描数据，能够读取多行数据，不建议扫描过多的数据，推荐使用 startRow 和stopRow 来控制读取的数据，默认范围左闭右开。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase:067:0&gt; scan &#x27;bigdata:student&#x27;,&#123;STARTROW =&gt; &#x27;1001&#x27;,STOPROW =&gt; &#x27;1002&#x27;&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>实际开发中使用 shell 的机会不多，所有丰富的使用方法到 API 中介绍。</p>
</blockquote>
<h3 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h3><p>删除数据的方法有两个：delete 和 deleteall。</p>
<p><strong>delete</strong></p>
<p>delete 表示删除一个版本的数据，即为 1 个 cell，不填写版本默认删除最新的一个版本。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase:068:0&#x27; delete &#x27;bigdata:student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;</span><br></pre></td></tr></table></figure>

<p><strong>deleteall</strong></p>
<p>deleteall 表示删除所有版本的数据，即为当前行当前列的多个 cell。（执行命令会标记数据为要删除，不会直接将数据彻底删除，删除数据只在特定时期清理磁盘时进行）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase:069:0&#x27; deleteall &#x27;bigdata:student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="清空表数据"><a href="#清空表数据" class="headerlink" title="清空表数据"></a>清空表数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase:004:0&gt; truncate &#x27;bigdata:student&#x27;</span><br></pre></td></tr></table></figure>



<h1 id="HBase高可用"><a href="#HBase高可用" class="headerlink" title="HBase高可用"></a>HBase高可用</h1><p>在当前的HBase集群中，只有一个Master，一旦Master出现故障，将会导致HBase不再可用。所以，在实际的生产环境中，是非常有必要搭建一个高可用的HBase集群的。</p>
<p>HBase的高可用配置其实就是HMaster的高可用。要搭建HBase的高可用，只需要再选择一个节点作为HMaster，在HBase的conf目录下创建文件backup-masters，然后再backup-masters添加备份Master的记录。一条记录代表一个backup master，可以在文件配置多个记录。</p>
<h2 id="搭建HBase高可用"><a href="#搭建HBase高可用" class="headerlink" title="搭建HBase高可用"></a>搭建HBase高可用</h2><ol>
<li>在hbase的conf文件夹中创建 backup-masters 文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hbase-2.5.2/conf</span><br><span class="line">touch backup-masters</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>将node2和node3添加到该文件中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim backup-masters</span><br><span class="line">node2</span><br><span class="line">node3</span><br></pre></td></tr></table></figure>
</li>
<li><p>将backup-masters文件分发到所有的服务器节点中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp backup-masters root@node2:$PWD</span><br><span class="line">scp backup-masters root@node3:$PWD</span><br></pre></td></tr></table></figure>


</li>
<li><p>重新启动hbase</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop-hbase.sh</span><br><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure>


</li>
<li><p>查看webui，检查Backup Masters中是否有node2、node3</p>
<p><img src="/2022/02/24/HBase%E5%AE%9E%E6%93%8D/image-20221228134110955.png" alt="image-20221228134110955"></p>
</li>
<li><p>杀掉node1节点上的master</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -9 HMaster进程id</span><br></pre></td></tr></table></figure>


</li>
<li><p>访问<a target="_blank" rel="noopener" href="http://node1:16010/master-status">http://node2:16010</a>和<a href="http://node3:16010，观察是否选举了新的Master">http://node3:16010，观察是否选举了新的Master</a></p>
<p><img src="/2022/02/24/HBase%E5%AE%9E%E6%93%8D/image-20221228134313416.png" alt="image-20221228134313416"></p>
</li>
</ol>
<h1 id="HBASE-Java编程"><a href="#HBASE-Java编程" class="headerlink" title="HBASE Java编程"></a>HBASE Java编程</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="创建IDEA-Maven项目"><a href="#创建IDEA-Maven项目" class="headerlink" title="创建IDEA Maven项目"></a>创建IDEA Maven项目</h3><p>groupId：cn.st</p>
<p>artifactId：hbase_op</p>
<h3 id="导入pom依赖"><a href="#导入pom依赖" class="headerlink" title="导入pom依赖"></a>导入pom依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span><span class="comment">&lt;!-- 代码库 --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">id</span>&gt;</span>aliyun<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">updatePolicy</span>&gt;</span>never<span class="tag">&lt;/<span class="name">updatePolicy</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.13<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.testng<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>testng<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">version</span>&gt;</span>6.14.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="复制HBase和Hadoop配置文件"><a href="#复制HBase和Hadoop配置文件" class="headerlink" title="复制HBase和Hadoop配置文件"></a>复制HBase和Hadoop配置文件</h3><p>将以下三个配置文件复制到resource目录中</p>
<ul>
<li><p>hbase-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sz /export/server/hbase-2.5.2/conf/hbase-site.xml</span><br></pre></td></tr></table></figure>
</li>
<li><p>core-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sz /export/server/hadoop-3.3.0/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>
</li>
<li><p>log4j.properties</p>
</li>
</ul>
<p>注意：确认配置文件中的服务器节点hostname&#x2F;ip地址配置正确</p>
<h3 id="创建包结构和类"><a href="#创建包结构和类" class="headerlink" title="创建包结构和类"></a>创建包结构和类</h3><ol>
<li><p>在<strong>test</strong>目录创建 cn.st.hbase.admin.api_test 包结构</p>
</li>
<li><p>创建TableAdminTest类</p>
</li>
</ol>
<h3 id="创建Hbase连接以及admin管理对象"><a href="#创建Hbase连接以及admin管理对象" class="headerlink" title="创建Hbase连接以及admin管理对象"></a>创建Hbase连接以及admin管理对象</h3><p>要操作Hbase也需要建立Hbase的连接。此处我们仍然使用TestNG来编写测试。使用@BeforeTest初始化HBase连接，创建admin对象、@AfterTest关闭连接。</p>
<p>实现步骤：</p>
<ol>
<li><p>使用HbaseConfiguration.create()创建Hbase配置</p>
</li>
<li><p>使用ConnectionFactory.createConnection()创建Hbase连接</p>
</li>
<li><p>要创建表，需要基于Hbase连接获取admin管理对象</p>
</li>
<li><p>使用admin.close、connection.close关闭连接</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.st.hbase.admin.api_test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.junit.After;</span><br><span class="line"><span class="keyword">import</span> org.testng.annotations.AfterTest;</span><br><span class="line"><span class="keyword">import</span> org.testng.annotations.BeforeTest;</span><br><span class="line"><span class="keyword">import</span> org.testng.annotations.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableAdminTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">private</span> Connection connection;</span><br><span class="line">    <span class="keyword">private</span> Admin admin;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@BeforeTest</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">beforeTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        configuration = HBaseConfiguration.create();</span><br><span class="line">        connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">        admin = connection.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterTest</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">afterTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        admin.close();</span><br><span class="line">        connection.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="使用Java创建表"><a href="#使用Java创建表" class="headerlink" title="使用Java创建表"></a>使用Java创建表</h3><p>创建一个名为WATER_BILL的表，包含一个列蔟C1。</p>
<p>实现步骤：</p>
<ol>
<li><p>判断表是否存在。存在，则退出</p>
</li>
<li><p>使用TableDescriptorBuilder.newBuilder构建表描述构建器</p>
</li>
<li><p>使用ColumnFamilyDescriptorBuilder.newBuilder构建列蔟描述构建器</p>
</li>
<li><p>构建列蔟描述，构建表描述</p>
</li>
<li><p>创建表</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 创建表</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createTableTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="comment">//表名</span></span><br><span class="line">       <span class="type">String</span> <span class="variable">TABLE_NAME</span> <span class="operator">=</span> <span class="string">&quot;WATER_BILL&quot;</span>;</span><br><span class="line">       <span class="comment">//列簇名</span></span><br><span class="line">       <span class="type">String</span> <span class="variable">COLUMN_FAMILY</span> <span class="operator">=</span> <span class="string">&quot;C1&quot;</span>;</span><br><span class="line"></span><br><span class="line">       <span class="comment">//判断表是否存在</span></span><br><span class="line">       <span class="keyword">if</span> (admin.tableExists(TableName.valueOf(TABLE_NAME))) &#123;</span><br><span class="line">           <span class="keyword">return</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">//构建表描述构建器</span></span><br><span class="line">       <span class="type">TableDescriptorBuilder</span> <span class="variable">tableDescriptorBuilder</span> <span class="operator">=</span> TableDescriptorBuilder.newBuilder(TableName.valueOf(TABLE_NAME));</span><br><span class="line">       <span class="type">ColumnFamilyDescriptorBuilder</span> <span class="variable">columnFamilyDescriptorBuilder</span> <span class="operator">=</span> ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(COLUMN_FAMILY));</span><br><span class="line"></span><br><span class="line">       <span class="comment">//构建列簇描述构建器</span></span><br><span class="line">       <span class="type">ColumnFamilyDescriptor</span> <span class="variable">columnFamilyDescriptor</span> <span class="operator">=</span> columnFamilyDescriptorBuilder.build();</span><br><span class="line"></span><br><span class="line">       <span class="comment">//添加列簇</span></span><br><span class="line">       tableDescriptorBuilder.setColumnFamily(columnFamilyDescriptor);</span><br><span class="line">       <span class="type">TableDescriptor</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> tableDescriptorBuilder.build();</span><br><span class="line"></span><br><span class="line">       <span class="comment">//创建表</span></span><br><span class="line">       admin.createTable(tableDescriptor);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h3 id="使用Java删除表"><a href="#使用Java删除表" class="headerlink" title="使用Java删除表"></a>使用Java删除表</h3><p>实现步骤：</p>
<ol>
<li><p>判断表是否存在</p>
</li>
<li><p>如果存在，则禁用表</p>
</li>
<li><p>再删除表</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dropTableTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(<span class="string">&quot;WATER_BILL&quot;</span>);</span><br><span class="line"></span><br><span class="line">       <span class="comment">//判断表是否存在</span></span><br><span class="line">       <span class="keyword">if</span> (admin.tableExists(tableName)) &#123;</span><br><span class="line">           <span class="comment">//禁用表</span></span><br><span class="line">           admin.disableTable(tableName);</span><br><span class="line">           <span class="comment">//删除表</span></span><br><span class="line">           admin.deleteTable(tableName);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h3 id="插入列数据"><a href="#插入列数据" class="headerlink" title="插入列数据"></a>插入列数据</h3><p>实现步骤：</p>
<ol>
<li><p>使用Hbase连接获取Htable</p>
</li>
<li><p>构建ROWKEY、列蔟名、列名</p>
</li>
<li><p>构建Put对象（对应put命令）</p>
</li>
<li><p>添加姓名列</p>
</li>
<li><p>使用Htable表对象执行put操作</p>
</li>
<li><p>关闭Htable表对象</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">       <span class="comment">//获取table</span></span><br><span class="line">       <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(<span class="string">&quot;WATER_BILL&quot;</span>);</span><br><span class="line">       <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(tableName);</span><br><span class="line"></span><br><span class="line">       <span class="comment">//构建rowkey，列簇名，列名</span></span><br><span class="line">       <span class="type">String</span> <span class="variable">rowkey</span> <span class="operator">=</span> <span class="string">&quot;00000001&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">cfName</span> <span class="operator">=</span> <span class="string">&quot;C1&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colName</span> <span class="operator">=</span> <span class="string">&quot;NAME&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colADDRESS</span> <span class="operator">=</span> <span class="string">&quot;ADDRESS&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colSEX</span> <span class="operator">=</span> <span class="string">&quot;SEX&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colPAY_DATE</span> <span class="operator">=</span> <span class="string">&quot;PAY_DATE&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colNUM_CURRENT</span> <span class="operator">=</span> <span class="string">&quot;NUM_CURRENT&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colNUM_PREVIOUS</span> <span class="operator">=</span> <span class="string">&quot;NUM_PREVIOUS&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colNUM_USAGE</span> <span class="operator">=</span> <span class="string">&quot;NUM_USAGE&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colTOTAL_MONEY</span> <span class="operator">=</span> <span class="string">&quot;TOTAL_MONEY&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colRECORD_DATE</span> <span class="operator">=</span> <span class="string">&quot;RECORD_DATE&quot;</span>;</span><br><span class="line">       <span class="type">String</span> <span class="variable">colLATEST_DATE</span> <span class="operator">=</span> <span class="string">&quot;LATEST_DATE&quot;</span>;</span><br><span class="line"></span><br><span class="line">       <span class="comment">//构建Put对象（对应put命令）</span></span><br><span class="line">       <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(rowkey));</span><br><span class="line">       <span class="comment">//添加姓名列</span></span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colName), Bytes.toBytes(<span class="string">&quot;张三&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colADDRESS), Bytes.toBytes(<span class="string">&quot;云南省昆明市&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colSEX), Bytes.toBytes(<span class="string">&quot;男&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colPAY_DATE), Bytes.toBytes(<span class="string">&quot;2021-05-10&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colNUM_CURRENT), Bytes.toBytes(<span class="string">&quot;308.1&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colNUM_PREVIOUS), Bytes.toBytes(<span class="string">&quot;283.1&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colNUM_USAGE), Bytes.toBytes(<span class="string">&quot;25&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colTOTAL_MONEY), Bytes.toBytes(<span class="string">&quot;150&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colRECORD_DATE), Bytes.toBytes(<span class="string">&quot;2021-04-25&quot;</span>));</span><br><span class="line">       put.addColumn(Bytes.toBytes(cfName), Bytes.toBytes(colLATEST_DATE), Bytes.toBytes(<span class="string">&quot;2021-06-09&quot;</span>));</span><br><span class="line"></span><br><span class="line">       <span class="comment">//使用Htable表对象执行put</span></span><br><span class="line">       table.put(put);</span><br><span class="line">       table.close();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>



<h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><p>实现步骤：</p>
<ol>
<li><p>获取HTable</p>
</li>
<li><p>使用rowkey构建Get对象</p>
</li>
<li><p>执行get请求</p>
</li>
<li><p>获取所有单元格</p>
</li>
<li><p>打印rowkey</p>
</li>
<li><p>迭代单元格列表</p>
</li>
<li><p>关闭表</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getOneTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 1. 获取HTable</span></span><br><span class="line">    <span class="type">TableName</span> <span class="variable">waterBillTableName</span> <span class="operator">=</span> TableName.valueOf(<span class="string">&quot;WATER_BILL&quot;</span>);</span><br><span class="line">    <span class="type">Table</span> <span class="variable">waterBilltable</span> <span class="operator">=</span> connection.getTable(waterBillTableName);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 使用rowkey构建Get对象</span></span><br><span class="line">    <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(Bytes.toBytes(<span class="string">&quot;00000001&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 执行get请求</span></span><br><span class="line">    <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> waterBilltable.get(get);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 获取所有单元格</span></span><br><span class="line">    List&lt;Cell&gt; cellList = result.listCells();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印rowkey</span></span><br><span class="line">    System.out.println(<span class="string">&quot;rowkey =&gt; &quot;</span> + Bytes.toString(result.getRow()));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 迭代单元格列表</span></span><br><span class="line">    <span class="keyword">for</span> (Cell cell : cellList) &#123;</span><br><span class="line">        <span class="comment">// 打印列蔟名</span></span><br><span class="line">        System.out.print(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()));</span><br><span class="line">        System.out.println(<span class="string">&quot; =&gt; &quot;</span> + Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6. 关闭表</span></span><br><span class="line">    waterBilltable.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="删除数据-1"><a href="#删除数据-1" class="headerlink" title="删除数据"></a>删除数据</h3><p>实现步骤：</p>
<ol>
<li><p>获取HTable对象</p>
</li>
<li><p>根据rowkey构建delete对象</p>
</li>
<li><p>执行delete请求</p>
</li>
<li><p>关闭表</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deleteOneTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 1. 获取HTable对象</span></span><br><span class="line">    <span class="type">Table</span> <span class="variable">waterBillTable</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(<span class="string">&quot;WATER_BILL&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 根据rowkey构建delete对象</span></span><br><span class="line">    <span class="type">Delete</span> <span class="variable">delete</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Delete</span>(Bytes.toBytes(<span class="string">&quot;00000001&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 执行delete请求</span></span><br><span class="line">    waterBillTable.delete(delete);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 关闭表</span></span><br><span class="line">    waterBillTable.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Import 表名 HDFS数据文件路径</span><br></pre></td></tr></table></figure>



<h3 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Export 表名 HDFS数据文件路径</span><br></pre></td></tr></table></figure>



<h3 id="过滤器的使用"><a href="#过滤器的使用" class="headerlink" title="过滤器的使用"></a>过滤器的使用</h3><p>实现步骤：</p>
<ol>
<li><p>获取表</p>
</li>
<li><p>构建scan请求对象</p>
</li>
<li><p>构建两个过滤器</p>
</li>
</ol>
<p>​		a) 构建两个日期范围过滤器（注意此处请使用RECORD_DATE——抄表日期比较</p>
<p>​		b) 构建过滤器列表</p>
<ol start="4">
<li><p>执行scan扫描请求</p>
</li>
<li><p>迭代打印result</p>
</li>
<li><p>迭代单元格列表</p>
</li>
<li><p>关闭ResultScanner（这玩意把转换成一个个的类似get的操作，注意要关闭释放资源）</p>
</li>
<li><p>关闭表</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">queryTest1</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// 1. 获取表</span></span><br><span class="line">    <span class="type">Table</span> <span class="variable">waterBillTable</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(<span class="string">&quot;WATER_BILL&quot;</span>));</span><br><span class="line">    <span class="comment">// 2. 构建scan请求对象</span></span><br><span class="line">    <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">    <span class="comment">// 3. 构建两个过滤器</span></span><br><span class="line">    <span class="comment">// 3.1 构建日期范围过滤器（注意此处请使用RECORD_DATE——抄表日期比较</span></span><br><span class="line">    <span class="type">SingleColumnValueFilter</span> <span class="variable">startDateFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(Bytes.toBytes(<span class="string">&quot;C1&quot;</span>)</span><br><span class="line">            , Bytes.toBytes(<span class="string">&quot;RECORD_DATE&quot;</span>)</span><br><span class="line">            , CompareOperator.GREATER_OR_EQUAL</span><br><span class="line">            , Bytes.toBytes(<span class="string">&quot;2020-06-01&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="type">SingleColumnValueFilter</span> <span class="variable">endDateFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(Bytes.toBytes(<span class="string">&quot;C1&quot;</span>)</span><br><span class="line">            , Bytes.toBytes(<span class="string">&quot;RECORD_DATE&quot;</span>)</span><br><span class="line">            , CompareOperator.LESS_OR_EQUAL</span><br><span class="line">            , Bytes.toBytes(<span class="string">&quot;2020-06-30&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.2 构建过滤器列表</span></span><br><span class="line">    <span class="type">FilterList</span> <span class="variable">filterList</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FilterList</span>(FilterList.Operator.MUST_PASS_ALL</span><br><span class="line">            , startDateFilter</span><br><span class="line">            , endDateFilter);</span><br><span class="line"></span><br><span class="line">    scan.setFilter(filterList);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 执行scan扫描请求</span></span><br><span class="line">    <span class="type">ResultScanner</span> <span class="variable">resultScan</span> <span class="operator">=</span> waterBillTable.getScanner(scan);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 迭代打印result</span></span><br><span class="line">    <span class="keyword">for</span> (Result result : resultScan) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;rowkey -&gt; &quot;</span> + Bytes.toString(result.getRow()));</span><br><span class="line">        System.out.println(<span class="string">&quot;------&quot;</span>);</span><br><span class="line"></span><br><span class="line">        List&lt;Cell&gt; cellList = result.listCells();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6. 迭代单元格列表</span></span><br><span class="line">        <span class="keyword">for</span> (Cell cell : cellList) &#123;</span><br><span class="line">            <span class="comment">// 打印列蔟名</span></span><br><span class="line">            System.out.print(Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()));</span><br><span class="line">            System.out.println(<span class="string">&quot; =&gt; &quot;</span> + Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;------&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">resultScanner.close();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 7. 关闭表</span></span><br><span class="line">    waterBillTable.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="乱码问题"><a href="#乱码问题" class="headerlink" title="乱码问题"></a>乱码问题</h3><p>可以根据列来判断，使用哪种方式转换字节码。如下：</p>
<ol>
<li><p>NUM_CURRENT</p>
</li>
<li><p>NUM_PREVIOUS</p>
</li>
<li><p>NUM_USAGE</p>
</li>
<li><p>TOTAL_MONEY</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">colName</span> <span class="operator">=</span> Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());</span><br><span class="line">System.out.print(colName);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(colName.equals(<span class="string">&quot;NUM_CURRENT&quot;</span>)</span><br><span class="line">        || colName.equals(<span class="string">&quot;NUM_PREVIOUS&quot;</span>)</span><br><span class="line">        || colName.equals(<span class="string">&quot;NUM_USAGE&quot;</span>)</span><br><span class="line">        || colName.equals(<span class="string">&quot;TOTAL_MONEY&quot;</span>)) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot; =&gt; &quot;</span> + Bytes.toDouble(cell.getValueArray(), cell.getValueOffset()));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot; =&gt; &quot;</span> + Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/22/HBase%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">HBase基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-22 20:12:05" itemprop="dateCreated datePublished" datetime="2022-02-22T20:12:05+08:00">2022-02-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-28 18:40:01" itemprop="dateModified" datetime="2022-12-28T18:40:01+08:00">2022-12-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>Apache HBase是以HDFS为数据存储的，一种分布式、可扩展的NoSQL数据库。这意味着它不像传统的RDBMS数据库那样支持SQL作为查询语言。Hbase更像是分布式存储而不是分布式数据库，它缺少很多RDBMS系统的特性，比如列类型，辅助索引，触发器，和高级查询语言等待。</p>
<h2 id="HBase特性"><a href="#HBase特性" class="headerlink" title="HBase特性"></a>HBase特性</h2><ul>
<li><p>强读写一致，但不是“最终一致性”的数据存储，这使得它非常适合高速的计算聚合</p>
</li>
<li><p>自动分片，通过Region分散在集群中，当行数增长的时候，Region也会自动的切分和再分配</p>
</li>
<li><p>自动的故障转移</p>
</li>
<li><p>Hadoop&#x2F;HDFS集成，和HDFS开箱即用</p>
</li>
<li><p>HBase通过MapReduce支持大规模并行处理，将HBase用作源和接收器</p>
</li>
<li><p>丰富的“简洁，高效”API，Thrift&#x2F;REST API，Java API</p>
</li>
<li><p>块缓存，布隆过滤器，可以高效的列查询优化</p>
</li>
<li><p>操作管理，Hbase提供了内置的web界面来操作，还可以监控JMX指标</p>
</li>
</ul>
<h2 id="RDBMS与HBase的对比"><a href="#RDBMS与HBase的对比" class="headerlink" title="RDBMS与HBase的对比"></a>RDBMS与HBase的对比</h2><h3 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h3><p><strong>结构</strong></p>
<ul>
<li><p>数据库以表的形式存在</p>
</li>
<li><p>支持FAT、NTFS、EXT、文件系统</p>
</li>
<li><p>使用主键（PK）</p>
</li>
<li><p>通过外部中间件可以支持分库分表，但底层还是单机引擎</p>
</li>
<li><p>使用行、列、单元格</p>
</li>
</ul>
<p><strong>功能</strong></p>
<ul>
<li><p>支持向上扩展（买更好的服务器）</p>
</li>
<li><p>使用SQL查询</p>
</li>
<li><p>面向行，即每一行都是一个连续单元</p>
</li>
<li><p>数据总量依赖于服务器配置</p>
</li>
<li><p>具有ACID支持</p>
</li>
<li><p>适合结构化数据</p>
</li>
<li><p>传统关系型数据库一般都是中心化的</p>
</li>
<li><p>支持事务</p>
</li>
<li><p>支持Join</p>
</li>
</ul>
<h3 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h3><p><strong>结构</strong></p>
<ul>
<li><p>以表形式存在</p>
</li>
<li><p>支持HDFS文件系统</p>
</li>
<li><p>使用行键（row key）</p>
</li>
<li><p>原生支持分布式存储、计算引擎</p>
</li>
<li><p>使用行、列、列蔟和单元格</p>
</li>
</ul>
<p><strong>功能</strong></p>
<ul>
<li><p>支持向外扩展</p>
</li>
<li><p>使用API和MapReduce、Spark、Flink来访问HBase表数据</p>
</li>
<li><p>面向列蔟，即每一个列蔟都是一个连续的单元</p>
</li>
<li><p>数据总量不依赖具体某台机器，而取决于机器数量</p>
</li>
<li><p>HBase不支持ACID（Atomicity、Consistency、Isolation、Durability）</p>
</li>
<li><p>适合结构化数据和非结构化数据</p>
</li>
<li><p>一般都是分布式的</p>
</li>
<li><p>HBase不支持事务，支持的是单行数据的事务操作</p>
</li>
<li><p>不支持Join</p>
</li>
</ul>
<h2 id="HDFS对比HBase"><a href="#HDFS对比HBase" class="headerlink" title="HDFS对比HBase"></a>HDFS对比HBase</h2><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><ul>
<li>HDFS是一个非常适合存储大型文件的分布式文件系统</li>
</ul>
<h3 id="HBase-1"><a href="#HBase-1" class="headerlink" title="HBase"></a>HBase</h3><ul>
<li><p>HBase构建在HDFS之上，并为大型表提供快速记录查找(和更新)</p>
</li>
<li><p>HBase内部将大量数据放在HDFS中名为「StoreFiles」的索引中，以便进行高速查找</p>
</li>
<li><p>Hbase比较适合做快速查询等需求，而不适合做大规模的OLAP应用</p>
</li>
</ul>
<h2 id="Hive对比Hbase"><a href="#Hive对比Hbase" class="headerlink" title="Hive对比Hbase"></a>Hive对比Hbase</h2><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><ul>
<li>数据仓库工具</li>
</ul>
<p>​	Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询</p>
<ul>
<li>用于数据分析、清洗</li>
</ul>
<p>​	Hive适用于离线的数据分析和清洗，延迟较高</p>
<ul>
<li>基于HDFS、MapReduce</li>
</ul>
<p>​	Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行</p>
<h3 id="HBase-2"><a href="#HBase-2" class="headerlink" title="HBase"></a>HBase</h3><ul>
<li>NoSQL数据库</li>
</ul>
<p>​	是一种面向列存储的非关系型数据库。</p>
<ul>
<li>用于存储结构化和非结构化的数据</li>
</ul>
<p>​	适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p>
<ul>
<li>基于HDFS</li>
</ul>
<p>​	数据持久化存储的体现形式是Hfile，存放于DataNode中，被ResionServer以region的形式进行管理</p>
<ul>
<li>延迟较低，接入在线业务使用</li>
</ul>
<p>​	面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度</p>
<h3 id="总结Hive与HBase"><a href="#总结Hive与HBase" class="headerlink" title="总结Hive与HBase"></a>总结Hive与HBase</h3><ul>
<li><p>Hive和Hbase是两种基于Hadoop的不同技术</p>
</li>
<li><p>Hive是一种类SQL的引擎，并且运行MapReduce任务</p>
</li>
<li><p>Hbase是一种在Hadoop之上的NoSQL 的Key&#x2F;value数据库</p>
</li>
<li><p>这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到HBase，或者从HBase写回Hive</p>
</li>
</ul>
<h2 id="HBase适用场合"><a href="#HBase适用场合" class="headerlink" title="HBase适用场合"></a>HBase适用场合</h2><p>Hbase不适合解决所有的问题：</p>
<ul>
<li><p>首先数据库量要足够多，如果有十亿及百亿行数据，那么Hbase是一个很好的选项，如果只有几百万行甚至不到的数据量，RDBMS是一个很好的选择。因为数据量小的话，真正能工作的机器量少，剩余的机器都处于空闲的状态</p>
</li>
<li><p>其次，如果你不需要辅助索引，静态类型的列，事务等特性，一个已经用RDBMS的系统想要切换到Hbase，则需要重新设计系统。</p>
</li>
<li><p>最后，保证硬件资源足够，每个HDFS集群在少于5个节点的时候，都不能表现的很好。因为HDFS默认的复制数量是3，再加上一个NameNode。</p>
</li>
</ul>
<h1 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h1><h2 id="HBase数据模型"><a href="#HBase数据模型" class="headerlink" title="HBase数据模型"></a>HBase数据模型</h2><p>Bigtable是一个稀疏的、分布式的、持久的多维排序map（映射）。该映射由行键、列键和时间戳索引；映射中的每个值都是一个未解释的字节数组。</p>
<p>HBase 使用与 Bigtable 非常相似的数据模型。用户将数据行存储在带标签的表中。数据行具有可排序的键和任意数量的列。</p>
<p>HBase 数据模型的关键在于稀疏、分布式、多维、排序的映射。其中映射 map指代非关系型数据库的 key-Value 结构。</p>
<h2 id="HBase逻辑结构"><a href="#HBase逻辑结构" class="headerlink" title="HBase逻辑结构"></a>HBase逻辑结构</h2><p>HBase 可以用于存储多种结构的数据。以json为例，存储的数据原貌为：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;row_key1&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;personal_info&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span><span class="string">&quot;北京&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;phone&quot;</span><span class="punctuation">:</span><span class="string">&quot;131********&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;office_info&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;tel&quot;</span><span class="punctuation">:</span><span class="string">&quot;010-1111111&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span><span class="string">&quot;atguigu&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;row_key11&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;personal_info&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span><span class="string">&quot;上海&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;phone&quot;</span><span class="punctuation">:</span><span class="string">&quot;132********&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;office_info&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;tel&quot;</span><span class="punctuation">:</span><span class="string">&quot;010-1111111&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/image-20221222144917988.png" alt="image-20221222144917988"></p>
<h2 id="HBase物理存储结构"><a href="#HBase物理存储结构" class="headerlink" title="HBase物理存储结构"></a>HBase物理存储结构</h2><p>物理存储结构即为数据映射关系，而在概念视图的空单元格，底层实际根本不存储。</p>
<p><img src="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/image-20221222145117938.png" alt="image-20221222145117938"></p>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><h3 id="NameSpace"><a href="#NameSpace" class="headerlink" title="NameSpace"></a>NameSpace</h3><p>命名空间，类似于关系型数据库的 database 概念，每个命名空间下有多个表。HBase 两个自带的命名空间，分别是 hbase 和 default，hbase 中存放的是 HBase 内置的表，default表是用户默认使用的命名空间。</p>
<h3 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h3><p>类似于关系型数据库的表概念。不同的是，HBase 定义表时只需要声明列族即可，不需要声明具体的列。因为数据存储时稀疏的，所有往 HBase 写入数据时，字段可以动态、按需指定。因此，和关系型数据库相比，HBase 能够轻松应对字段变更的场景。</p>
<h3 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h3><p>HBase 表中的每行数据都由一个 <strong>RowKey</strong> 和多个 <strong>Column</strong>（列）组成，数据是按照 RowKey的字典顺序存储的，并且查询数据时只能根据 RowKey 进行检索，所以 RowKey 的设计十分重要。</p>
<h3 id="Column"><a href="#Column" class="headerlink" title="Column"></a>Column</h3><p>HBase 中的每个列都由 Column Family(列族)和 Column Qualifier（列限定符）进行限定，例如 info：name，info：age。建表时，只需指明列族，而列限定符无需预先定义。</p>
<h3 id="Timestamp"><a href="#Timestamp" class="headerlink" title="Timestamp"></a>Timestamp</h3><p>用于标识数据的不同版本（version），每条数据写入时，系统会自动为其加上该字段，其值为写入 HBase 的时间。</p>
<h3 id="Cell"><a href="#Cell" class="headerlink" title="Cell"></a>Cell</h3><p>由{rowkey, column Family：column Qualifier, timestamp} 唯一确定的单元。cell 中的数据全部是字节码形式存贮。</p>
<h2 id="HBase基本架构"><a href="#HBase基本架构" class="headerlink" title="HBase基本架构"></a>HBase基本架构</h2><p><img src="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/image-20221222150205283.png" alt="image-20221222150205283"></p>
<p>角色：</p>
<p><strong>Master</strong></p>
<p>RegionServer要实时的向Master报告信息。Master知道全局的RegionServer运行情况，可以控制RegionServer的故障转移和Region的切分。</p>
<p>实现类为 HMaster，负责监控集群中所有的 RegionServer 实例。主要作用如下：</p>
<p>（1）管理元数据表格 hbase:meta，接收用户对表格创建修改删除的命令并执行。</p>
<p>（2）监控 region 是否需要进行负载均衡，故障转移和 region 的拆分。</p>
<p>通过启动多个后台线程监控实现上述功能：</p>
<p>① LoadBalancer 负载均衡器</p>
<p>​	周期性监控 region 分布在 regionServer 上面是否均衡，由参数 hbase.balancer.period 控制周期时间，默认 5 分钟。</p>
<p>② CatalogJanitor 元数据管理器</p>
<p>​	定期检查和清理 hbase:meta 中的数据。meta 表内容在进阶中介绍。</p>
<p>③ MasterProcWAL master 预写日志处理器</p>
<p>​	把 master 需要执行的任务记录到预写日志 WAL 中，如果 master 宕机，让 backupMaster读取日志继续干。</p>
<p><strong>Region Server</strong></p>
<p>理解为数据节点，存储数据的。</p>
<p>Region Server 实现类为 HRegionServer，主要作用如下:</p>
<p>（1）负责数据 cell 的处理，例如写入数据 put，查询数据 get 等</p>
<p>（2）拆分合并 region 的实际执行者，有 master 监控，有 regionServer 执行。</p>
<p><strong>Zookeeper</strong></p>
<p>作为分布式的协调。RegionServer也会把自己的信息写到ZooKeeper中。</p>
<p>HBase 通过 Zookeeper 来做 master 的高可用、记录 RegionServer 的部署信息、并且存储有 meta 表的位置信息。</p>
<p>HBase 对于数据的读写操作时直接访问 Zookeeper 的，在 2.3 版本推出 Master Registry模式，客户端可以直接访问 master。使用此功能，会加大对 master 的压力，减轻对 Zookeeper的压力。</p>
<p><strong>HDFS</strong></p>
<p>HDFS 为 Hbase 提供最终的底层数据存储服务，同时为 HBase 提供高容错的支持。</p>
<h3 id="架构细化"><a href="#架构细化" class="headerlink" title="架构细化"></a>架构细化</h3><p><img src="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/426671-fc9efc43916684c1.png" alt="img"></p>
<p>HMaster是Master Server的实现，负责监控集群中的RegionServer实例，同时是所有metadata改变的接口，在集群中，通常运行在NameNode上面，<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=http://blog.zahoor.in/2012/08/hbase-hmaster-architecture/">这里有一篇更细的HMaster介绍</a></p>
<ul>
<li>HMasterInterface暴露的接口，Table(createTable, modifyTable, removeTable, enable, disable),ColumnFamily (addColumn, modifyColumn, removeColumn),Region (move, assign, unassign)</li>
<li>Master运行的后台线程：LoadBalancer线程，控制region来平衡集群的负载。CatalogJanitor线程，周期性的检查hbase:meta表。</li>
</ul>
<p>HRegionServer是RegionServer的实现，服务和管理Regions，集群中RegionServer运行在DataNode</p>
<ul>
<li>HRegionRegionInterface暴露接口：Data (get, put, delete, next, etc.)，Region (splitRegion, compactRegion, etc.)</li>
<li>RegionServer后台线程：CompactSplitThread，MajorCompactionChecker，MemStoreFlusher，LogRoller</li>
</ul>
<p>Regions，代表table，Region有多个Store(列簇)，Store有一个Memstore和多个StoreFiles(HFiles)，StoreFiles的底层是Block。</p>
<h2 id="存储设计"><a href="#存储设计" class="headerlink" title="存储设计"></a>存储设计</h2><p>在Hbase中，表被分割成多个更小的块然后分散的存储在不同的服务器上，这些小块叫做Regions，存放Regions的地方叫做RegionServer。Master进程负责处理不同的RegionServer之间的Region的分发。在Hbase实现中HRegionServer和HRegion类代表RegionServer和Region。HRegionServer除了包含一些HRegions之外，还处理两种类型的文件用于数据存储</p>
<ul>
<li>HLog， 预写日志文件，也叫做WAL(write-ahead log)</li>
<li>HFile 真实的数据存储文件</li>
</ul>
<h3 id="HLog"><a href="#HLog" class="headerlink" title="HLog"></a>HLog</h3><ul>
<li><p>MasterProcWAL：HMaster记录管理操作，比如解决冲突的服务器，表创建和其它DDLs等操作到它的WAL文件中，这个WALs存储在MasterProcWALs目录下，它不像RegionServer的WALs，HMaster的WAL也支持弹性操作，就是如果Master服务器挂了，其它的Master接管的时候继续操作这个文件。</p>
</li>
<li><p>WAL记录所有的Hbase数据改变，如果一个RegionServer在MemStore进行FLush的时候挂掉了，WAL可以保证数据的改变被应用到。如果写WAL失败了，那么修改数据的完整操作就是失败的。</p>
</li>
</ul>
<ul>
<li>通常情况，每个RegionServer只有一个WAL实例。在2.0之前，WAL的实现叫做HLog</li>
<li>WAL位于*&#x2F;hbase&#x2F;WALs&#x2F;*目录下</li>
<li>MultiWAL: 如果每个RegionServer只有一个WAL，由于HDFS必须是连续的，导致必须写WAL连续的，然后出现性能问题。MultiWAL可以让RegionServer同时写多个WAL并行的，通过HDFS底层的多管道，最终提升总的吞吐量，但是不会提升单个Region的吞吐量。</li>
</ul>
<ul>
<li>WAL配置</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 启用multiwal</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.wal.provider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>multiwal<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="Hfile"><a href="#Hfile" class="headerlink" title="Hfile"></a>Hfile</h3><p>HFile是Hbase在HDFS中存储数据的格式，它包含多层的索引，这样在Hbase检索数据的时候就不用完全的加载整个文件。索引的大小(keys的大小，数据量的大小)影响block的大小，在大数据集的情况下，block的大小设置为每个RegionServer 1GB也是常见的。</p>
<h4 id="Hfile生成方式"><a href="#Hfile生成方式" class="headerlink" title="Hfile生成方式"></a>Hfile生成方式</h4><p>起初，HFile中并没有任何Block，数据还存在于MemStore中。</p>
<p>Flush发生时，创建HFile Writer，第一个空的Data Block出现，初始化后的Data Block中为Header部分预留了空间，Header部分用来存放一个Data Block的元数据信息。</p>
<p>而后，位于MemStore中的KeyValues被一个个append到位于内存中的第一个Data Block中：</p>
<p><strong>注</strong>：如果配置了Data Block Encoding，则会在Append KeyValue的时候进行同步编码，编码后的数据不再是单纯的KeyValue模式。Data Block Encoding是HBase为了降低KeyValue结构性膨胀而提供的内部编码机制。</p>
<p><img src="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/426671-fc9efc43916684b1.png" alt="img"></p>
<h4 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h4><p><img src="/2022/02/22/HBase%E5%9F%BA%E7%A1%80/426671-726c0d6e0f57814a.png" alt="img"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/18/SparkSQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/18/SparkSQL/" class="post-title-link" itemprop="url">SparkSQL</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-18 21:12:45" itemprop="dateCreated datePublished" datetime="2022-02-18T21:12:45+08:00">2022-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-11 22:58:05" itemprop="dateModified" datetime="2022-12-11T22:58:05+08:00">2022-12-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="SparkSQL概述"><a href="#SparkSQL概述" class="headerlink" title="SparkSQL概述"></a>SparkSQL概述</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>SparkSQL是Spark的一个模块，用于处理海量的结构化数据。它支持SQL语言、性能强、可以自动优化、API简单、兼容HIVE等</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul>
<li>融合性：SQL可以无缝集成在代码中，随时用SQL处理数据</li>
<li>统一的数据访问：一套标准的API可读写不同的数据源</li>
<li>Hive兼容：可以使用SparkSQL直接计算并生成Hive数据表</li>
<li>标准化连接：支持标准化JDBC&#x2F;ODBC连接，方便和各种数据库进行数据交互</li>
</ul>
<h2 id="SparkSQL和Hive的异同"><a href="#SparkSQL和Hive的异同" class="headerlink" title="SparkSQL和Hive的异同"></a>SparkSQL和Hive的异同</h2><p><img src="/2022/02/18/SparkSQL/image-20221208112145644.png" alt="image-20221208112145644"></p>
<h2 id="SparkSQL的数据抽象"><a href="#SparkSQL的数据抽象" class="headerlink" title="SparkSQL的数据抽象"></a>SparkSQL的数据抽象</h2><p>各计算框架的数据抽象</p>
<ul>
<li>Pandas - DataFrame - 二维表数据结构 &#x2F; 单机（本地）集合</li>
<li>SparkCore - RDD - 无标准数据结构，存储什么数据都可以 &#x2F; 分布式集合（分区）</li>
<li>SparkSQL - DataFrame - 二维表数据结构 &#x2F; 分布式集合（分区）</li>
<li>SparkSQL for JVM - DataSet&#x2F;DataFrame</li>
<li>SparkSQL for Python&#x2F;R - DataFrame</li>
</ul>
<h2 id="SparkSession对象"><a href="#SparkSession对象" class="headerlink" title="SparkSession对象"></a>SparkSession对象</h2><p>在RDD阶段，程序的执行入口是：SparkContext。</p>
<p>在Spark2.0后，SparkSession作为Spark编码的统一入口对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#构建SparkSession对象，构建器模式，通过builder方法来构建</span></span><br><span class="line">    <span class="comment">#通过getOrCreate()方法创建</span></span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">&#x27;study01&#x27;</span>).master(<span class="string">&#x27;local[*&#x27;</span>).config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).getOrCreate()</span><br></pre></td></tr></table></figure>



<h1 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h1><h2 id="DataFrame组成"><a href="#DataFrame组成" class="headerlink" title="DataFrame组成"></a>DataFrame组成</h2><p>结构层面：</p>
<ul>
<li>StructType对象描述整个DataFrame的表结构</li>
<li>StructField对象描述一个列的信息</li>
</ul>
<p>数据层面</p>
<ul>
<li>Row对象记录一行数据</li>
<li>Column对象记录一列数据并包含列的信息</li>
</ul>
<p><img src="/2022/02/18/SparkSQL/image-20221208115422089.png" alt="image-20221208115422089"></p>
<p>StructType描述，如下图</p>
<p><img src="/2022/02/18/SparkSQL/image-20221208115655961.png" alt="image-20221208115655961"></p>
<p>一个StructField记录：列名、列类型、列是否运行为空。</p>
<p>多个StructField组成一个StructType对象。</p>
<p>一个StructType对象可以描述一个DataFrame。</p>
<h2 id="DataFrame的代码构建"><a href="#DataFrame的代码构建" class="headerlink" title="DataFrame的代码构建"></a>DataFrame的代码构建</h2><h3 id="基于RDD"><a href="#基于RDD" class="headerlink" title="基于RDD"></a>基于RDD</h3><h4 id="方式1"><a href="#方式1" class="headerlink" title="方式1"></a>方式1</h4><p>通过SparkSession对象的createDataFrame方法将RDD转换为DataFrame。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#构建SparkSession对象，构建器模式，通过builder方法来构建</span></span><br><span class="line">    <span class="comment">#通过getOrCreate()方法创建</span></span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line">    rdd = sc.textFile(<span class="string">&quot;hdfs://node1:8020/input/sql/people.txt&quot;</span>).\</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;,&#x27;</span>)).\</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: [x[<span class="number">0</span>], <span class="built_in">int</span>(x[<span class="number">1</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#构建dataFrame，这里只传入列名称，类型从RDD中进行推断，是否允许为空（默认允许true）</span></span><br><span class="line">    df = spark.createDataFrame(rdd, schema=[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>])</span><br><span class="line">    <span class="comment">#打印表结构</span></span><br><span class="line">    df.printSchema()</span><br><span class="line">    <span class="comment">#打印数据</span></span><br><span class="line">    df.show()</span><br><span class="line"></span><br><span class="line">    df.createTempView(<span class="string">&#x27;ttt&#x27;</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;select * from ttt where age &lt; 30&quot;</span>).show()</span><br></pre></td></tr></table></figure>



<h4 id="方式2"><a href="#方式2" class="headerlink" title="方式2"></a>方式2</h4><p>通过StructType对象来定义DataFrame的“表结构”转换RDD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType, IntegerType</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line">    rdd = sc.textFile(<span class="string">&quot;hdfs://node1:8020/input/sql/stu_score.txt&quot;</span>).\</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;,&#x27;</span>)).\</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: [<span class="built_in">int</span>(x[<span class="number">0</span>]), x[<span class="number">1</span>], <span class="built_in">int</span>(x[<span class="number">2</span>])])</span><br><span class="line"></span><br><span class="line">    schema = StructType().\</span><br><span class="line">        add(<span class="string">&#x27;id&#x27;</span>, IntegerType(), nullable=<span class="literal">False</span>).\</span><br><span class="line">        add(<span class="string">&#x27;name&#x27;</span>, StringType(), nullable=<span class="literal">True</span>).\</span><br><span class="line">        add(<span class="string">&#x27;score&#x27;</span>, IntegerType(), nullable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#构建dataFrame，</span></span><br><span class="line">    df = spark.createDataFrame(rdd, schema)</span><br><span class="line">    <span class="comment">#打印表结构</span></span><br><span class="line">    df.printSchema()</span><br><span class="line">    <span class="comment">#打印数据</span></span><br><span class="line">    df.show()</span><br></pre></td></tr></table></figure>



<h4 id="方式3"><a href="#方式3" class="headerlink" title="方式3"></a>方式3</h4><p>使用RDD的toDF方法转换RDD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType, IntegerType</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line">    rdd = sc.textFile(<span class="string">&quot;hdfs://node1:8020/input/sql/stu_score.txt&quot;</span>).\</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;,&#x27;</span>)).\</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: [<span class="built_in">int</span>(x[<span class="number">0</span>]), x[<span class="number">1</span>], <span class="built_in">int</span>(x[<span class="number">2</span>])])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#方式1，只传列名，类型靠推断，是否允许为空是true</span></span><br><span class="line">    df1 = rdd.toDF([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;score&#x27;</span>])</span><br><span class="line">    df1.printSchema()</span><br><span class="line">    df1.show()</span><br><span class="line"></span><br><span class="line">    schema = StructType().\</span><br><span class="line">        add(<span class="string">&#x27;id&#x27;</span>, IntegerType(), nullable=<span class="literal">False</span>).\</span><br><span class="line">        add(<span class="string">&#x27;name&#x27;</span>, StringType(), nullable=<span class="literal">True</span>).\</span><br><span class="line">        add(<span class="string">&#x27;score&#x27;</span>, IntegerType(), nullable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#方式2，传入完整的schema描述对象StructType</span></span><br><span class="line">    df2 = rdd.toDF(schema=schema)</span><br><span class="line">    df2.printSchema()</span><br><span class="line">    df2.show()</span><br></pre></td></tr></table></figure>



<h3 id="基于Pandas的DataFrame"><a href="#基于Pandas的DataFrame" class="headerlink" title="基于Pandas的DataFrame"></a>基于Pandas的DataFrame</h3><p>将Pandas的DataFrame对象，转变为分布式的SparkSQL DataFrame对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType, IntegerType</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    pdf = pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&#x27;id&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: [<span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;李四&#x27;</span>, <span class="string">&#x27;王五&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;age&#x27;</span>:[<span class="number">11</span>,<span class="number">23</span>,<span class="number">24</span>]</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame(pdf)</span><br><span class="line">    df.printSchema()</span><br><span class="line">    df.show()</span><br></pre></td></tr></table></figure>



<h3 id="读取外部数据"><a href="#读取外部数据" class="headerlink" title="读取外部数据"></a>读取外部数据</h3><p>通过SparkSQL的统一的API进行数据的读取构建DataFrame</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sparksession.read.<span class="built_in">format</span>(<span class="string">&quot;text|csv|parquet|orc|avro|jdbc|...&quot;</span>)</span><br><span class="line">	.option(<span class="string">&quot;K&quot;</span>, <span class="string">&quot;V&quot;</span>) <span class="comment">#option可选</span></span><br><span class="line">    .schema(StructType | String) <span class="comment">#STRING的语法如.schema(&quot;name STRING&quot;, &quot;age INT&quot;)</span></span><br><span class="line">    .load(<span class="string">&quot;被读取的文件的路径， 支持本地文件系统和HDFS&quot;</span>)</span><br></pre></td></tr></table></figure>



<h4 id="读取text数据源"><a href="#读取text数据源" class="headerlink" title="读取text数据源"></a>读取text数据源</h4><p>使用format(“text”)读取文本数据，读取到的DataFrame只会有一个列，列名默认称之为：value</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    schema = StructType().add(<span class="string">&quot;data&quot;</span>, StringType(), nullable=<span class="literal">True</span>)</span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&quot;text&quot;</span>)\</span><br><span class="line">        .schema(schema)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/people.txt&quot;</span>)</span><br><span class="line">    df.printSchema()</span><br><span class="line">    df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line"><span class="comment">#root</span></span><br><span class="line"><span class="comment"># |-- data: string (nullable = true)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#+-----------+</span></span><br><span class="line"><span class="comment">#|       data|</span></span><br><span class="line"><span class="comment">#+-----------+</span></span><br><span class="line"><span class="comment">#|Michael, 29|</span></span><br><span class="line"><span class="comment">#|   Andy, 30|</span></span><br><span class="line"><span class="comment">#| Justin, 19|</span></span><br><span class="line"><span class="comment">#+-----------+</span></span><br><span class="line"><span class="comment">#</span></span><br></pre></td></tr></table></figure>



<h4 id="读取json数据源"><a href="#读取json数据源" class="headerlink" title="读取json数据源"></a>读取json数据源</h4><p>使用format(“json”)读取json数据。</p>
<p>JSON类型一般不用写.schema，json自带，json带有列名和列类型（字符串和数字）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&quot;json&quot;</span>)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/people.json&quot;</span>)</span><br><span class="line">    df.printSchema()</span><br><span class="line">    df.show()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line"><span class="comment">#root</span></span><br><span class="line"><span class="comment"># |-- age: long (nullable = true)</span></span><br><span class="line"><span class="comment"># |-- name: string (nullable = true)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#+----+-------+</span></span><br><span class="line"><span class="comment">#| age|   name|</span></span><br><span class="line"><span class="comment">#+----+-------+</span></span><br><span class="line"><span class="comment">#|null|Michael|</span></span><br><span class="line"><span class="comment">#|  30|   Andy|</span></span><br><span class="line"><span class="comment">#|  19| Justin|</span></span><br><span class="line"><span class="comment">#+----+-------+</span></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure>



<h4 id="读取csv数据"><a href="#读取csv数据" class="headerlink" title="读取csv数据"></a>读取csv数据</h4><p>使用format(“csv”)读取csv数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&quot;csv&quot;</span>)\</span><br><span class="line">        .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&#x27;;&#x27;</span>)\</span><br><span class="line">        .option(<span class="string">&quot;header&quot;</span>, <span class="literal">False</span>)\</span><br><span class="line">        .option(<span class="string">&quot;encoding&quot;</span>, <span class="string">&quot;utf-8&quot;</span>)\</span><br><span class="line">        .schema(<span class="string">&quot;name STRING, age INT, job STRING&quot;</span>)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/people.csv&quot;</span>)</span><br><span class="line">    df.printSchema()</span><br><span class="line">    df.show()</span><br></pre></td></tr></table></figure>



<h4 id="读取parquet数据"><a href="#读取parquet数据" class="headerlink" title="读取parquet数据"></a>读取parquet数据</h4><p>使用format(“parquet”)读取parquet数据。</p>
<p>parquet是Spark中常用的一种列式存储文件格式，和Hive中的ORC差不多，它俩都是列存储格式。</p>
<p>parquet与普通文件的区别</p>
<ul>
<li><p>parquet内置了schema（列名\列类型\是否为空）</p>
</li>
<li><p>存储是以列作为存储格式</p>
</li>
<li><p>存储是序列化存储在文件中的（有压缩属性体积）</p>
</li>
</ul>
<p>Parquet文件不能直接打开，在pycharm中可以安卓插件【Avro and Parquet Viewer】来查看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;parquet&#x27;</span>)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/users.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">    df.printSchema()</span><br><span class="line">    df.show()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#输出</span></span><br><span class="line"><span class="comment">#root</span></span><br><span class="line"><span class="comment"># |-- name: string (nullable = true)</span></span><br><span class="line"><span class="comment"># |-- favorite_color: string (nullable = true)</span></span><br><span class="line"><span class="comment"># |-- favorite_numbers: array (nullable = true)</span></span><br><span class="line"><span class="comment"># |    |-- element: integer (containsNull = true)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#+------+--------------+----------------+</span></span><br><span class="line"><span class="comment">#|  name|favorite_color|favorite_numbers|</span></span><br><span class="line"><span class="comment">#+------+--------------+----------------+</span></span><br><span class="line"><span class="comment">#|Alyssa|          null|  [3, 9, 15, 20]|</span></span><br><span class="line"><span class="comment">#|   Ben|           red|              []|</span></span><br><span class="line"><span class="comment">#+------+--------------+----------------+</span></span><br><span class="line"><span class="comment">#  </span></span><br></pre></td></tr></table></figure>



<h2 id="DataFrame入门操作"><a href="#DataFrame入门操作" class="headerlink" title="DataFrame入门操作"></a>DataFrame入门操作</h2><p>DataFrame支持两种风格进行编程，分别是：</p>
<ul>
<li>DSL风格</li>
<li>SQL风格</li>
</ul>
<p><strong>DSL语法风格</strong></p>
<p>DSL称之为：领域特定语言。</p>
<p>其实就是指DataFrame的特有API。</p>
<p>DSL风格就是以调用API的方式来处理Data，比如：df.where().limit()</p>
<p><strong>SQL语法风格</strong></p>
<p>使用SQL语句处理DataFrame的数据。</p>
<p>比如：spark.sql(“select * from xxx”)</p>
<h3 id="DSL"><a href="#DSL" class="headerlink" title="DSL"></a>DSL</h3><h4 id="show方法"><a href="#show方法" class="headerlink" title="show方法"></a>show方法</h4><p>功能：展示DataFrame中的数据，默认20条</p>
<p>语法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.show(参数<span class="number">1</span>, 参数<span class="number">2</span>)</span><br><span class="line">- 参数<span class="number">1</span>：默认<span class="number">20</span>条，控制展示多少条</span><br><span class="line">- 参数<span class="number">2</span>：是否阶段列，默认只输出<span class="number">20</span>各字符的长度，过长不显示，要显示的话truncate=<span class="literal">True</span></span><br></pre></td></tr></table></figure>



<h4 id="printSchema方法"><a href="#printSchema方法" class="headerlink" title="printSchema方法"></a>printSchema方法</h4><p>功能：打印输出df的schema信息</p>
<p>语法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure>



<h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p>功能：选择DataFrame中指定的列（通过参数进行控制）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;parquet&#x27;</span>)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/users.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取对象</span></span><br><span class="line">    names = df[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(names)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#支持字符串方式传入</span></span><br><span class="line">    df.select(<span class="string">&#x27;name&#x27;</span>).show()</span><br><span class="line">    df.select([<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;favorite_color&#x27;</span>]).show()</span><br><span class="line">    df.select(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;favorite_numbers&quot;</span>).show()</span><br><span class="line">    <span class="comment">#支持column对象方式传入</span></span><br><span class="line">    df.select(df[<span class="string">&#x27;name&#x27;</span>], df[<span class="string">&#x27;favorite_color&#x27;</span>]).show()</span><br></pre></td></tr></table></figure>



<h4 id="filter和where"><a href="#filter和where" class="headerlink" title="filter和where"></a>filter和where</h4><p>功能：过滤DataFrame内的数据，返回一个过滤后的DataFrame</p>
<p>where和filter功能上是等价的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/people.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    df.where(<span class="string">&quot;age &lt; 30&quot;</span>).show()</span><br><span class="line">    df.where(df[<span class="string">&#x27;age&#x27;</span>] &lt; <span class="number">30</span>).show()</span><br><span class="line"></span><br><span class="line">    df.<span class="built_in">filter</span>(<span class="string">&quot;age &lt; 30&quot;</span>).show()</span><br><span class="line">    df.<span class="built_in">filter</span>(df[<span class="string">&#x27;age&#x27;</span>] &lt; <span class="number">30</span>).show()</span><br></pre></td></tr></table></figure>



<h3 id="groupBy-分组"><a href="#groupBy-分组" class="headerlink" title="groupBy 分组"></a>groupBy 分组</h3><p>功能：按照指定的列进行分组，返回值是GroupedData对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StringType</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;csv&#x27;</span>)\</span><br><span class="line">        .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;;&quot;</span>)\</span><br><span class="line">        .option(<span class="string">&quot;header&quot;</span>, <span class="literal">False</span>)\</span><br><span class="line">        .option(<span class="string">&quot;encoding&quot;</span>, <span class="string">&quot;utf-8&quot;</span>)\</span><br><span class="line">        .schema(<span class="string">&quot;name STRING, age INT, job STRING&quot;</span>)\</span><br><span class="line">        .load(<span class="string">&quot;hdfs://node1:8020/input/sql/people.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    df.groupBy(<span class="string">&#x27;job&#x27;</span>).count().show()</span><br><span class="line">    df.groupBy(<span class="string">&#x27;job&#x27;</span>, <span class="string">&#x27;age&#x27;</span>).count().show()</span><br></pre></td></tr></table></figure>

<p><strong>GroupedData对象</strong></p>
<p>GroupedData对象是一个特殊的DataFrame数据集。这个对象是经过groupBy后得到的返回值，内部记录了以分组形式存储的数据。</p>
<p>GroupedData对象的API：min、max、avg、sum和count等</p>
<h3 id="SQL风格"><a href="#SQL风格" class="headerlink" title="SQL风格"></a>SQL风格</h3><h4 id="注册DataFrame称为表"><a href="#注册DataFrame称为表" class="headerlink" title="注册DataFrame称为表"></a>注册DataFrame称为表</h4><p>要使用SQL风格的语法，需要将DataFrame注册成表，采用方式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.createTempView(<span class="string">&#x27;score&#x27;</span>) <span class="comment">#注册一个临时表</span></span><br><span class="line">df.createOrReplaceTempView(<span class="string">&#x27;score&#x27;</span>) <span class="comment">#注册一个临时表,如果存在进行替换</span></span><br><span class="line">df.createGlobalTempView(<span class="string">&#x27;score&#x27;</span>) <span class="comment">#注册一个全局表</span></span><br></pre></td></tr></table></figure>

<p><strong>全局表</strong></p>
<p>跨SparkSession对象使用，在一个程序内的多个SparkSession中均可调用，查询前带上前缀 <code>global_temp</code></p>
<p><strong>临时表</strong></p>
<p>只在当前SparkSession中可用</p>
<h4 id="SQL查询"><a href="#SQL查询" class="headerlink" title="SQL查询"></a>SQL查询</h4><p>注册好表后，可以通过</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sparksession.sql(sql语句)</span><br></pre></td></tr></table></figure>

<p>来执行sql查询，返回一个新的DataFrame</p>
<h4 id="pyspark-sql-functions包"><a href="#pyspark-sql-functions包" class="headerlink" title="pyspark.sql.functions包"></a>pyspark.sql.functions包</h4><p>pyspark.sql.functions包提供了一系列计算函数供SparkSQL使用。包中的函数返回值多数都是Column对象。</p>
<h4 id="数据清洗API"><a href="#数据清洗API" class="headerlink" title="数据清洗API"></a>数据清洗API</h4><h5 id="dropDuplicates"><a href="#dropDuplicates" class="headerlink" title="dropDuplicates"></a>dropDuplicates</h5><p>功能：对DF数据进行去重，如果重复数据有多条，取第一条。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 无参数是对数据进行整体去重</span></span><br><span class="line">df.dropDuplicates().show()</span><br><span class="line"><span class="comment"># 可以针对字段进行去重</span></span><br><span class="line">df.dropDuplicates([<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;job&#x27;</span>]).show()</span><br></pre></td></tr></table></figure>



<h5 id="dropna"><a href="#dropna" class="headerlink" title="dropna"></a>dropna</h5><p>功能：如果数据中包含null，通过dropna来进行判断，符合条件就删除这一行数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果有缺失，进行数据删除</span></span><br><span class="line"><span class="comment"># 无参数，为how=&#x27;any&#x27;,只要有一个列是null，数据整行删除。如果how=&#x27;all&#x27; 表示全部列为空，才会删除</span></span><br><span class="line">df.dropna().show()</span><br><span class="line"><span class="comment"># 指定阈值进行删除，thresh=3表示，有效的列最少有3个，这行数据才保留，设定thresh后，how参数无效</span></span><br><span class="line">df.dropna(thresh=<span class="number">3</span>).show()</span><br><span class="line"><span class="comment"># 可以指定阈值 配合指定列进行工作</span></span><br><span class="line"><span class="comment"># thresh=2，subset=[&#x27;name&#x27;, &#x27;age&#x27;]表示 针对这2列，有效列最少为2个才保留数据</span></span><br><span class="line">df.dropna(thresh=<span class="number">2</span>, subset=[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]).show()</span><br></pre></td></tr></table></figure>



<h5 id="fillna"><a href="#fillna" class="headerlink" title="fillna"></a>fillna</h5><p>功能：根据参数的规则，来进行null的替换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将所有为空，按照指定的值进行填充，任何空都会被填充</span></span><br><span class="line">df.fillna(<span class="string">&#x27;loss&#x27;</span>).show()</span><br><span class="line"><span class="comment"># 指定列进行填充</span></span><br><span class="line">df.fillna(<span class="string">&#x27;loss&#x27;</span>, subset=[<span class="string">&#x27;job&#x27;</span>]).show()</span><br><span class="line"><span class="comment"># 给定字典，设定各个列的填充规则</span></span><br><span class="line">df.fillna(&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;未知姓名&#x27;</span>, <span class="string">&#x27;age&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;job&#x27;</span>: <span class="string">&#x27;worker&#x27;</span>&#125;).show()</span><br></pre></td></tr></table></figure>



<h3 id="SparkSQL统一API写出DataFrame数据"><a href="#SparkSQL统一API写出DataFrame数据" class="headerlink" title="SparkSQL统一API写出DataFrame数据"></a>SparkSQL统一API写出DataFrame数据</h3><p>统一API语法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.write.mode().<span class="built_in">format</span>().option(K,V).save(PATH)</span><br><span class="line"><span class="comment"># mode 传入模式字符串，可选，append 追加，overwrite 覆盖， ignore 忽略，error 重复就报异常（默认）</span></span><br><span class="line"><span class="comment"># format 传入字符串格式，可选，text，csv，json，parquet，orc，avro，jdbc</span></span><br><span class="line"><span class="comment"># 注意text源只支持单列df写出</span></span><br><span class="line"><span class="comment"># option 设置属性</span></span><br><span class="line"><span class="comment"># save 写出路径，支持本地文件和hdfs</span></span><br></pre></td></tr></table></figure>



<h3 id="通过JDBC读写数据库（MYSQL）"><a href="#通过JDBC读写数据库（MYSQL）" class="headerlink" title="通过JDBC读写数据库（MYSQL）"></a>通过JDBC读写数据库（MYSQL）</h3><h4 id="安装驱动"><a href="#安装驱动" class="headerlink" title="安装驱动"></a>安装驱动</h4><p>驱动文件的版本要与mysql的版本对应</p>
<p>安装路径(linux)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/export/server/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/jars</span><br></pre></td></tr></table></figure>

<h4 id="写出"><a href="#写出" class="headerlink" title="写出"></a>写出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.write.mode(<span class="string">&#x27;overwrite&#x27;</span>).\</span><br><span class="line">       	<span class="built_in">format</span>(<span class="string">&#x27;jdbc&#x27;</span>).\</span><br><span class="line">        option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://node1:3306/test?useSSL=false&amp;useUnicode=true&quot;</span>).\</span><br><span class="line">        option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;u_data&quot;</span>).\</span><br><span class="line">        option(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;root&quot;</span>).\</span><br><span class="line">        option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;hadoop&quot;</span>).\</span><br><span class="line">        save()</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>jdbc连接字符串中，建议使用useSSL&#x3D;false确保连接可以正常连接（不使用SSL安全协议进行连接）</li>
<li>jdbc连接字符串中，建议使用useUnicode&#x3D;true来确保传输中不出现乱码</li>
<li>save()不要填参数</li>
<li>datable属性，指定写出的表名</li>
</ul>
<h4 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> df = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;jdbc&#x27;</span>). \</span><br><span class="line">        option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://node1:3306/test?useSSL=false&amp;useUnicode=true&quot;</span>). \</span><br><span class="line">        option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;u_data&quot;</span>). \</span><br><span class="line">        option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>). \</span><br><span class="line">        option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;hadoop&quot;</span>). \</span><br><span class="line">        load()</span><br><span class="line"></span><br><span class="line">df.show()</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>读出来是自带schema，不需要设置schema，因为数据库就有schema</li>
<li>load() 不需要加参数</li>
<li>dbtable：指定读取的表名</li>
</ul>
<h1 id="SparkSQL函数"><a href="#SparkSQL函数" class="headerlink" title="SparkSQL函数"></a>SparkSQL函数</h1><h2 id="定义UDF函数"><a href="#定义UDF函数" class="headerlink" title="定义UDF函数"></a>定义UDF函数</h2><p>SqarkSQL和Hive一样支持定义函数。</p>
<p>Hive自定义函数类型：</p>
<p><strong>1. UDF （User - Defined - Function）函数</strong></p>
<p>一对一的关系，输入一个值经过函数以后输出一个值；</p>
<p>在Hive中继承UDF类，方法名称为evaluate，返回值不能是void，其实就是实现一个方法。</p>
<p><strong>2. UDAF（User - Defined  Aggregation  Function）聚合函数</strong></p>
<p>多对一的关系，输入多个值输出一个值，通常与groupBy联合使用。</p>
<p><strong>3. UDTF（User  Defined  Table-Generating Functions）函数</strong></p>
<p>一对多的关系，输入一个值输出多个值（一行变多行）；</p>
<p>用户自定义生成函数，有点像flatMap。</p>
<blockquote>
<p>在SparkSQL中，目前仅仅支持UDF和UDAF，目前python仅支持UDF</p>
</blockquote>
<h4 id="SparkSQL定义UDF函数"><a href="#SparkSQL定义UDF函数" class="headerlink" title="SparkSQL定义UDF函数"></a>SparkSQL定义UDF函数</h4><h5 id="方式1-1"><a href="#方式1-1" class="headerlink" title="方式1"></a>方式1</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sparksession.udf.register()</span><br><span class="line"><span class="comment"># 注册的UDF可以用于DSL和SQL，返回值用于SQL风格，传参内给的名字用于SQL风格</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># udf对象 = sarksession.udf.register(参数1, 参数2, 参数3)</span></span><br><span class="line"><span class="comment"># 参数1：UDF名称，可用于SQL风格</span></span><br><span class="line"><span class="comment"># 参数2：被注册成UDF的方法名</span></span><br><span class="line"><span class="comment"># 参数3：声明UDF的返回值类型</span></span><br><span class="line"><span class="comment"># udf对象：返回值对象，是一个UDF对象，可用于DSL风格</span></span><br></pre></td></tr></table></figure>

<p><strong>方式2</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pyspark.sql.functions.udf</span><br><span class="line"><span class="comment"># 仅能用于DSL风格</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># from pyspark.sql import functions as F</span></span><br><span class="line"><span class="comment"># udf对象 = F.udf(参数1, 参数2)</span></span><br><span class="line"><span class="comment"># 参数1：被注册成UDF的方法名, 指具体的计算方法。如：def add(x,y): x + y  add就是将要被注册成UDF的方法名</span></span><br><span class="line"><span class="comment"># 参数2：声明UDF的返回值类型</span></span><br><span class="line"><span class="comment"># udf对象：返回值对象，是一个UDF对象，可用于DSL风格</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> IntegerType</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.\</span><br><span class="line">        appName(<span class="string">&#x27;study01&#x27;</span>).\</span><br><span class="line">        master(<span class="string">&#x27;local[*]&#x27;</span>).\</span><br><span class="line">        config(<span class="string">&#x27;spark.sql.shuffle.partitions&#x27;</span>, <span class="string">&#x27;4&#x27;</span>).\</span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    rdd = sc.textFile(<span class="string">&quot;hdfs://node1:8020/input/sql/stu_score.txt&quot;</span>). \</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;,&#x27;</span>)). \</span><br><span class="line">        <span class="built_in">map</span>(<span class="keyword">lambda</span> x: [<span class="built_in">int</span>(x[<span class="number">0</span>]), x[<span class="number">1</span>], <span class="built_in">int</span>(x[<span class="number">2</span>])])</span><br><span class="line"></span><br><span class="line">    df = rdd.toDF([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;score&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方式1 注册UDF，功能：将数字乘于10</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">num_ride_10</span>(<span class="params">num</span>):</span><br><span class="line">        <span class="keyword">return</span> num * <span class="number">10</span></span><br><span class="line">    <span class="comment"># 返回值用于DSL风格，内部注册的名称用于SQL（字符串表达式）风格</span></span><br><span class="line">    <span class="comment"># 参数1：UDF名称（可用于SQL风格），参数2：UDF的本体方法（处理逻辑），参数3：声明返回值类型</span></span><br><span class="line">    <span class="comment"># 返回值可用于DSL</span></span><br><span class="line">    udf2 = spark.udf.register(<span class="string">&quot;udf1&quot;</span>, num_ride_10, IntegerType())</span><br><span class="line"></span><br><span class="line">    df.select(udf2(df[<span class="string">&#x27;score&#x27;</span>])).show()</span><br><span class="line">    df.selectExpr(<span class="string">&#x27;udf1(score)&#x27;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#房市注册，仅能用于DSL风格</span></span><br><span class="line">    udf3 = F.udf(num_ride_10, IntegerType())</span><br><span class="line">    df.select(udf3(df[<span class="string">&#x27;score&#x27;</span>])).show()</span><br></pre></td></tr></table></figure>



<p>注意：</p>
<p>返回int，可以用IntegerType</p>
<p>返回小数，可以用FloatType或者DoubleType</p>
<p>返回数组list，可用ArrayType</p>
<p>返回字典，可用StructType</p>
<p>这些Spark内置的数据类型均存储在 <code>pyspark.sql.types</code> 包中</p>
<h2 id="使用窗口函数"><a href="#使用窗口函数" class="headerlink" title="使用窗口函数"></a>使用窗口函数</h2><h3 id="开窗函数"><a href="#开窗函数" class="headerlink" title="开窗函数"></a>开窗函数</h3><p>开窗函数的引入是为了既显示聚集前的数据，又显示聚集后的数据。即在每一行的最后一列添加聚合函数的结果。</p>
<p>开窗用于为行定义一个窗口（窗口指运算将要操作的行的集合），它对一组值进行操作，不需要使用GROUP BY子句对数据进行分组，能够在同一行中同时返回基础行的列和聚合列。</p>
<h3 id="聚合函数和开窗函数"><a href="#聚合函数和开窗函数" class="headerlink" title="聚合函数和开窗函数"></a>聚合函数和开窗函数</h3><p>聚合函数是将多行变成一行， count， avg，…</p>
<p>开窗函数是将一行变成多行；</p>
<p>聚合函数如果要显示其他的列必须将列加入到group by中</p>
<p>开窗函数可以不用group by，直接将所有信息显示出来</p>
<h3 id="开窗函数分类"><a href="#开窗函数分类" class="headerlink" title="开窗函数分类"></a>开窗函数分类</h3><ol>
<li><p>聚合开窗函数 </p>
<p>聚合函数（列） OVER（选项），这里的选项可以是PARTITION BY子句，但不可以是ORDER BY 子句。</p>
</li>
<li><p>排序开窗函数 </p>
<p>排序函数（列） OVER（选项），这里的选项可以是ORDER BY子句，也可以是OVER（PARTITION BY 子句 ORDER BY 子句），但不可以是PARTITION BY 子句。</p>
</li>
<li><p>分区类型NTILE的窗口函数</p>
</li>
</ol>
<h3 id="窗口函数的语法"><a href="#窗口函数的语法" class="headerlink" title="窗口函数的语法"></a>窗口函数的语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 聚合类型 SUM\MIN\MAX\AVG\COUNT</span></span><br><span class="line"><span class="built_in">sum</span>() OVER([PARTITION BY XXX][ORDER BY XXX [DESC]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排序类型： ROW_NUMBER|RANK|DENSE_RANK</span></span><br><span class="line">ROW_NUMBER() OVER([PARTITION BY XXX][ORDER BY XXX [DESC]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分区类型： NTILE</span></span><br><span class="line">NTILE(number) OVER([PARTITION BY XXX][ORDER BY XXX [DESC]])</span><br></pre></td></tr></table></figure>





<h1 id="SparkSQL运行流程"><a href="#SparkSQL运行流程" class="headerlink" title="SparkSQL运行流程"></a>SparkSQL运行流程</h1><h2 id="RDD执行流程"><a href="#RDD执行流程" class="headerlink" title="RDD执行流程"></a>RDD执行流程</h2><blockquote>
<p>代码 -&gt; DAG调度器逻辑任务 -&gt; Task调度器任务分配和管理监控 -&gt; Worker干活</p>
</blockquote>
<h2 id="SparkSQL的自动优化"><a href="#SparkSQL的自动优化" class="headerlink" title="SparkSQL的自动优化"></a>SparkSQL的自动优化</h2><p>RDD的运行完全按照开发者的代码执行，如果开发者水平有限，RDD的执行效率也会受到影响。</p>
<p>而SparkSQL会对写完的代码，执行“自动优化”，以提升代码的运行效率，避免开发者水平影响到代码执行效率。</p>
<p>其原因是RDD中的数据类型不限格式和结构，DataFrame是二维表结构，可以被针对处理。</p>
<p>SparkSQL的自动优化，依赖于Catalyst优化器</p>
<h2 id="Catalyst优化器"><a href="#Catalyst优化器" class="headerlink" title="Catalyst优化器"></a>Catalyst优化器</h2><p>Catalyst优化器是为了解决过多依赖Hive的问题，用它替代Hive中的优化器。</p>
<p>SparkSQL架构如下：</p>
<p><img src="/2022/02/18/SparkSQL/image-20221211112825489.png" alt="image-20221211112825489"></p>
<ol>
<li>API层简单的说就是Spark会通过一些API接受SQL语句。</li>
<li>收到SQL语句后，将其交给Catalyst，Catalyst负责解析SQL，生成执行计划等。</li>
<li>Catalyst的输出应该是RDD的执行计划。</li>
<li>最终交由集群运行。</li>
</ol>
<p>具体流程：</p>
<p><img src="/2022/02/18/SparkSQL/image-20221211114333532.png" alt="image-20221211114333532"></p>
<p><strong>step1：解析SQL，并且生成AST（抽象语法树）</strong></p>
<p><img src="/2022/02/18/SparkSQL/image-20221211114438677.png" alt="image-20221211114438677"></p>
<p><strong>step2：在AST中加入元数据信息，这一步是为了优化，例如col &#x3D; col这样的条件</strong></p>
<p><img src="/2022/02/18/SparkSQL/image-20221211114704326.png" alt="image-20221211114704326"></p>
<p><strong>step3：对已经加入元数据的AST，输入优化器，进行优化</strong></p>
<p>两种常见的优化：</p>
<p><img src="/2022/02/18/SparkSQL/image-20221211115003319.png" alt="image-20221211115003319"></p>
<p><img src="/2022/02/18/SparkSQL/image-20221211115052191.png" alt="image-20221211115052191"></p>
<p><strong>step4：上面的过程生成的AST其实最终还无法运行，这个AST叫做逻辑计划，结束后需要生成物理计划，从而生成RDD来运行</strong></p>
<p>在生成“物理计划”的时候，会经过“成本模型”对整棵树再次执行优化，选择一个更好的计划。</p>
<p>在生成“物理计划”以后，因为考虑到性能，所以会使用代码生成，在机器中运行。</p>
<p><strong>总结</strong></p>
<p>catalyst优化细节很多，大方面的优化有2点：</p>
<ul>
<li><p>谓词下推（Predicate Pushdown）\ 断言下推：将逻辑判断提前到前面，以减少shuffle阶段的数据量， 即<strong>行过滤，提前执行where</strong></p>
</li>
<li><p>列值裁剪（Column Pruning）：将加载的列进行裁剪，尽量减少被处理的数据的宽度，即<strong>列过滤，提前规划select的字段数量</strong></p>
</li>
</ul>
<h2 id="SparkSQL执行流程"><a href="#SparkSQL执行流程" class="headerlink" title="SparkSQL执行流程"></a>SparkSQL执行流程</h2><p><img src="/2022/02/18/SparkSQL/image-20221211120120259.png" alt="image-20221211120120259"></p>
<ol>
<li>提交SparkSQL代码</li>
<li>catalyst优化<ol>
<li>生成原始AST语法树</li>
<li>标记AST元数据</li>
<li>进行断言下推和列值裁剪，以及其它方面的优化作用在AST上</li>
<li>将最终AST得到，生成执行计划</li>
<li>将执行计划翻译为RDD代码</li>
</ol>
</li>
<li>Driver执行环境入口构建（SparkSession）</li>
<li>DAG调度器规划逻辑任务</li>
<li>TASK调度器分配逻辑任务到具体Executor上工作并监控管理任务</li>
<li>Worker干活</li>
</ol>
<h1 id="SparkSQL整合Hive"><a href="#SparkSQL整合Hive" class="headerlink" title="SparkSQL整合Hive"></a>SparkSQL整合Hive</h1><h2 id="Hive组件"><a href="#Hive组件" class="headerlink" title="Hive组件"></a>Hive组件</h2><ol>
<li>SQL优化翻译器（执行引擎），翻译SQL到MapReduce并提交到YARN执行</li>
<li>MetaStore元数据管理中心</li>
</ol>
<h2 id="Spark-On-Hive原理"><a href="#Spark-On-Hive原理" class="headerlink" title="Spark On Hive原理"></a>Spark On Hive原理</h2><p>对于Spark来说，它自身是一个执行引擎，没有元数据管理功能。</p>
<p>而Spark和Hive结合，<strong>Spark提供执行引擎能力</strong>，<strong>Hive的MetaStore提供元数据管理能力</strong>，就产生Spark On Hive。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>根据原理，就是Spark能够连接上Hive的MetaStore即可。</p>
<p>步骤1：</p>
<p>在Spark的conf目录中，创建hive-site.xml，内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&#x27;text/xsl&#x27; href=&#x27;configuration.xsl&#x27;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- spark创建表存到哪里 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- hive的metastore在哪 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>步骤2：</p>
<p>将mysql的驱动jar包放到spark的jars目录。</p>
<blockquote>
<p>因为要连接元数据，会有部分功能连接到mysql库，需要mysql驱动包</p>
</blockquote>
<p>步骤3：</p>
<p>确保hive配置了MetaStore相关服务，检查hive配置文件目录内的：hive-site.xml，确保有如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>步骤4：</p>
<p>启动hive的MetaStore服务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup /export/server/apache-hive-3.1.2-bin/bin/hive --service metastore 2&gt;&amp;1 &gt;&gt; /var/log/metastore.log &amp;</span><br></pre></td></tr></table></figure>

<p>nohup：后台启动程序的命令，使用</p>
<ul>
<li><code>nohup xxx命令 &amp;</code>  将命令后台执行，日志输出到当前目录的nohup.out中</li>
<li><code>nohup xxx命令 2&gt;&amp;1 &gt;&gt; 某路径下的日志文件 &amp;</code>  将命令后台执行，将日志输出到你指定的路径中</li>
</ul>
<p>测试：</p>
<p>bin&#x2F;pyspark：在里面直接写spark.sql(“sql语句”).show()即可</p>
<h2 id="在代码中集成Spark-On-Hive"><a href="#在代码中集成Spark-On-Hive" class="headerlink" title="在代码中集成Spark On Hive"></a>在代码中集成Spark On Hive</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.\</span><br><span class="line">        builder.appName(<span class="string">&quot;create df&quot;</span>).\</span><br><span class="line">        master(<span class="string">&quot;local[*]&quot;</span>).\</span><br><span class="line">        config(<span class="string">&quot;spark.sql.shuffle.paratitions&quot;</span>, <span class="string">&quot;4&quot;</span>).\</span><br><span class="line">        config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, <span class="string">&quot;hdfs://node1:8020/user/hive/warehouse&quot;</span>).\</span><br><span class="line">        config(<span class="string">&quot;hive.metastore.uris&quot;</span>, <span class="string">&quot;thrift://node1:9083&quot;</span>).\</span><br><span class="line">        enableHiveSupport().\ </span><br><span class="line">        getOrCreate()</span><br><span class="line"></span><br><span class="line">    spark.sql(<span class="string">&quot;select * from itheima.t_2&quot;</span>).show()</span><br></pre></td></tr></table></figure>



<h1 id="分布式SQL引擎配置"><a href="#分布式SQL引擎配置" class="headerlink" title="分布式SQL引擎配置"></a>分布式SQL引擎配置</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Spark中有个服务叫做：ThriftServer服务，可以启动并监听在10000端口。这个服务对外提供功能，我们可以用数据库工具或者代码连接，直接写SQL操作Spark。</p>
<p><img src="/2022/02/18/SparkSQL/image-20221211223801811.png" alt="image-20221211223801811"></p>
<p>当使用ThriftServer后，相当于是一个持续性的Spark On Hive集成模式。它提供10000端口，持续对外提供服务，外部可以通过这个端口连接上来，写SQL，让Spark运行。</p>
<h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><p>启动ThriftServer</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">SPARK_HOME/sbin/start-thriftserver.sh --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.server2.thrift.bind.host=node1 --master <span class="built_in">local</span>[2]</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">master选择<span class="built_in">local</span>，每一条sql都是<span class="built_in">local</span>进程执行</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">master选择yarn，每一条sql都是在YARN集群中执行</span></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/" class="post-title-link" itemprop="url">Spark内核调度</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-09 14:07:07" itemprop="dateCreated datePublished" datetime="2022-02-09T14:07:07+08:00">2022-02-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-08 11:02:06" itemprop="dateModified" datetime="2022-12-08T11:02:06+08:00">2022-12-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h1><p>Spark的核心是根据RDD来实现的，Spark Scheduler则为Spark核心实现的重要一环，其作用就是任务调度。Spark的任务调度就是如何组织任务去处理RDD中每个分区的数据，根据RDD的依赖关系构建DAG，基于DAG划分Stage，将每个Stage中的任务发到指定的节点运行。基于Spark的任务调度原理，可以合理规划资源利用，做到尽可能最少的资源高效地完成任务计算。</p>
<p>WordCount的DAG图：</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207141854497.png" alt="image-20221207141854497"></p>
<h2 id="DAG-1"><a href="#DAG-1" class="headerlink" title="DAG"></a>DAG</h2><p>DAG：有向无环图（有方向没有形成闭环的一个执行流程图），标识代码的逻辑执行流程。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207142235571.png" alt="image-20221207142235571"></p>
<p><strong>JOB和Action</strong></p>
<p>Action：返回值不是RDD的算子。它的作用是一个出发开关，会将Action算子之前的一串rdd依赖链条执行起来。一个Action会产生一个DAG图。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207142737106.png" alt="image-20221207142737106"></p>
<blockquote>
<p>1个Action会产生一个DAG，会在程序运行中产生一个JOB。 <code>1个Action = 1个DAG = 1个JOB</code></p>
<p>一个代码运行起来，在Spark中称之为Application。1个Application中，可以有多个JOB，每个JOB内含有一个DAG，同时每个JOB都是由一个Action产生的。</p>
</blockquote>
<p><strong>DAG和分区</strong></p>
<p>Spark是分布式（多分区）的，那么DAG和分区之间也是有关联的。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143426357.png" alt="image-20221207143426357"></p>
<h1 id="DAG的宽窄依赖和阶段划分"><a href="#DAG的宽窄依赖和阶段划分" class="headerlink" title="DAG的宽窄依赖和阶段划分"></a>DAG的宽窄依赖和阶段划分</h1><p>SparkRDD前后之间的关系分为<code>宽依赖</code>和<code>窄依赖</code>。</p>
<p>窄依赖：父RDD的一个分区，全部将数据发给子RDD的一个分区。</p>
<p>宽依赖：父RDD的一个分区，将数据发给RDD的多个分区。</p>
<p>宽依赖还有一个别名：shuffle</p>
<h2 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h2><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143755864.png" alt="image-20221207143755864"></p>
<h2 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h2><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143830716.png" alt="image-20221207143830716"></p>
<h2 id="阶段划分"><a href="#阶段划分" class="headerlink" title="阶段划分"></a>阶段划分</h2><p>对于Spark来说，会根据DAG，按照宽依赖，划分不同的DAG阶段。</p>
<p>划分依据：从后向前，遇到宽依赖，就划分出一个阶段，称之为stage。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208092610241.png" alt="image-20221208092610241"></p>
<p>在stage内部，一定都是窄依赖。</p>
<h1 id="内存迭代计算"><a href="#内存迭代计算" class="headerlink" title="内存迭代计算"></a>内存迭代计算</h1><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208094448308.png" alt="image-20221208094448308"></p>
<p>如图，基于带有分区的DAG，从图中可以得到逻辑上的最优task分配。一个task是一个线程来具体执行。图中task1中rdd1、rdd2和rdd3的迭代计算，都是由一个task（线程）完成，这一阶段的这条线，是纯内存计算。task1、task2和task3形成了3个并行的内存计算管道。</p>
<p>Spark默认受全局并行度的限制，除了个别算子有特殊分区情况，大部分算子，都会遵循全局并行的要求，来规划自己的分区数。如果全局并行度是3，其实大部分算子分区都是3。</p>
<blockquote>
<p>在Spark中，推荐只设置全局并行度，不要在算子上设置并行度</p>
</blockquote>
<h1 id="Spark并行度"><a href="#Spark并行度" class="headerlink" title="Spark并行度"></a>Spark并行度</h1><p>Spark的并行：在同一时间内，有多少个task在同时运行。</p>
<p>并行度：并行能力的设置。</p>
<p>比如：设置并行度是6，就有6个task并行执行，rdd的分区就被规划成6个分区。</p>
<h2 id="如何设置并行度"><a href="#如何设置并行度" class="headerlink" title="如何设置并行度"></a>如何设置并行度</h2><p>可以在代码中和配置文件中以及提交程序的客户端参数中设置。</p>
<p>优先级从高到低：</p>
<ol>
<li>代码中</li>
<li>客户端提交参数中</li>
<li>配置文件中</li>
<li>默认（1，但是不会全部以1来执行，多数情况下基于读取文件的分片数量来作为默认并行度）</li>
</ol>
<p>全局并行度配置参数</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spark.default.parallelism</span></span><br></pre></td></tr></table></figure>

<p><strong>推荐全局设置并行度</strong></p>
<p>配置文件中：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">conf/spark-defaults.conf中设置</span></span><br><span class="line"><span class="attr">spark.default.parallelism</span> <span class="string">100</span></span><br></pre></td></tr></table></figure>

<p>在客户端提交参数中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --conf &quot;spark.default.parallelism=100&quot;</span><br></pre></td></tr></table></figure>

<p>在代码中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf()</span><br><span class="line">conf.<span class="built_in">set</span>(<span class="string">&quot;spark.default.parallelism&quot;</span>, <span class="string">&quot;100&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>全局并行度是推荐设置，不要针对RDD改分区，可能会影响内存迭代管道的构建，或者会产生额外的shuffle</p>
</blockquote>
<h2 id="集群中如何规划并行度"><a href="#集群中如何规划并行度" class="headerlink" title="集群中如何规划并行度"></a>集群中如何规划并行度</h2><p>设置为cpu总核的2<del>10倍。比如集群可用cpu核心是100个，建议并行度是200</del>1000。</p>
<p>设置成cpu核心的倍数，目的是让cpu尽量不空闲，执行完一个task后有其他task可以继续执行，提高cpu利用率。</p>
<h1 id="Spark任务调度"><a href="#Spark任务调度" class="headerlink" title="Spark任务调度"></a>Spark任务调度</h1><p>Spark的任务，由Driver进行调度，这个工作包括：</p>
<ol>
<li>逻辑DAG产生</li>
<li>分区DAG产生</li>
<li>Task划分</li>
<li>将Task分配给Executor并监控其工作</li>
</ol>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208100811888.png" alt="image-20221208100811888"></p>
<p>如图：Spark程序的调度流程：</p>
<ol>
<li>构建Driver</li>
<li>构建SparkContext（执行环境入口对象）</li>
<li>基于DAG Scheduler（DAG调度器）构建逻辑Task分配</li>
<li>基于TaskScheduler（Task调度器）将逻辑Task分配到各个Executor上干活，并监控它们。</li>
<li>Worker（Executor），被TaskScheduler管理监控，听从它们的指令干活，并定期汇报进度。</li>
</ol>
<p>Driver内的两个组件：</p>
<ol>
<li>DAG调度器：将逻辑DAG图进行处理，最终得到逻辑上的Task划分。</li>
<li>TASK调度器：基于DAG Scheduler的产出，类规划这些逻辑TASK应该在哪些物理的Executor上运行，以及监控管理它们的运行。</li>
</ol>
<h1 id="Spark概念名词大全"><a href="#Spark概念名词大全" class="headerlink" title="Spark概念名词大全"></a>Spark概念名词大全</h1><ul>
<li>ClusterManager：在Standalone模式中即为Master（主节点），控制整个集群，监控Worker。在YARN模式中为资源管理器。</li>
<li>Worker：从节点，负责控制计算节点，启动Executor。在YARN模式中为NodeManager，负责计算节点的控制。</li>
<li>Driver：运行Application的main()函数并创建SparkContext。</li>
<li>Executor：执行器，在worker node上执行任务的组件、用于启动线程池运行任务。每个Application拥有独立的一组Executors。</li>
<li>SparkContext：整个应用的上下文，控制应用的生命周期。</li>
<li>RDD：Spark的基本计算单元，一组RDD可形成执行的有向无环图RDD Graph。</li>
<li>DAG Scheduler：实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</li>
<li>TaskScheduler：将任务（Task）分发给Executor执行。（所以Executor执行的就是我们的代码）</li>
<li>Stage：一个Spark作业一般包含一到多个Stage。</li>
<li>Task：一个Stage包含一到多个Task，通过多个Task实现并行运行的功能。</li>
<li>Transformations：转换(Transformations) (如：map, filter, groupBy, join等)，Transformations操作是Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算。（后面的wc例子就会有很好的说明）</li>
<li>Actions：操作(Actions) (如：count, collect, save等)，Actions操作会返回结果或把RDD数据写到存储系统中。Actions是触发Spark启动计算的动因。</li>
<li>SparkEnv：线程级别的上下文，存储运行时的重要组件的引用。SparkEnv内创建并包含如下一些重要组件的引用。</li>
<li>MapOutPutTracker：负责Shuffle元信息的存储。</li>
<li>BroadcastManager：负责广播变量的控制与元信息的存储。</li>
<li>BlockManager：负责存储管理、创建和查找块。</li>
<li>MetricsSystem：监控运行时性能指标信息。</li>
<li>SparkConf：负责存储配置信息。</li>
</ul>
<h2 id="Spark层级梳理"><a href="#Spark层级梳理" class="headerlink" title="Spark层级梳理"></a>Spark层级梳理</h2><ol>
<li>一个Spark环境可以运行多个Application。</li>
<li>一个代码运行起来，会称为一个Application。</li>
<li>Application内部可以有多个Job</li>
<li>每个Job由一个Action产生，并且每个Job有自己的DAG执行图</li>
<li>一个Job的DAG图，会基于窄依赖和宽依赖划分成不同的阶段</li>
<li>不同阶段内基于分区数量，形成多个并行的内存迭代管道</li>
<li>每个内存迭代管道形成一个Task（DAG调度器划分将JOB内划分出具体的Task任务，一个JOB被划分出来的task在逻辑上称之为这个job的taskset）</li>
</ol>
<h2 id="Spark-Shuffle"><a href="#Spark-Shuffle" class="headerlink" title="Spark Shuffle"></a>Spark Shuffle</h2><h3 id="MapReduce-Shuffle"><a href="#MapReduce-Shuffle" class="headerlink" title="MapReduce Shuffle"></a>MapReduce Shuffle</h3><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208103531463.png" alt="image-20221208103531463"></p>
<h3 id="Spark-Shuffle-1"><a href="#Spark-Shuffle-1" class="headerlink" title="Spark Shuffle"></a>Spark Shuffle</h3><p>Spark在DAG调度阶段会将一个Job划分成多个Stage，上游Stage做map工作，下游Stage做Reduce工作，其本质上还是MapReduce计算框架。</p>
<p>Shuffle是连接map和reduce之间的桥梁，它将map的输出对应到reduce输入中，涉及到序列化、跨节点网络IO以及磁盘读写IO等。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208103955136.png" alt="image-20221208103955136"></p>
<p>Spark的Shuffle分为Write和Read两个阶段，分属于两个不同的Stage，前者是Parent Stage的最后一步，后者是Child Stage的第一步。</p>
<p>执行Shuffle的主体是Stage中的并发任务，这些任务份ShuffleMapTask和ResultTask两种，ShuffleMapTask要进行Shuffle，ResultTask负责返回计算结果，一个Job中只有最后的Stage采用ResultTask，其他的均为ShuffleMapTask。如果要按照map段和reduce端来分析的话，ShuffleMapTask可以即是map端任务，又是reduce端任务，因为Spark中Shuffle是可以串行的；ResultTask则只能充当reduce端任务的角色。</p>
<h3 id="ShuffleManager（Shuffle管理器）"><a href="#ShuffleManager（Shuffle管理器）" class="headerlink" title="ShuffleManager（Shuffle管理器）"></a>ShuffleManager（Shuffle管理器）</h3><p>ShuffleManager：负责Shuffle过程的执行、计算和处理。</p>
<p>实现方式有两种：HashShuffleManager和SortShuffleManager</p>
<h4 id="HashShuffleManager"><a href="#HashShuffleManager" class="headerlink" title="HashShuffleManager"></a>HashShuffleManager</h4><p>Spark1.2以前，默认的shuffle计算引擎，其缺点是会产生大量的中间磁盘文件，进而有大量的磁盘IO操作影响了性能。</p>
<h4 id="SortShuffleManager"><a href="#SortShuffleManager" class="headerlink" title="SortShuffleManager"></a>SortShuffleManager</h4><p>Spark1.2后，默认的ShuffleManager。对比HashShuffleManager的改进，每个task在进行shuffle操作时，虽然也会产生大量的中间磁盘文件，但是最后会将所有的临时文件合并（merge）成一个磁盘文件，因此每个task就只有一个磁盘文件。在下一次读取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/" class="post-title-link" itemprop="url">Spark核心编程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-05 11:11:10" itemprop="dateCreated datePublished" datetime="2022-02-05T11:11:10+08:00">2022-02-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-08 10:20:18" itemprop="dateModified" datetime="2022-12-08T10:20:18+08:00">2022-12-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h1><h2 id="RDD-定义"><a href="#RDD-定义" class="headerlink" title="RDD 定义"></a>RDD 定义</h2><blockquote>
<p>RDD(Resilient Distributed Dataset) 弹性分布式数据集，是Spark中最基本的数据抽象，代表一个不可变、可分区、里面的元素可以并行计算的集合</p>
</blockquote>
<ul>
<li>Dataset：一个数据集合，用于存放数据的</li>
<li>Distributed：分布式存储，可用于并行计算</li>
<li>Resilient：可以存储在内存中或磁盘中</li>
</ul>
<h2 id="RDD五大特性"><a href="#RDD五大特性" class="headerlink" title="RDD五大特性"></a>RDD五大特性</h2><h3 id="RDD是有分区的"><a href="#RDD是有分区的" class="headerlink" title="RDD是有分区的"></a>RDD是有分区的</h3><p>RDD的分区是RDD数据存储的最小单位</p>
<p>一份RDD的数据，本质上是分割成了多个分区</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]).glom().collect()</span><br><span class="line">[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]]                                         </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>], <span class="number">3</span>).glom().collect()</span><br><span class="line">[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br></pre></td></tr></table></figure>

<h3 id="RDD的方法会作用在其所有分区上"><a href="#RDD的方法会作用在其所有分区上" class="headerlink" title="RDD的方法会作用在其所有分区上"></a>RDD的方法会作用在其所有分区上</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>], <span class="number">3</span>).glom().collect()</span><br><span class="line">[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>], <span class="number">3</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x * <span class="number">10</span>).glom().collect()</span><br><span class="line">[[<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>], [<span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>], [<span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>, <span class="number">100</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment">#RDD 3个分区，在执行了map操作，将数据都乘以10后，3个分区的数据都乘以10了</span></span><br></pre></td></tr></table></figure>

<h3 id="RDD之间是有依赖关系（RDD有血缘关系）"><a href="#RDD之间是有依赖关系（RDD有血缘关系）" class="headerlink" title="RDD之间是有依赖关系（RDD有血缘关系）"></a>RDD之间是有依赖关系（RDD有血缘关系）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd1 = sc.textFile(<span class="string">&quot;hdfs://node1:8020/input/words.txt&quot;</span>)</span><br><span class="line">    rdd2 = rdd1.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    rdd3 = rdd2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line">    rdd4 = rdd3.reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd4.collect())</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#rdd2依赖rdd1，rdd3依赖rdd2，rdd4依赖rdd3</span></span><br></pre></td></tr></table></figure>



<h3 id="Key-Value型的RDD可以有分区器（可能的）"><a href="#Key-Value型的RDD可以有分区器（可能的）" class="headerlink" title="Key-Value型的RDD可以有分区器（可能的）"></a>Key-Value型的RDD可以有分区器（可能的）</h3><p>默认分区器：Hash分区规则，可以手动设置一个分区器（rdd.partitionBy的方法来设置）</p>
<p>这个特性是可能的，因为并不是所有的RDD都是Key-Value型</p>
<p>Key-Value RDD：RDD中存储的是二元元组，这就是Key-Value型RDD</p>
<p>二元元组：只有2个元素的元组，比如（’hadoop’, 1)</p>
<h3 id="RDD的分区规划，会尽量靠近数据所在的服务器"><a href="#RDD的分区规划，会尽量靠近数据所在的服务器" class="headerlink" title="RDD的分区规划，会尽量靠近数据所在的服务器"></a>RDD的分区规划，会尽量靠近数据所在的服务器</h3><p>在初始RDD（读取数据的时候）规划的时候，分区会尽量规划到存储数据所在的服务器上。这样可以走本地读取，避免网络读取。</p>
<p>本地读取：Executor所在的服务器，同样是一个DataNode，同时这个DataNode上有它要读取的数据，所以可以直接取机器硬盘上的数据，无需走网络传输。</p>
<p>Spark会在确保并行计算能力的前提下，尽量确保本地读取，从而提升性能</p>
<h1 id="RDD编程"><a href="#RDD编程" class="headerlink" title="RDD编程"></a>RDD编程</h1><h2 id="程序入口SparkContext对象"><a href="#程序入口SparkContext对象" class="headerlink" title="程序入口SparkContext对象"></a>程序入口SparkContext对象</h2><p>Spark RDD编程的程序入口对象是SparkContext对象（不论何种语言）</p>
<p>只有构建出SparkContext，基于它才能执行后续的API调用和计算</p>
<p>本质上，SparkContext对编程来说，主要功能就是创建第一个RDD出来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h2><p>RDD的创建主要有2种方式：</p>
<ul>
<li>通过并行化集合创建（本地对象转分布式RDD）</li>
<li>读取外部数据源（读取文件）</li>
</ul>
<p><strong>并行化创建</strong></p>
<p>并行化创建是指将本地集合 -&gt; 转向分布式RDD</p>
<p><strong>获取RDD分区数</strong></p>
<p><code>getNumPartitions</code>  API     </p>
<p>获取RDD分区数量，返回值是Int数字</p>
<p><strong>读取文件创建</strong></p>
<p><code>textFile</code> API   </p>
<p>可以读取本地文件，也可以读取HDFS数据</p>
<p><code>wholeTextFile</code> API   </p>
<p>小文件读取专用，适合读取一堆小文件</p>
<h2 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h2><p>分布式集合对象上的API称之为算子</p>
<p><strong>算子分类</strong></p>
<ul>
<li>Transformation：转换算子</li>
<li>Action：动作（行动）算子</li>
</ul>
<p><strong>Transformation算子</strong></p>
<p>定义：RDD的算子，返回值仍旧是一个RDD的，称为转换算子</p>
<p>特性：这类算子是<code>lazy  懒加载</code>的。如果没有action算子，Tranformation算子是不工作的。</p>
<p><strong>Action算子</strong></p>
<p>定义：返回值不是RDD的就是Action算子</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206134922918.png" alt="image-20221206134922918"></p>
<h2 id="常用的Transformation算子"><a href="#常用的Transformation算子" class="headerlink" title="常用的Transformation算子"></a>常用的Transformation算子</h2><h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><p>功能：map算子，是将RDD的数据一条条处理（处理的逻辑基于map算子中接收的处理函数），返回新的RDD</p>
<p>语法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206135501887.png" alt="image-20221206135501887"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">map_func</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">return</span> data * <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># f:(T) -&gt; U</span></span><br><span class="line">    <span class="built_in">print</span>(rdd.<span class="built_in">map</span>(map_func).collect())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#匿名lambda的方式</span></span><br><span class="line">    <span class="built_in">print</span>(rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x * <span class="number">10</span>).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[10, 20, 30, 40, 50, 60, 70, 80]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[10, 20, 30, 40, 50, 60, 70, 80]</span></span><br></pre></td></tr></table></figure>



<h3 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h3><p>功能：对RDD执行map操作，然后进行<strong>解除嵌套</strong>操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#嵌套的list</span></span><br><span class="line"><span class="built_in">list</span> = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line"><span class="comment">#解除嵌套的list</span></span><br><span class="line"><span class="built_in">list</span> = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="string">&#x27;a b c&#x27;</span>, <span class="string">&#x27;a c e&#x27;</span>, <span class="string">&#x27;e c a&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(rdd.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27; &#x27;</span>)).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;c&#x27;, &#x27;e&#x27;, &#x27;e&#x27;, &#x27;c&#x27;, &#x27;a&#x27;]      </span></span><br></pre></td></tr></table></figure>



<h3 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h3><p>功能：针对KV型的RDD，自动按照key分组，然后根据你提供的聚合逻辑，完成组内数据（value）的聚合操作</p>
<p>用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd.reduceByKey(func)</span><br><span class="line"><span class="comment"># func: (V, V) -&gt; V</span></span><br><span class="line"><span class="comment"># 接受2个传入参数（类型要一致），返回一个返回值，类型和传入要求一致</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;c&#x27;</span>,<span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>,<span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>)])</span><br><span class="line">    <span class="built_in">print</span>(rdd.reduceByKey(<span class="keyword">lambda</span> a, b: a + b).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;b&#x27;, 2), (&#x27;c&#x27;, 1), (&#x27;a&#x27;, 3)]      </span></span><br></pre></td></tr></table></figure>



<h3 id="groupBy"><a href="#groupBy" class="headerlink" title="groupBy"></a>groupBy</h3><p>功能：将rdd的数据进行分组</p>
<p>语法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206141147532.png" alt="image-20221206141147532"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">    rdd2 = rdd.groupBy(<span class="keyword">lambda</span> num: <span class="string">&#x27;even&#x27;</span> <span class="keyword">if</span> num % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;odd&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(rdd2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], <span class="built_in">list</span>(x[<span class="number">1</span>]))).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;even&#x27;, [2, 4, 6, 8]), (&#x27;odd&#x27;, [1, 3, 5, 7])]  </span></span><br></pre></td></tr></table></figure>



<h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><p>功能：过滤想要的数据进行保留</p>
<p>语法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.<span class="built_in">filter</span>(func)</span><br><span class="line"><span class="comment"># func: (T) -&gt; bool 传入1个参数（随意类型），返回值必须是True或False</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x % <span class="number">2</span> == <span class="number">1</span>).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 3, 5, 7]  </span></span><br></pre></td></tr></table></figure>



<h3 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h3><p>功能：对rdd数据进行去重，返回新的rdd</p>
<p>语法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.distinct(参数)</span><br><span class="line"><span class="comment"># 参数，去重分区数量，一般不用传</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd.distinct().collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[4, 8, 1, 5, 2, 6, 3, 7]</span></span><br></pre></td></tr></table></figure>



<h3 id="union"><a href="#union" class="headerlink" title="union"></a>union</h3><p>功能：2个rdd合并成一个rdd返回，只是合并，不会去重，不同类型的rdd均可以合并</p>
<p>用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.union(other_rdd)</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd1 = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">    rdd2 = sc.parallelize([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(rdd1.union(rdd2).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 2, 3, 4, 5, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]</span></span><br></pre></td></tr></table></figure>



<h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>功能：对rdd进行join操作（可实现SQL的内&#x2F;外连接）</p>
<p>注意：join算子只能用于二元元组</p>
<p>用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd.join(other_add) <span class="comment">#内连接</span></span><br><span class="line">rdd.leftOuterJoin(other_rdd) <span class="comment">#左外</span></span><br><span class="line">rdd.rightOuterJoin(other_rdd) <span class="comment">#右外</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd1 = sc.parallelize([(<span class="number">101</span>, <span class="string">&#x27;a&#x27;</span>), (<span class="number">102</span>, <span class="string">&#x27;b&#x27;</span>), (<span class="number">103</span>, <span class="string">&#x27;c&#x27;</span>), (<span class="number">104</span>, <span class="string">&#x27;d&#x27;</span>)])</span><br><span class="line">    rdd2 = sc.parallelize([(<span class="number">101</span>, <span class="string">&#x27;x&#x27;</span>), (<span class="number">103</span>, <span class="string">&#x27;y&#x27;</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd1.join(rdd2).collect())</span><br><span class="line">    <span class="built_in">print</span>(rdd1.leftOuterJoin(rdd2).collect())</span><br><span class="line">    <span class="built_in">print</span>(rdd1.rightOuterJoin(rdd2).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(101, (&#x27;a&#x27;, &#x27;x&#x27;)), (103, (&#x27;c&#x27;, &#x27;y&#x27;))]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(104, (&#x27;d&#x27;, None)), (101, (&#x27;a&#x27;, &#x27;x&#x27;)), (102, (&#x27;b&#x27;, None)), (103, (&#x27;c&#x27;, &#x27;y&#x27;))]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(101, (&#x27;a&#x27;, &#x27;x&#x27;)), (103, (&#x27;c&#x27;, &#x27;y&#x27;))]</span></span><br></pre></td></tr></table></figure>



<h3 id="intersection"><a href="#intersection" class="headerlink" title="intersection"></a>intersection</h3><p>功能：求2个rdd的交集，返回一个新的rdd</p>
<p>用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.intersection(other_rdd)</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd1 = sc.parallelize([(<span class="number">101</span>, <span class="string">&#x27;a&#x27;</span>), (<span class="number">102</span>, <span class="string">&#x27;b&#x27;</span>), (<span class="number">103</span>, <span class="string">&#x27;c&#x27;</span>), (<span class="number">104</span>, <span class="string">&#x27;d&#x27;</span>)])</span><br><span class="line">    rdd2 = sc.parallelize([(<span class="number">101</span>, <span class="string">&#x27;x&#x27;</span>), (<span class="number">103</span>, <span class="string">&#x27;c&#x27;</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd1.intersection(rdd2).collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(103, &#x27;c&#x27;)]</span></span><br></pre></td></tr></table></figure>



<h3 id="glom"><a href="#glom" class="headerlink" title="glom"></a>glom</h3><p>功能：将rdd加上嵌套，这个嵌套按照分区来进行。比如rdd数据[1,2,3,4,5]有2个分区，那么，glom后，数据变成[[1,2,3], [4,5]]</p>
<p>用法：<code>rdd.glom()</code></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], <span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(rdd.glom().collect())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[[1, 2], [3, 4], [5, 6, 7, 8]]</span></span><br></pre></td></tr></table></figure>



<h3 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h3><p>功能：针对KV型rdd，自动根据key分组</p>
<p>用法：<code>rdd.groupByKey()</code></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">5</span>)])</span><br><span class="line">    <span class="built_in">print</span>(rdd.groupByKey().<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], <span class="built_in">list</span>(x[<span class="number">1</span>]))).collect())</span><br><span class="line">  </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;b&#x27;, [2, 5]), (&#x27;c&#x27;, [3]), (&#x27;a&#x27;, [1, 4])]</span></span><br></pre></td></tr></table></figure>



<h3 id="sortBy"><a href="#sortBy" class="headerlink" title="sortBy"></a>sortBy</h3><p>功能：对rdd数据进行排序，基于你指定的排序依据</p>
<p>语法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206152059608.png" alt="image-20221206152059608"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">5</span>)])</span><br><span class="line">    <span class="built_in">print</span>(rdd.sortBy(<span class="keyword">lambda</span> x: x[<span class="number">1</span>], ascending=<span class="literal">True</span>, numPartitions=<span class="number">2</span>).collect())</span><br><span class="line">    <span class="built_in">print</span>(rdd.sortBy(<span class="keyword">lambda</span> x: x[<span class="number">1</span>], ascending=<span class="literal">False</span>, numPartitions=<span class="number">1</span>).collect())</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 3), (&#x27;a&#x27;, 4), (&#x27;b&#x27;, 5)]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;b&#x27;, 5), (&#x27;a&#x27;, 4), (&#x27;c&#x27;, 3), (&#x27;b&#x27;, 2), (&#x27;a&#x27;, 1)]</span></span><br></pre></td></tr></table></figure>



<h3 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey"></a>sortByKey</h3><p>功能：针对KV型rdd，按照key进行排序</p>
<p>语法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206152535926.png" alt="image-20221206152535926"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;e&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">8</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd.sortByKey().collect()) <span class="comment">#默认升序排序</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果要确保全局有序，排序分区数要是1，如果不是1的话，只能确保各个分区类排好序，整体上不保证</span></span><br><span class="line">    <span class="built_in">print</span>(rdd.sortByKey(<span class="literal">True</span>, numPartitions=<span class="number">2</span>).collect())</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#对排序的key进行整理</span></span><br><span class="line">    <span class="built_in">print</span>(rdd.sortByKey(<span class="literal">True</span>, numPartitions=<span class="number">2</span>, keyfunc=<span class="keyword">lambda</span> key: <span class="built_in">str</span>(key).lower()).collect())</span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;B&#x27;, 2), (&#x27;D&#x27;, 8), (&#x27;a&#x27;, 1), (&#x27;a&#x27;, 4), (&#x27;c&#x27;, 3), (&#x27;e&#x27;, 5)]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 4), (&#x27;B&#x27;, 2), (&#x27;c&#x27;, 3), (&#x27;D&#x27;, 8), (&#x27;e&#x27;, 5)]</span></span><br></pre></td></tr></table></figure>



<h2 id="常用Action算子"><a href="#常用Action算子" class="headerlink" title="常用Action算子"></a>常用Action算子</h2><h3 id="countByKey"><a href="#countByKey" class="headerlink" title="countByKey"></a>countByKey</h3><p>功能：统计key出现的次数（一般适用于KV型的RDD）</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd1 = sc.textFile(<span class="string">&quot;hdfs://node1:8020/input/words.txt&quot;</span>)</span><br><span class="line">    rdd2 = rdd1.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27; &#x27;</span>))</span><br><span class="line">    rdd3 = rdd2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line">    <span class="built_in">print</span>(rdd3.countByKey())</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;defaultdict(&lt;class &#x27;int&#x27;&gt;, &#123;&#x27;hello&#x27;: 3, &#x27;spark&#x27;: 1, &#x27;hadoop&#x27;: 1, &#x27;flink&#x27;: 1&#125;)</span></span><br></pre></td></tr></table></figure>



<h3 id="collect"><a href="#collect" class="headerlink" title="collect"></a>collect</h3><p>功能：将rdd各个分区内的数据，统一收集到driver中，形成一个List对象</p>
<p>注意：rdd是分布式对象，其数据量可以很大，所以在用这个算子之前，要了解结果数据集不会太大，不然会把Driver内存撑爆</p>
<p>用法：<code>rdd.collect()</code></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">    <span class="built_in">print</span>(rdd.collect())</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 2, 3, 4, 5]</span></span><br></pre></td></tr></table></figure>



<h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h3><p>功能：对rdd数据集按照你传入的逻辑进行聚合</p>
<p>语法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206154632113.png" alt="image-20221206154632113"></p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206154653501.png" alt="image-20221206154653501"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line">    <span class="built_in">print</span>(rdd.reduce(<span class="keyword">lambda</span> a, b: a + b))</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;45</span></span><br></pre></td></tr></table></figure>



<h3 id="fold"><a href="#fold" class="headerlink" title="fold"></a>fold</h3><p>功能：和reduce一样，接受传入逻辑进行聚合，聚合是带有初始值的</p>
<p>注意：这个初始值会作用在：分区内聚合、分区间聚合</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>), <span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(rdd.fold(<span class="number">10</span>, <span class="keyword">lambda</span> a, b: a + b))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;85</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#数据分布在3个分区 如[[1,2,3],[4,5,6],[7,8,9]]</span></span><br><span class="line"><span class="comment">#分区1，1,2,3聚合的时候带上10作为初始值得到16</span></span><br><span class="line"><span class="comment">#分区2，4,5,6聚合的时候带上10作为初始值得到25</span></span><br><span class="line"><span class="comment">#分区3，7,8,9聚合的时候带上10作为初始值得到34</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#3个分区结果聚合带上10作为初始值，结果：10 + 16 + 25 + 34 = 85</span></span><br></pre></td></tr></table></figure>



<h3 id="first"><a href="#first" class="headerlink" title="first"></a>first</h3><p>功能：取出rdd的第一个元素</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(sc.parallelize(<span class="built_in">range</span>(<span class="number">3</span>, <span class="number">10</span>)).first())</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br></pre></td></tr></table></figure>



<h3 id="take"><a href="#take" class="headerlink" title="take"></a>take</h3><p>功能：取出rdd的前N个元素，组合成List返回</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(sc.parallelize(<span class="built_in">range</span>(<span class="number">3</span>, <span class="number">10</span>)).take(<span class="number">4</span>))</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[3, 4, 5, 6]</span></span><br></pre></td></tr></table></figure>



<h3 id="top"><a href="#top" class="headerlink" title="top"></a>top</h3><p>功能：对rdd数据集进行降序排序，取前N个</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(sc.parallelize(<span class="built_in">range</span>(<span class="number">3</span>, <span class="number">10</span>)).top(<span class="number">4</span>))</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[9, 8, 7, 6]</span></span><br></pre></td></tr></table></figure>



<h3 id="count"><a href="#count" class="headerlink" title="count"></a>count</h3><p>功能：计算rdd有多少条数据，返回值是一个数字</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(sc.parallelize(<span class="built_in">range</span>(<span class="number">3</span>, <span class="number">10</span>)).count())</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;7</span></span><br></pre></td></tr></table></figure>



<h3 id="takeSample"><a href="#takeSample" class="headerlink" title="takeSample"></a>takeSample</h3><p>功能：随机抽样rdd的数据</p>
<p>用法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206160645256.png" alt="image-20221206160645256"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(rdd.takeSample(<span class="literal">True</span>, <span class="number">20</span>))</span><br><span class="line">    <span class="built_in">print</span>(rdd.takeSample(<span class="literal">False</span>, <span class="number">20</span>))</span><br><span class="line">    <span class="built_in">print</span>(rdd.takeSample(<span class="literal">False</span>, <span class="number">5</span>))</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 4, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 4]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 2, 1, 1, 1, 3, 5, 1, 4, 1, 4, 6]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 1, 1, 1, 2]</span></span><br></pre></td></tr></table></figure>



<h3 id="takeOrdered"><a href="#takeOrdered" class="headerlink" title="takeOrdered"></a>takeOrdered</h3><p>功能：对rdd进行排序取前N个</p>
<p>用法：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206161237241.png" alt="image-20221206161237241"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">6</span>], <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(rdd.takeOrdered(<span class="number">3</span>))</span><br><span class="line">    <span class="built_in">print</span>(rdd.takeOrdered(<span class="number">3</span>, <span class="keyword">lambda</span> x: -x))</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[1, 2, 3]</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[9, 7, 6]</span></span><br></pre></td></tr></table></figure>



<h3 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a>foreach</h3><p>功能：对rdd的每一个元素，执行提供的逻辑操作，它没有返回值</p>
<p>用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd.foreach(func)</span><br><span class="line"><span class="comment"># func: (T) -&gt; None</span></span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>], <span class="number">1</span>)</span><br><span class="line">    rdd.foreach(<span class="keyword">lambda</span> x: <span class="built_in">print</span>(x * <span class="number">10</span>))</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;10</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;30</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;20</span></span><br></pre></td></tr></table></figure>



<h3 id="saveAsTextFile"><a href="#saveAsTextFile" class="headerlink" title="saveAsTextFile"></a>saveAsTextFile</h3><p>功能：将rdd的数据写入到文本文件中，支持本地文件、hdfs文件系统</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize(<span class="built_in">range</span>(<span class="number">100</span>))</span><br><span class="line">    rdd.saveAsTextFile(<span class="string">&quot;hdfs://node1:8020/output/range100&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206163035163.png" alt="image-20221206163035163"></p>
<p>注意：</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206163152460.png" alt="image-20221206163152460"></p>
<p><strong>注意点</strong></p>
<p>foreach和saveAsTextFile算子是分区（Executor）直接执行的，跳过Driver，由分区所在的Executor直接执行，其余的Action算子都会将结果发送至Driver</p>
<h2 id="分区操作算子（Transformation-amp-Action）"><a href="#分区操作算子（Transformation-amp-Action）" class="headerlink" title="分区操作算子（Transformation &amp; Action）"></a>分区操作算子（Transformation &amp; Action）</h2><h3 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206165850734.png" alt="image-20221206165850734"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">6</span>], <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">func_map</span>(<span class="params">data</span>):</span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">            num += i</span><br><span class="line">        <span class="keyword">return</span> [num]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(rdd.mapPartitions(func_map).collect())</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[4, 6, 22]</span></span><br></pre></td></tr></table></figure>



<h3 id="foreachPartition"><a href="#foreachPartition" class="headerlink" title="foreachPartition"></a>foreachPartition</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206171225266.png" alt="image-20221206171225266"></p>
<h3 id="partitionBy"><a href="#partitionBy" class="headerlink" title="partitionBy"></a>partitionBy</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206171333040.png" alt="image-20221206171333040"></p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;SPARK_HOME&#x27;</span>] = <span class="string">&#x27;/export/server/spark-3.2.0-bin-hadoop3.2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([(<span class="string">&#x27;hadoop&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;spark&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;flink&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;hadoop&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;spark&#x27;</span>, <span class="number">1</span>)])</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">partition_self</span>(<span class="params">key</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;hadoop&#x27;</span> == key: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&#x27;spark&#x27;</span> == key <span class="keyword">or</span> <span class="string">&#x27;flink&#x27;</span> == key):</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">#分区号不要超标，设置3个分区，分区号只能是0，1，2</span></span><br><span class="line">    <span class="built_in">print</span>(rdd.partitionBy(<span class="number">3</span>, partition_self).glom().collect())</span><br><span class="line">  </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[[(&#x27;hadoop&#x27;, 1), (&#x27;hadoop&#x27;, 1)], [(&#x27;spark&#x27;, 1), (&#x27;flink&#x27;, 1), (&#x27;spark&#x27;, 1)], []]</span></span><br></pre></td></tr></table></figure>



<h3 id="repartition"><a href="#repartition" class="headerlink" title="repartition"></a>repartition</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206171957688.png" alt="image-20221206171957688"></p>
<h3 id="coalesce"><a href="#coalesce" class="headerlink" title="coalesce"></a>coalesce</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206172041561.png" alt="image-20221206172041561"></p>
<h3 id="mapValues"><a href="#mapValues" class="headerlink" title="mapValues"></a>mapValues</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206172122526.png" alt="image-20221206172122526"></p>
<h1 id="RDD的持久化"><a href="#RDD的持久化" class="headerlink" title="RDD的持久化"></a>RDD的持久化</h1><h2 id="RDD的数据是过程数据"><a href="#RDD的数据是过程数据" class="headerlink" title="RDD的数据是过程数据"></a>RDD的数据是过程数据</h2><p>RDD之间进行相互迭代计算（Transformation的转换），当执行开启后，新RDD的生成，代表老的RDD的消失。</p>
<p>RDD的数据是过程数据，只在处理的过程中存在，一旦处理完成，就不见了。</p>
<p>这个特性可以最大化的利用资源，老旧RDD没用了就从内存中清理，给后续的计算腾出内存空间。</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206173712249.png" alt="image-20221206173712249"></p>
<p>如上图，rdd3被2次使用，第一次使用后，其实rdd3就不存在了。第二次用的时候，只能基于rdd的血缘关系，从rdd1重新执行，构建出rdd3，供rdd5使用。</p>
<h2 id="RDD缓存"><a href="#RDD缓存" class="headerlink" title="RDD缓存"></a>RDD缓存</h2><p>将指定的rdd数据保留在内存或硬盘上。</p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206174001016.png" alt="image-20221206174001016"></p>
<p><strong>缓存特点</strong></p>
<ul>
<li>缓存技术可以将过程RDD数据，持久化保存到内存或者硬盘上。</li>
<li>但是，这个保存在设定上认为是不安全的（存在丢失的风险）</li>
<li>缓存可以保留RDD之间的血缘（依赖）关系，一旦缓存丢失，可以基于血缘关系的记录，重新计算这个RDD的数据</li>
</ul>
<p>每个分区的缓存都会保存到其对应的Executor中的内存中，或者是对应的Executor所在服务器的硬盘上。</p>
<p><strong>缓存是如何保存</strong></p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206174850915.png" alt="image-20221206174850915"></p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206174914952.png" alt="image-20221206174914952"></p>
<h2 id="RDD-CheckPoint"><a href="#RDD-CheckPoint" class="headerlink" title="RDD CheckPoint"></a>RDD CheckPoint</h2><p>将RDD数据保存起来，<strong>它仅支持硬盘存储</strong>，它被设计认为是安全的。它不保留血缘关系。</p>
<p><strong>CheckPoint是如何保存数据的</strong></p>
<p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206174751409.png" alt="image-20221206174751409"></p>
<h3 id="缓存和CheckPoint的对比"><a href="#缓存和CheckPoint的对比" class="headerlink" title="缓存和CheckPoint的对比"></a>缓存和CheckPoint的对比</h3><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206175054890.png" alt="image-20221206175054890"></p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#第一步，选择CP的保存路径</span></span><br><span class="line"><span class="comment">#如果是Local模式，可以支持本地文件系统，如果在集群运行，千万要用HDFS</span></span><br><span class="line">sc.setCheckpointDir(<span class="string">&quot;hdfs://node1:8020/output/bj52ckp&quot;</span>)</span><br><span class="line"><span class="comment">#用的时候，直接调用checkoutpoint算子即可</span></span><br><span class="line">rdd.checkpoint()</span><br></pre></td></tr></table></figure>



<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>CheckPoint是一种重量级的使用，也就是RDD的计算成本很高的时候，采用CheckPoint比较合适。</p>
<p>或者数据量很大，用CheckPoint比较合适。</p>
<p>如果数据量小，或者RDD重新计算是非常块的，用CheckPoint没啥必要，直接缓存即可。</p>
<ul>
<li>Cache和CheckPoint两个API都不是Action类型</li>
<li>所以，要它两工作，必须在后面接上Action</li>
<li>接上Action的目的，是让RDD有数据，而不是为了让CheckPoint和Cache工作</li>
</ul>
<h1 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h1><h2 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h2><p>代码中存在本地对象时，会被发送到每个分区的处理线程上使用，也就是一个Executor内，其实存放了2份一样的数据。Executor是进程，进程内的资源共享，进程内保存了两份一样的数据，操作内存资源浪费。</p>
<p>如果将本地资源标记为广播变量对象，Spark只会给每个Executor发送一份数据，Executor内部的各个线程（分区）共享这份数据，而不是每个分区的处理线程都发送一份，从而节省了内存。</p>
<p>使用方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.将本地list标记成广播变量即可</span></span><br><span class="line">broadcast = sc.broadcast(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.使用广播变量，从broadcast对象中取出本地list对象即可</span></span><br><span class="line">value = broadcast.value</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    stu_info_list = [(<span class="number">1</span>, <span class="string">&#x27;张三&#x27;</span>, <span class="number">11</span>), (<span class="number">2</span>, <span class="string">&#x27;李四&#x27;</span>, <span class="number">13</span>), (<span class="number">3</span>, <span class="string">&#x27;王五&#x27;</span>, <span class="number">11</span>), (<span class="number">4</span>, <span class="string">&#x27;朱六&#x27;</span>, <span class="number">11</span>)]</span><br><span class="line"></span><br><span class="line">    broadcast = sc.broadcast(stu_info_list)</span><br><span class="line"></span><br><span class="line">    score_info_rdd = sc.parallelize([</span><br><span class="line">        (<span class="number">1</span>, <span class="string">&#x27;语文&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">&#x27;数学&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">3</span>, <span class="string">&#x27;外语&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="string">&#x27;自然&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">&#x27;化学&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">&#x27;物理&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">3</span>, <span class="string">&#x27;政治&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="string">&#x27;俄语&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">&#x27;日语&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">&#x27;编程&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">3</span>, <span class="string">&#x27;生物&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="string">&#x27;历史&#x27;</span>, <span class="number">99</span>),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">map_func</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="built_in">id</span> = data[<span class="number">0</span>]</span><br><span class="line">        name = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        value = broadcast.value</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> value:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">id</span> == i[<span class="number">0</span>]:</span><br><span class="line">                name = i[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> (name, data[<span class="number">1</span>], data[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(score_info_rdd.<span class="built_in">map</span>(map_func).collect())</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;[(&#x27;张三&#x27;, &#x27;语文&#x27;, 99), (&#x27;李四&#x27;, &#x27;数学&#x27;, 99), (&#x27;王五&#x27;, &#x27;外语&#x27;, 99), (&#x27;朱六&#x27;, &#x27;自然&#x27;, 99), (&#x27;张三&#x27;, &#x27;化学&#x27;, 99), (&#x27;李四&#x27;, &#x27;物理&#x27;, 99), (&#x27;王五&#x27;, &#x27;政治&#x27;, 99), (&#x27;朱六&#x27;, &#x27;俄语&#x27;, 99), (&#x27;张三&#x27;, &#x27;日语&#x27;, 99), (&#x27;李四&#x27;, &#x27;编程&#x27;, 99), (&#x27;王五&#x27;, &#x27;生物&#x27;, 99), (&#x27;朱六&#x27;, &#x27;历史&#x27;, 99)]</span></span><br></pre></td></tr></table></figure>



<h2 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h2><p>对map算子计算中的数据，进行计数累加得到全部数据计算后的累加结果。</p>
<p><strong>没有累加器的示例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">map_func</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">global</span> count</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(count)</span><br><span class="line"></span><br><span class="line">    rdd.<span class="built_in">map</span>(map_func).collect()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;最终结果&#x27;</span>,count)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;1</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;2</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;1</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;2</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;1</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;2</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;最终结果 0</span></span><br></pre></td></tr></table></figure>

<p>上述代码中存在的问题：</p>
<blockquote>
<p>count来自Driver对象，当在分布式的map算子中需要count对象的时候</p>
<p>Driver会将count发送给每一个Executor一份（复制发送）</p>
<p>最后打印count时，被打印的count是Driver中的那个，所以，不管Executor中累加到多少，都和Driver中的count无关</p>
</blockquote>
<p><strong>累加器</strong></p>
<p>累加器对象可以从各个Executor中收集它们的执行结果，作用会自己身上。</p>
<p>用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.accumulator(初始值)</span><br></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">&quot;study_00&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    count = sc.accumulator(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">map_func</span>(<span class="params">data</span>):</span><br><span class="line">        <span class="keyword">global</span> count</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(count)</span><br><span class="line"></span><br><span class="line">    rdd.<span class="built_in">map</span>(map_func).collect()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;最终结果&#x27;</span>,count)</span><br><span class="line">   </span><br><span class="line"><span class="comment">#&gt;&gt;&gt;输出</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;1</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;2</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;1</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;2</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;1</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;2</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;3</span></span><br><span class="line"><span class="comment">#&gt;&gt;&gt;最终结果 9</span></span><br></pre></td></tr></table></figure>

<p><strong>注意事项</strong></p>
<p>如果累加器计数的代码，存在重新构建的步骤中，累加器计数的代码可能被多次执行。</p>
<h1 id="提交到YARN集群中运行"><a href="#提交到YARN集群中运行" class="headerlink" title="提交到YARN集群中运行"></a>提交到YARN集群中运行</h1><p><img src="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/image-20221206153551743.png" alt="image-20221206153551743"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">Spark基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-01 21:07:40" itemprop="dateCreated datePublished" datetime="2022-02-01T21:07:40+08:00">2022-02-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-10 20:29:30" itemprop="dateModified" datetime="2022-12-10T20:29:30+08:00">2022-12-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Spark框架概述"><a href="#Spark框架概述" class="headerlink" title="Spark框架概述"></a>Spark框架概述</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>Apache Spark是用于大规模数据处理的统一分析引擎。</p>
<p>RDD：弹性分布式数据集。RDD是一种分布式内存抽象，其使得程序员能够在大规模集群中做内存运算，并且有一定的容错方式。而这也是整个Spark的核心数据结构，Spark整个平台都围绕着RDD进行。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221426265.png" alt="image-20221208221426265"></p>
<p>Spark的特点是对任意类型的数据进行自定义计算。它可以计算结构化、半结构化、非结构化等各种类型的数据结构。同时也支持使用Python、Java、Scala、R及SQL语言去开发应用程序计算数据。</p>
<h2 id="Spark-VS-Hadoop-MapReduce"><a href="#Spark-VS-Hadoop-MapReduce" class="headerlink" title="Spark VS Hadoop(MapReduce)"></a>Spark VS Hadoop(MapReduce)</h2><p>Spark和Hadoop技术栈的区别：</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221847274.png" alt="image-20221208221847274"></p>
<p>尽管Spark相对Hadoop具有较大优势，但Spark并不能完全替代Hadoop。</p>
<ul>
<li>在计算层面，Spark相比较MapReduce有巨大的性能优势，但至今仍有许多计算工具基于MapReduce架构，比如非常成熟的Hive</li>
<li>Spark仅做计算，而Hadoop生态圈不仅有计算（MapReduce），也有存储（HDFS）和资源管理调度（YARN），HDFS和YARN仍是许多大数据体系的核心架构。</li>
</ul>
<h2 id="Spark四大特点"><a href="#Spark四大特点" class="headerlink" title="Spark四大特点"></a>Spark四大特点</h2><h3 id="速度快"><a href="#速度快" class="headerlink" title="速度快"></a>速度快</h3><p>Spark支持内存计算，并且通过DAG（有向无环图）执行引擎支持无环数据流，其在内存中运行速度比MapReduce快（官方宣称比MapReduce快100倍，在硬盘中快10倍）。</p>
<p>Spark处理数据与MapReduce处理数据相比，有两个不同点：</p>
<ul>
<li>Spark处理数据时，可以将中间处理结果存储到内存中。</li>
<li>Spark提供了非常丰富的算子（API），可以做到复杂任务在一个Spark程序中完成。</li>
</ul>
<h3 id="易于使用"><a href="#易于使用" class="headerlink" title="易于使用"></a>易于使用</h3><p>Spark支持使用Python、Java、Scala、R及SQL语言去开发应用程序</p>
<h3 id="通用性强"><a href="#通用性强" class="headerlink" title="通用性强"></a>通用性强</h3><p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208223515333.png" alt="image-20221208223515333"></p>
<p>可以在一个应用中无缝地使用这些工具库。</p>
<h3 id="运行方式"><a href="#运行方式" class="headerlink" title="运行方式"></a>运行方式</h3><p>Spark支持多种运行方式。包括Hadoop和Mesos，也支持Standalone的独立运行模式，也可以运行在云Kubernetes上。</p>
<p>对于数据源，Spark支持HDFS、HBase、Cassandra及Kafka等。</p>
<h2 id="Spark框架模块"><a href="#Spark框架模块" class="headerlink" title="Spark框架模块"></a>Spark框架模块</h2><p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208223922127.png" alt="image-20221208223922127"></p>
<p><strong>Spark Core</strong></p>
<p>Spark的核心，提供Spark核心功能，是Spark运行的基础。Spark Core以RDD为数据抽象，提供Python、Java、Scala、R语言的API，可以编程进行海量离线数据批处理计算。</p>
<p><strong>SparkSQL</strong></p>
<p>基于SparkCore之上，提供结构化数据的处理模块，SparkSQL支持以SQL语言对数据进行处理，SparkSQL本身针对离线计算场景。同时基于SparkSQL，Spark提供了StructedStreaming模块，进行数据流式计算。</p>
<p><strong>SparkStreaming</strong></p>
<p>以SparkCore为基础，提供数据流式计算的功能。</p>
<p><strong>MLlib</strong></p>
<p>以SparkCore为基础，进行机器学习，内置大量机器学习卡和API算法。</p>
<p><strong>GraphX</strong></p>
<p>以SparkCore为基础，进行图计算</p>
<h2 id="Spark运行模式"><a href="#Spark运行模式" class="headerlink" title="Spark运行模式"></a>Spark运行模式</h2><p><strong>本地模式（单机）</strong></p>
<p>以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行环境</p>
<p><strong>Standalone模式（集群）</strong></p>
<p>Spark中各个角色以独立进程的形式存在，并组成Spark集群环境</p>
<p><strong>Hadoop YARN模式（集群）</strong></p>
<p>Spark中的各个角色运行在YARN的容器内部，并组成Spark集群环境</p>
<p><strong>Kubernetes模式（容器集群）</strong></p>
<p>Spark中的各个角色运行在Kubernetes的容器内部，并组成Spark集群环境</p>
<h3 id="Spark的架构角色"><a href="#Spark的架构角色" class="headerlink" title="Spark的架构角色"></a>Spark的架构角色</h3><h4 id="YARN角色"><a href="#YARN角色" class="headerlink" title="YARN角色"></a>YARN角色</h4><p>资源管理层面：</p>
<ul>
<li>集群资源管理者（Master）：ResourceManager</li>
<li>单机资源管理者（Worker）：NodeManager</li>
</ul>
<p>任务计算层面：</p>
<ul>
<li>单任务管理者（Master）：ApplicationMaster</li>
<li>单任务执行者（Worder）：Task（容器内计算框架的工作角色）</li>
</ul>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208225238293.png" alt="image-20221208225238293"></p>
<h4 id="Spark运行角色"><a href="#Spark运行角色" class="headerlink" title="Spark运行角色"></a>Spark运行角色</h4><p>资源管理层面：</p>
<ul>
<li>管理者：Master角色（管理整个集群的资源），YARN是ResourceManager</li>
<li>工作者：Worker角色（管理单个服务器的资源），YARN是NodeManager</li>
</ul>
<p>任务执行层面</p>
<ul>
<li>某任务管理者：Driver角色（管理单个任务在运行的时候的工作），YARN是ApplicationMaster</li>
<li>某任务执行者：Executor角色（单个任务运行的时候的一堆工作者，干活的），YARN是容器中运行的具体工作进程（TASK）</li>
</ul>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208225924296.png" alt="image-20221208225924296"></p>
<h1 id="Spark部署方式"><a href="#Spark部署方式" class="headerlink" title="Spark部署方式"></a>Spark部署方式</h1><h2 id="Local"><a href="#Local" class="headerlink" title="Local"></a>Local</h2><p>Local模式是以一个独立进程配合其内部线程来提供完成Spark运行时环境。Local模式可以通过spark-shell&#x2F;pyspark&#x2F;spark-submit等来开启。</p>
<h2 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h2><h3 id="Standalone架构"><a href="#Standalone架构" class="headerlink" title="Standalone架构"></a>Standalone架构</h3><p>Standalone模式是Sark自带的一种集群模式，不同于本地模式启动多个进程来模拟集群环境，Standalone模式是真实的在多个机器之间搭建Spark集群的环境，完全可以利用该模式搭建多机器机器，用于实际的大数据处理。</p>
<p>Standalone是完整的Spark运行环境，其中Master角色以Master进程存在，Worker角色以Worker进程存在。Driver和Executor运行于Worker进程内，由Worker提供资源供给它们运行。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210151603188.png" alt="image-20221210151603188"></p>
<p>Standalone集群在进程上主要有3类进程：</p>
<ol>
<li><p>主节点Master进程</p>
<p>Master角色，管理整个集群资源，并托管运行各个任务的Driver。</p>
</li>
<li><p>从节点Workers</p>
<p>Worker角色，管理每个集群的资源，分配对应的资源来运行Executor（TASK）；每个从节点分配资源信息给Worker管理，资源信息包含Memory和CPU Cores核数</p>
</li>
<li><p>历史服务器HistoryServer（可选）</p>
<p>Spark Application运行完成后，保存事件日志数据至HDFS，启动HistoryServer可以查看应用运行相关信息</p>
</li>
</ol>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210152323860.png" alt="image-20221210152323860"></p>
<h3 id="Spark应用架构"><a href="#Spark应用架构" class="headerlink" title="Spark应用架构"></a>Spark应用架构</h3><p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210155620073.png" alt="image-20221210155620073"></p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210155700797.png" alt="image-20221210155700797"></p>
<p>从上图可以看出Spark Application运行到集群上时，由两部分组成：Driver Program和Excutors。</p>
<p><strong>Driver Program</strong></p>
<p>相当于AppMaster，整个应用的管理者，负责应用中所有Job的调度执行。</p>
<p>运行JVM Process，运行程序的main函数，必须建立SparkContext上下文对象。</p>
<p>一个SparkApplication仅有一个。</p>
<p><strong>Executors</strong></p>
<p>相当于一个线程池，运行JVM Process，其中有很多线程，每个线程运行一个Task任务，一个Task任务运行需要1 core CPU，所以可以认为Executor中线程数就等于CPU core核数。</p>
<p>一个Spark Application中可以有多个Executors，可以设置个数和资源信息。</p>
<p><strong>执行流程</strong></p>
<p>用户程序从最开始的提交到最终的计算执行，需要经历一下几个阶段：</p>
<ol>
<li>用户程序创建SparkContext时，新创建的SparkContext实例会连接到ClusterManager。 ClusterManager会根据用户提交时设置的CPU和内存等信息为本次提交分配计算资源，启动Executor。</li>
<li>Driver会将用户程序划分为不同的执行阶段Stage，每个执行阶段Stage由一组完全相同的Task组成，这些Task分别作用于待处理数据的不同分区。在接到划分完成和Task创建后，Driver会向Executor发送Task。</li>
<li>Executor在接收到Task后，会下载Task的运行时依赖，在准备好Task的执行环境后，会开始执行Task，并且将Task的运行状态汇报给Driver。</li>
<li>Driver会根据收到的Task的运行状态来处理不同的状态更新。Task分两种：一种时Shuffle Map Task，它实现数据的重新洗牌，洗牌的结果保存到Executor所在节点的文件系统中；另外一种是Result Task，它负责生成结果数据。</li>
<li>Driver会不断地调用Task，将Task发送到Executor执行，在所有地Task都正确执行或者超过执行次数地限制仍然没有执行成功时停止。</li>
</ol>
<p><strong>Spark程序运行层次结构</strong></p>
<p>Spark Application程序运行时三个核心概念：Job、Stage、Task。</p>
<ul>
<li><strong>Job</strong> ：由多个Task地并行计算部分，一般Spark中的action操作（如save、collect）会生成一个Job</li>
<li><strong>Stage</strong> ：Job的组成单位，一个Job会切分成多个Stage，Stage彼此之间互相依赖顺序执行，而每个Stage是多个Task的集合，类似map和reduce stage</li>
<li><strong>Task</strong> ：被分配到Executor的单位工作内容，它是Spark中的最小执行单位，一般来说有多少个paritition，就会有多少个Task，就会有多少个Task，每个Task只会处理单一分支上的数据。</li>
</ul>
<blockquote>
<p>一个Spark Application中，包含多个Job，每个Job有多个Stage组成，每个Job的执行安装DAG图进行的。其中每个Satge中包含多个Task任务，每个Task以线程方式执行。</p>
</blockquote>
<p><strong>端口</strong></p>
<ul>
<li>4040：是一个运行的Application在运行的过程中临时绑定的端口，用以查看当前的任务状态。4040被占用会顺延到4041、4042等。4040是一个临时端口，当程序运行完成后，4040就会被注销。</li>
<li>8080：默认时Standalone下，Master角色的web端口，用以查看当前Master（集群）的状态</li>
<li>18080：默认时历史服务器的端口，由于每个程序运行完成后，4040端口就被注销了，可以通过历史服务费回看某个程序的运行状态。</li>
</ul>
<h2 id="Standalone-HA"><a href="#Standalone-HA" class="headerlink" title="Standalone HA"></a>Standalone HA</h2><p>基于Zookeeper实现HA</p>
<p>Zookeeer提供了一个Leader Election机制，利用这个机制可以保证虽然集群存在多个Master，但是只有一个是Active，其他的都是Standby。当Active的Master出现故障时，另外的一个Standy Master会被选举出来。由于集群的信息，及woker、driver和Application的信息都已经持久化到文件系统，因此在切换的过程中只会影响新Job的提交，对于正在进行的Job没有任何影响。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210163520123.png" alt="image-20221210163520123"></p>
<h2 id="Spark-On-YARN"><a href="#Spark-On-YARN" class="headerlink" title="Spark On YARN"></a>Spark On YARN</h2><p>多数情况下，各企业都会有Haddop集群，为了节约服务器资源，将Spark运行到YARN集群中，不需要再单独部署Spark Standalone集群。</p>
<p>在Spark on YARN中，无需部署Spark集群，只要一个服务器充当Spark客户端，即可提交任务到YARN集群中运行。</p>
<h3 id="Spark-On-YARN的本质"><a href="#Spark-On-YARN的本质" class="headerlink" title="Spark On YARN的本质"></a>Spark On YARN的本质</h3><p>Master角色由YARN的ResourceManager担任。</p>
<p>Worker角色由YARN的NodeManager担任。</p>
<p>Driver角色运行在YARN容器内或提交任务的客户端进程中。</p>
<p>真正干活的Executor运行在YARN提供的容器内。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210172323763.png" alt="image-20221210172323763"></p>
<h3 id="部署模式DeloyMode"><a href="#部署模式DeloyMode" class="headerlink" title="部署模式DeloyMode"></a>部署模式DeloyMode</h3><p><strong>Cluster模式</strong></p>
<p>Driver运行在YARN容器内部，和ApplicationMaster在同一个容器内</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180238773.png" alt="image-20221210180238773"></p>
<p>详细流程：</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210182646551.png" alt="image-20221210182646551"></p>
<p>具体流程步骤：</p>
<ol>
<li>任务提交后会和ResourceManager通讯申请启动ApplicationMaster；</li>
<li>随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster就是Driver；</li>
<li>Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后在合适的NodeManager上启动Executor进程；</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将Task分发到各个Executor上执行</li>
</ol>
<p><strong>Client模式</strong></p>
<p>Driver运行在客户端进程中，比如Driver运行在spark-submit程序的进程中</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180341609.png" alt="image-20221210180341609"></p>
<p>详细流程：</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210181813615.png" alt="image-20221210181813615"></p>
<p>具体流程步骤：</p>
<ol>
<li>Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster；</li>
<li>随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存；</li>
<li>ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程；</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将Task分发到各个Executor上执行</li>
</ol>
<p><strong>两种模式的区别</strong></p>
<img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180524025.png" alt="image-20221210180524025" style="zoom:80%;">



<p><strong>使用方式</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME = /export/server/spark</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">&#123;SPARK_HOME&#125;/bin/spark-submit --master yarn -- deploy-mode client|cluster test.py</span></span><br></pre></td></tr></table></figure>





<h1 id="PySpark"><a href="#PySpark" class="headerlink" title="PySpark"></a>PySpark</h1><p>PySpark是Spark官方提供的一个Python类库，内置了完全的Spark API，可以通过PySpark类库来编写Spark应用程序，并将其提交到Spark集群中运行。</p>
<p>Python On Spark执行原理</p>
<p>PySark宗旨是在不破坏Spark已有的运行时架构，在Spark架构外层包装一层Python API，借助Py4j实现Python和Java的交互，进而实现通过Python编写Spark应用程序，其运行时架构如图所示。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210202831245.png" alt="image-20221210202831245"></p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210202906475.png" alt="image-20221210202906475"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/12/24/kotlin%E7%B1%BB%E5%92%8C%E5%AF%B9%E8%B1%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/24/kotlin%E7%B1%BB%E5%92%8C%E5%AF%B9%E8%B1%A1/" class="post-title-link" itemprop="url">Kotlin类和对象</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-24 09:38:32" itemprop="dateCreated datePublished" datetime="2021-12-24T09:38:32+08:00">2021-12-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-05-14 15:08:26" itemprop="dateModified" datetime="2022-05-14T15:08:26+08:00">2022-05-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3><h4 id="类-1"><a href="#类-1" class="headerlink" title="类"></a>类</h4><p>使用关键字 <code>class</code> 声明类</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span> &#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>类声明由类名、类头（指定其类型参数、主构造函数等）以及由花括号包围的类体构 成。类头与类体都是可选的； 如果⼀个类没有类体，可以省略花括号。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Empty</span></span><br></pre></td></tr></table></figure>

<h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><p>在 Kotlin 中，⼀个类可以有⼀个主构造函数以及⼀个或多个次构造函数。主构造函数是 类头的⼀部分：它跟在类名与可选的类型参数后。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span> <span class="keyword">constructor</span>(firstName: String) &#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>如果主构造函数没有任何注解或者可⻅性修饰符，可以省略这个 constructor 关键 字。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(firstName: String) &#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>主构造函数不能包含任何的代码。初始化的代码可以放到以 init 关键字作为前缀的初始化块（initializer blocks）中。 在实例初始化期间，初始化块按照它们出现在类体中的顺序执⾏，与属性初始化器交织 在⼀起</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OrderDemo</span>(name: String) &#123;</span><br><span class="line">    <span class="keyword">val</span> firtProperty = <span class="string">&quot;First property: <span class="variable">$name</span>&quot;</span>.also(::println)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">init</span> &#123;</span><br><span class="line">        println(<span class="string">&quot;First initializer block that prints <span class="variable">$name</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> secondProperty = <span class="string">&quot;Second property: <span class="subst">$&#123;name.length&#125;</span>&quot;</span>.also(::println)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">init</span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Second initializer block that prints <span class="subst">$&#123;name.length&#125;</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">(args: <span class="type">Array</span>&lt;<span class="type">String</span>&gt;)</span></span> &#123;</span><br><span class="line">    OrderDemo(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主构造的参数可以在初始化块中使⽤。它们也可以在类体内声明的属性初始化器中使 ⽤：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Customer</span>(name: String) &#123;</span><br><span class="line">    <span class="keyword">val</span> customerKey = name.uppercase()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>与普通属性⼀样，主构造函数中声明的属性可以是可变的（ var ）或只读的 （ val ）。</p>
<p>如果构造函数有注解或可⻅性修饰符，这个 constructor 关键字是必需的，并且这些 修饰符在它前⾯：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Customer</span> <span class="keyword">public</span> <span class="meta">@Inject</span> <span class="keyword">constructor</span>(name: String) &#123; ... &#125;</span><br></pre></td></tr></table></figure>

<h4 id="次构造函数"><a href="#次构造函数" class="headerlink" title="次构造函数"></a>次构造函数</h4><p>类也可以声明前缀有 constructor 的次构造函数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="keyword">val</span> pets: MutableList&lt;Pet&gt; = mutableListOf())</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pet</span> &#123;</span><br><span class="line">    <span class="keyword">constructor</span>(owner: Person) &#123;</span><br><span class="line">        owner.pets.add(<span class="keyword">this</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果类有⼀个主构造函数，每个次构造函数需要委托给主构造函数， 可以直接委托或者 通过别的次构造函数间接委托。委托到同⼀个类的另⼀个构造函数⽤ this 关键字即 可：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="keyword">val</span> name: String) &#123;</span><br><span class="line">    <span class="keyword">val</span> children: MutableList&lt;Person&gt; = mutalbeListOf()</span><br><span class="line">    <span class="keyword">constructor</span>(name: String, parent: Person): <span class="keyword">this</span>(name) &#123;</span><br><span class="line">        parent.children.add(<span class="keyword">this</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>请注意，初始化块中的代码实际上会成为主构造函数的⼀部分。委托给主构造函数会作 为次构造函数的第⼀条语句，因此所有初始化块与属性初始化器中的代码都会在次构造 函数体之前执⾏。</p>
<p>即使该类没有主构造函数，这种委托仍会隐式发⽣，并且仍会执⾏初始化块：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Constructors</span> &#123;</span><br><span class="line">    <span class="keyword">init</span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Init block&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">constructor</span>(i: <span class="built_in">Int</span>) &#123;</span><br><span class="line">        println(<span class="string">&quot;Constructor <span class="variable">$i</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">(args: <span class="type">Array</span>&lt;<span class="type">String</span>&gt;)</span></span> &#123;</span><br><span class="line">    Constructors(<span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果⼀个⾮抽象类没有声明任何（主或次）构造函数，它会有⼀个⽣成的不带参数的主 构造函数。构造函数的可⻅性是 public。</p>
<p>如果你不希望你的类有⼀个公有构造函数，那么声明⼀个带有⾮默认可⻅性的空的主构 造函数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DontCreateMe</span> <span class="keyword">private</span> <span class="keyword">constructor</span>() &#123; ... &#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在 JVM 上，如果主构造函数的所有的参数都有默认值，编译器会⽣成⼀个额外的 ⽆参构造函数，它将使⽤默认值。这使得 Kotlin 更易于使⽤像 Jackson 或者 JPA 这样的通过⽆参构造函数创建类的实例的库。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Customer</span>(<span class="keyword">val</span> customerName: String = <span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>


</blockquote>
<h4 id="创建类的实例"><a href="#创建类的实例" class="headerlink" title="创建类的实例"></a>创建类的实例</h4><p>创建⼀个类的实例，只需像普通函数⼀样调⽤构造函数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> invoice = Invoice()</span><br><span class="line"><span class="keyword">val</span> customer = Customer(<span class="string">&quot;Abc&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>Kotlin没有new关键字</p>
<h4 id="类成员"><a href="#类成员" class="headerlink" title="类成员"></a>类成员</h4><p>类成员可以包括：</p>
<ul>
<li>构造函数与初始化块</li>
<li>函数</li>
<li>属性</li>
<li>嵌套类与内部类</li>
<li>对象声明</li>
</ul>
<h4 id="伴生对象"><a href="#伴生对象" class="headerlink" title="伴生对象"></a>伴生对象</h4><p>如果你需要写一个可以无需用一个类的实例来调用、但需要访问类内部的函数（例如，工厂方法），你可以把它写成该类内<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/object-declarations.html">对象声明</a>中的一员。</p>
<p>更具体地讲，如果在你的类内声明了一个<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/object-declarations.html#%E4%BC%B4%E7%94%9F%E5%AF%B9%E8%B1%A1">伴生对象</a>， 你就可以访问其成员，只是以类名作为限定符。</p>
<h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p>在Kotlin中所有类都有一个共同的超类<code>Any</code>，这对于没有超类型声明的类是默认超类：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span> // 从<span class="title">Any</span>隐式继承</span><br></pre></td></tr></table></figure>

<p><code>Any</code> 有三个方法：<code>equals()</code>、 <code>hashCode()</code> 与 <code>toString()</code>。因此，为所有 Kotlin 类都定义了这些方法。</p>
<p>默认情况下，Kotlin 类是最终（final）的：它们不能被继承。 要使一个类可继承，请用 <code>open</code> 关键字标记它。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Base</span> //该类开放继承</span><br></pre></td></tr></table></figure>

<p>如需声明一个显式的超类型，请在类头中把超类型放到冒号之后：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Base</span>(p: <span class="built_in">Int</span>)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span>(p: <span class="built_in">Int</span>): Base(p)</span><br></pre></td></tr></table></figure>

<p>如果派生类有一个主构造函数，其基类可以（并且必须） 用派生类主构造函数的参数就地初始化。</p>
<p>如果派生类没有主构造函数，那么每个次构造函数必须使用<code>super</code> 关键字初始化其基类型，或委托给另一个做到这点的构造函数。 请注意，在这种情况下，不同的次构造函数可以调用基类型的不同的构造函数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyView</span>: <span class="type">View</span> &#123;</span><br><span class="line">    <span class="keyword">constructor</span>(ctx: Context): <span class="keyword">super</span>(ctx)</span><br><span class="line">    <span class="keyword">constructor</span>(ctx: Context, attrs: AttributeSet): <span class="keyword">super</span>(ctx, attrs)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="覆盖方法"><a href="#覆盖方法" class="headerlink" title="覆盖方法"></a>覆盖方法</h4><p>Kotlin 对于可覆盖的成员以及覆盖后的成员需要显式修饰符：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Shape</span> &#123;</span><br><span class="line">    <span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">fill</span><span class="params">()</span></span> &#123; ... &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Circle</span>(): Shape() &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Circle.draw() 函数上必须加上 override 修饰符。如果没写，编译器会报错。 如果函 数没有标注 open 如 Shape.fill() ，那么⼦类中不允许定义相同签名的函数， ⽆论加 不加 override 。将 open 修饰符添加到 final 类（即没有 open 的类） 的成员上不起 作⽤。</p>
<p>标记为 override 的成员本身是开放的，因此可以在⼦类中覆盖。如果你想禁⽌再次覆 盖， 使⽤ final 关键字：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Rectangle</span>() : Shape() &#123;</span><br><span class="line"> <span class="keyword">final</span> <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; <span class="comment">/*……*/</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="覆盖属性"><a href="#覆盖属性" class="headerlink" title="覆盖属性"></a>覆盖属性</h4><p>属性与⽅法的覆盖机制相同。在超类中声明然后在派⽣类中重新声明的属性必须以 override 开头，并且它们必须具有兼容的类型。 每个声明的属性可以由具有初始化器 的属性或者具有 get ⽅法的属性覆盖：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Shape</span> &#123;</span><br><span class="line"> <span class="keyword">open</span> <span class="keyword">val</span> vertexCount: <span class="built_in">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span> : <span class="type">Shape</span>() &#123;</span><br><span class="line"> <span class="keyword">override</span> <span class="keyword">val</span> vertexCount = <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>你也可以⽤⼀个 var 属性覆盖⼀个 val 属性，但反之则不⾏。 这是允许的，因为⼀ 个 val 属性本质上声明了⼀个 get ⽅法， ⽽将其覆盖为 var 只是在⼦类中额外声 明⼀个 set ⽅法。 </p>
<p>请注意，你可以在主构造函数中使⽤ override 关键字作为属性声明的⼀部分：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Shape</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> vertexCount: <span class="built_in">Int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>(<span class="keyword">override</span> <span class="keyword">val</span> vertexCount: <span class="built_in">Int</span> = <span class="number">4</span>): Shape</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Polygon</span>: <span class="type">Shape</span> &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">var</span> vertextCount: <span class="built_in">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="派生类初始化顺序"><a href="#派生类初始化顺序" class="headerlink" title="派生类初始化顺序"></a>派生类初始化顺序</h4><p>在构造派⽣类的新实例的过程中，第⼀步完成其基类的初始化 （在之前只有对基类构造 函数参数的求值），这意味着它发⽣在派⽣类的初始化逻辑运⾏之前。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Base</span>(<span class="keyword">val</span> name: String) &#123;</span><br><span class="line">    <span class="keyword">init</span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Initializing a base class&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">open</span> <span class="keyword">val</span> size: <span class="built_in">Int</span> = name.length.also &#123; println(<span class="string">&quot;Initializing size in the base class: <span class="variable">$it</span>&quot;</span>) &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span>(</span><br><span class="line">    name: String,</span><br><span class="line">    <span class="keyword">val</span> lastName: String,</span><br><span class="line">) : Base(name.also &#123; println(<span class="string">&quot;Argument for the base class: <span class="variable">$it</span>&quot;</span>) &#125;) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">init</span> &#123; println(<span class="string">&quot;Initializing a derived class&quot;</span>) &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> size: <span class="built_in">Int</span> =</span><br><span class="line">        (<span class="keyword">super</span>.size + lastName.length).also &#123; println(<span class="string">&quot;Initializing size in the derived class: <span class="variable">$it</span>&quot;</span>) &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">(args: <span class="type">Array</span>&lt;<span class="type">String</span>&gt;)</span></span> &#123;</span><br><span class="line">    println(<span class="string">&quot;Constructing the derived class(\&quot;hello\&quot;, \&quot;world\&quot;)&quot;</span>)</span><br><span class="line">    Derived(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这意味着，基类构造函数执行时，派生类中声明或覆盖的属性都还没有初始化。在基类初始化逻辑中（直接或者通过另一个覆盖的 <code>open</code> 成员的实现间接）使用任何一个这种属性，都可能导致不正确的行为或运行时故障。 设计一个基类时，应该避免在构造函数、属性初始化器或者 <code>init</code> 块中使用 <code>open</code> 成员。</p>
<h4 id="调用超类实现"><a href="#调用超类实现" class="headerlink" title="调用超类实现"></a>调用超类实现</h4><p>派⽣类中的代码可以使⽤ super 关键字调⽤其超类的函数与属性访问器的实现：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Rectangle</span> &#123;</span><br><span class="line">    <span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;Drawing a rectangle&quot;</span>) &#125;</span><br><span class="line">    <span class="keyword">val</span> borderColor: String <span class="keyword">get</span>() = <span class="string">&quot;black&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FilledRectangle</span>: <span class="type">Rectangle</span>() &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">super</span>.draw()</span><br><span class="line">        println(<span class="string">&quot;Filling the rectangle&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> fillColor: String <span class="keyword">get</span> = <span class="keyword">super</span>.borderColor</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在⼀个内部类中访问外部类的超类，可以使⽤由外部类名限定的 super 关键字来实 现： super@Outer ：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Rectangle</span> &#123;</span><br><span class="line">    <span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;Drawing a rectangle&quot;</span>)&#125;</span><br><span class="line">    <span class="keyword">val</span> borderColor: String <span class="keyword">get</span>() = <span class="string">&quot;black&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FilledRectangle</span>: <span class="type">Rectangle</span>() &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">val</span> filler = Filler()</span><br><span class="line">        filler.drawAndFill()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">class</span> <span class="title class_">Filler</span> &#123;</span><br><span class="line">        <span class="function"><span class="keyword">fun</span> <span class="title">fill</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;Filling&quot;</span>)&#125;</span><br><span class="line">        <span class="function"><span class="keyword">fun</span> <span class="title">drawAndFill</span><span class="params">()</span></span> &#123;</span><br><span class="line">            <span class="symbol">super@</span>FilledRectangle.draw()</span><br><span class="line">            fill()</span><br><span class="line">            println(<span class="string">&quot;Drawn a filled rectangle with color <span class="subst">$&#123;super@FilledRectangle.borderColor&#125;</span>&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> fr = FilledRectangle()</span><br><span class="line">    fr.draw()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="覆盖规则"><a href="#覆盖规则" class="headerlink" title="覆盖规则"></a>覆盖规则</h4><p>在 Kotlin 中，实现继承由下述规则规定：如果⼀个类从它的直接超类继承相同成员的多 个实现， 它必须覆盖这个成员并提供其⾃⼰的实现（也许⽤继承来的其中之⼀）。 如需表示采⽤从哪个超类型继承的实现，请使⽤由尖括号中超类型名限定的<code> super</code> ， 如 <code>super &lt;Base&gt;</code>：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Rectangle</span> &#123;</span><br><span class="line"> 	<span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">interface</span> <span class="title class_">Polygon</span> &#123;</span><br><span class="line"> 	<span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123; <span class="comment">/* …… */</span> &#125; <span class="comment">// 接⼝成员默认就是“open”的</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Square</span>() : Rectangle(), Polygon &#123;</span><br><span class="line"> 	<span class="comment">// 编译器要求覆盖 draw()：</span></span><br><span class="line"> 	<span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123;</span><br><span class="line"> 		<span class="keyword">super</span>&lt;Rectangle&gt;.draw() <span class="comment">// 调⽤ Rectangle.draw()</span></span><br><span class="line">		<span class="keyword">super</span>&lt;Polygon&gt;.draw() <span class="comment">// 调⽤ Polygon.draw()</span></span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以同时继承 Rectangle 与 Polygon ， 但是⼆者都有各⾃的 draw() 实现，所以必须 在 Square 中覆盖 draw() ， 并为其提供⼀个单独的实现以消除歧义。</p>
<h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p>Kotlin 类中的属性既可以⽤关键字 var 声明为可变的， 也可以⽤关键字 val 声明为 只读的。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Address</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> name: String = <span class="string">&quot;&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使⽤⼀个属性，以其名称引⽤它即可：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">copyAddress</span><span class="params">(address: <span class="type">Address</span>)</span></span>: Address &#123;</span><br><span class="line">    <span class="keyword">val</span> result = Address()</span><br><span class="line">    result.name = address.name</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="Getter-与-Setter"><a href="#Getter-与-Setter" class="headerlink" title="Getter 与 Setter"></a>Getter 与 Setter</h4><p>声明⼀个属性的完整语法如下</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> &lt;propertyName&gt;[: &lt;PropertyType&gt;] [= &lt;property_initializer&gt;]</span><br><span class="line"> [&lt;getter&gt;]</span><br><span class="line"> [&lt;setter&gt;]</span><br></pre></td></tr></table></figure>

<p>其初始器（initializer）、getter 和 setter 都是可选的。属性类型如果可以从初始器， （或者从初始化器或其 getter 的返回值，如下⽂所示）中推断出来，也可以省略：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> initialized = <span class="number">1</span> <span class="comment">// 类型 Int、默认 getter 和 setter</span></span><br><span class="line"><span class="comment">// var allByDefault // 错误：需要显式初始化器，隐含默认 getter 和 setter</span></span><br></pre></td></tr></table></figure>

<p>⼀个只读属性的语法和⼀个可变的属性的语法有两⽅⾯的不同： 1、只读属性的⽤ val ⽽不是 var 声明 2、只读属性不允许 setter</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> simple: <span class="built_in">Int</span>? <span class="comment">// 类型 Int、默认 getter、必须在构造函数中初始化</span></span><br><span class="line"><span class="keyword">val</span> inferredType = <span class="number">1</span> <span class="comment">// 类型 Int 、默认 getter</span></span><br></pre></td></tr></table></figure>

<p>可以为属性定义⾃定义的访问器。如果定义了⼀个⾃定义的 getter，那么每次访问该属 性时都会调⽤它 （这让可以实现计算出的属性）。以下是⼀个⾃定义 getter 的示例：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>(<span class="keyword">val</span> width: <span class="built_in">Int</span>, <span class="keyword">val</span> height: <span class="built_in">Int</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> area: <span class="built_in">Int</span></span><br><span class="line">    	<span class="keyword">get</span>() = <span class="keyword">this</span>.width * <span class="keyword">this</span>.height</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果可以从 getter 推断出属性类型，则可以省略它：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> area <span class="keyword">get</span>() = <span class="keyword">this</span>.width * <span class="keyword">this</span>.height</span><br></pre></td></tr></table></figure>

<p>如果定义了⼀个⾃定义的 setter，那么每次给属性赋值时都会调⽤它, except its initialization. ⼀个⾃定义的 setter 如下所示：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> stringRepresentation: String</span><br><span class="line">	<span class="keyword">get</span>() = <span class="keyword">this</span>.toString()</span><br><span class="line">	<span class="keyword">set</span>(value) &#123;</span><br><span class="line">        setDataFromString(value)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>按照惯例，setter 参数的名称是 value ，但是如果你喜欢你可以选择⼀个不同的名称。</p>
<p>如果你需要改变对⼀个访问器进⾏注解或者改变其可⻅性，但是不需要改变默认的实 现， 你可以定义访问器⽽不定义其实现:</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> setterVisibility: String = <span class="string">&quot;abc&quot;</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">set</span> <span class="comment">// 此 setter 是私有的并且有默认实现</span></span><br><span class="line"><span class="keyword">var</span> setterWithAnnotation: Any? = <span class="literal">null</span></span><br><span class="line">	<span class="meta">@Inject</span> <span class="keyword">set</span> <span class="comment">// ⽤ Inject 注解此 setter</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>对于 JVM 平台：通过默认 getter 和 setter 访问私有属性会被优化以避免函数调⽤ 开销。</p>
</blockquote>
<h5 id="幕后字段"><a href="#幕后字段" class="headerlink" title="幕后字段"></a>幕后字段</h5><p>在 Kotlin 中，字段仅作为属性的⼀部分在内存中保存其值时使⽤。字段不能直接声明。 然⽽，当⼀个属性需要⼀个幕后字段时，Kotlin 会⾃动提供。这个幕后字段可以使⽤ field 标识符在访问器中引⽤：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> counter = <span class="number">0</span> <span class="comment">// 这个初始器直接为幕后字段赋值</span></span><br><span class="line">	<span class="keyword">set</span>(value) &#123;</span><br><span class="line">        <span class="keyword">if</span> (value &gt;= <span class="number">0</span>)</span><br><span class="line">        	field = value</span><br><span class="line"> 			<span class="comment">// counter = value // ERROR StackOverflow: Using actual name &#x27;counter&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>field</code> 标识符只能⽤在属性的访问器内。</p>
<p>如果属性⾄少⼀个访问器使⽤默认实现， 或者⾃定义访问器通过 field 引⽤幕后字 段，将会为该属性⽣成⼀个幕后字段。</p>
<p>例如，以下情况下就没有幕后字段：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> isEmpty: <span class="built_in">Boolean</span></span><br><span class="line">	<span class="keyword">get</span>() = <span class="keyword">this</span>.size == <span class="number">0</span></span><br></pre></td></tr></table></figure>



<h5 id="幕后属性"><a href="#幕后属性" class="headerlink" title="幕后属性"></a>幕后属性</h5><p>如果你的需求不符合这套隐式的幕后字段⽅案， 那么总可以使⽤ 幕后属性（backing property）：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _table: Map&lt;String, <span class="built_in">Int</span>&gt;? = <span class="literal">null</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">val</span> table: Map&lt;String, <span class="built_in">Int</span>&gt;</span><br><span class="line"> 	<span class="keyword">get</span>() &#123;</span><br><span class="line"> 		<span class="keyword">if</span> (_table == <span class="literal">null</span>) &#123;</span><br><span class="line"> 			_table = HashMap() <span class="comment">// 类型参数已推断出</span></span><br><span class="line"> 		&#125;</span><br><span class="line"> 	<span class="keyword">return</span> _table ?: <span class="keyword">throw</span> AssertionError(<span class="string">&quot;Set to null by another thread&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="编译期属性"><a href="#编译期属性" class="headerlink" title="编译期属性"></a>编译期属性</h4><p>如果只读属性的值在编译期是已知的，那么可以使⽤<code> const</code> 修饰符将其标记为编译期 常量。 这种属性需要满⾜以下要求：</p>
<ul>
<li>必须位于顶层或者是 <code>object 声明</code> 或 <code>伴生对象</code> 的一个成员</li>
<li>必须以 <code>String</code> 或原生类型值初始化</li>
<li>不能有自定义getter</li>
</ul>
<p>这些属性可以⽤在注解中</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">val</span> SUBSYSTEM_DEPRECATED: String = <span class="string">&quot;This subsystem is deprecated&quot;</span></span><br><span class="line"><span class="meta">@Deprecated(SUBSYSTEM_DEPRECATED)</span> <span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">()</span></span> &#123; …… &#125;</span><br></pre></td></tr></table></figure>



<h4 id="延迟初始化属性与变量"><a href="#延迟初始化属性与变量" class="headerlink" title="延迟初始化属性与变量"></a>延迟初始化属性与变量</h4><p>⼀般地，属性声明为⾮空类型必须在构造函数中初始化。 然⽽，这经常不⽅便。例如： 属性可以通过依赖注⼊来初始化， 或者在单元测试的 setup ⽅法中初始化。 这种情况 下，你不能在构造函数内提供⼀个⾮空初始器。 但你仍然想在类体中引⽤该属性时避免 空检测。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyTest</span> &#123;</span><br><span class="line"> 	<span class="keyword">lateinit</span> <span class="keyword">var</span> subject: TestSubject</span><br><span class="line"> 	<span class="meta">@SetUp</span> <span class="function"><span class="keyword">fun</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line"> 		subject = TestSubject()</span><br><span class="line"> 	&#125;</span><br><span class="line">	<span class="meta">@Test</span> <span class="function"><span class="keyword">fun</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line"> 		subject.method() <span class="comment">// 直接解引⽤</span></span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该修饰符只能⽤于在类体中的属性（不是在主构造函数中声明的 var 属性， 并且仅当 该属性没有⾃定义 getter 或 setter 时），也⽤于顶层属性与局部变量。 该属性或变量 必须为⾮空类型，并且不能是原⽣类型。</p>
<p>在初始化前访问⼀个 lateinit 属性会抛出⼀个特定异常，该异常明确标识该属性被访 问及它没有初始化的事实。</p>
<h4 id="检测⼀个-lateinit-var-是否已初始化"><a href="#检测⼀个-lateinit-var-是否已初始化" class="headerlink" title="检测⼀个 lateinit var 是否已初始化"></a>检测⼀个 <code>lateinit var</code> 是否已初始化</h4><p>要检测⼀个<code> lateinit var</code> 是否已经初始化过，请在该属性的引⽤上使⽤<code> .isInitialized</code>：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (foo::bar.isInitialized) &#123;</span><br><span class="line"> 	println(foo.bar)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此检测仅对可词法级访问的属性可⽤，当声明位于同⼀个类型内、位于其中⼀个外围类 型中或者位于相同⽂件的顶层的属性时。</p>
<h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><p>类以及其中的某些或全部成员可以声明为<code>abstract</code>。抽象成员在本类中可以不用实现。并不需要用<code>open</code>标注抽象类或函数。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Polygon</span> &#123;</span><br><span class="line">    <span class="keyword">abstract</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>: <span class="type">Polygon</span>() &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以用一个抽象成员覆盖一个非抽象的开放成员</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Polygon</span> &#123;</span><br><span class="line">    <span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span> &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">WildShape</span>: <span class="type">Polygon</span>() &#123;</span><br><span class="line">    <span class="keyword">abstract</span> <span class="function"><span class="keyword">fun</span> <span class="title">draw</span><span class="params">()</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>Kotlin 的接⼝可以既包含抽象⽅法的声明也包含实现。与抽象类不同的是，接⼝⽆法保 存状态。它可以有属性但必须声明为抽象或提供访问器实现。</p>
<p>使⽤关键字 <code>interface</code> 来定义接⼝：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">MyInterface</span> &#123;</span><br><span class="line"> 	<span class="function"><span class="keyword">fun</span> <span class="title">bar</span><span class="params">()</span></span></span><br><span class="line"> 	<span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">()</span></span> &#123;</span><br><span class="line"> 		<span class="comment">// 可选的⽅法体</span></span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="实现接口"><a href="#实现接口" class="headerlink" title="实现接口"></a>实现接口</h4><p>⼀个类或者对象可以实现⼀个或多个接⼝：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Child</span> : <span class="type">MyInterface</span> &#123;</span><br><span class="line"> 	<span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">bar</span><span class="params">()</span></span> &#123;</span><br><span class="line"> 		<span class="comment">// ⽅法体</span></span><br><span class="line"> 	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="接⼝中的属性"><a href="#接⼝中的属性" class="headerlink" title="接⼝中的属性"></a>接⼝中的属性</h4><p>可以在接⼝中定义属性。在接⼝中声明的属性要么是抽象的，要么提供访问器的实现。 在接⼝中声明的属性不能有幕后字段（backing field），因此接⼝中声明的访问器不能 引⽤它们：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">MyInterface</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> prop: <span class="built_in">Int</span> <span class="comment">// 抽象的</span></span><br><span class="line">    <span class="keyword">val</span> propertyWithImplementation: String</span><br><span class="line">        <span class="keyword">get</span>() = <span class="string">&quot;foo&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">()</span></span> &#123;</span><br><span class="line">        print(prop)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Child</span> : <span class="type">MyInterface</span> &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> prop: <span class="built_in">Int</span> = <span class="number">29</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="接⼝继承"><a href="#接⼝继承" class="headerlink" title="接⼝继承"></a>接⼝继承</h4><p>⼀个接⼝可以从其他接⼝派⽣，意味着既能提供基类型成员的实现也能声明新的函数与属性。很⾃然地，实现这样接⼝的类只需定义所缺少的实现：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Named</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> name: String</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">interface</span> <span class="title class_">Person</span> : <span class="type">Named</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> firstName: String</span><br><span class="line">    <span class="keyword">val</span> lastName: String</span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> name: String <span class="keyword">get</span>() = <span class="string">&quot;<span class="variable">$firstName</span> <span class="variable">$lastName</span>&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">data</span> <span class="keyword">class</span> <span class="title class_">Employee</span>(</span><br><span class="line">    <span class="comment">// 不必实现“name”</span></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> firstName: String,</span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">val</span> lastName: String,</span><br><span class="line">    <span class="keyword">val</span> position: Position</span><br><span class="line">) : Person</span><br></pre></td></tr></table></figure>



<h4 id="解决覆盖冲突"><a href="#解决覆盖冲突" class="headerlink" title="解决覆盖冲突"></a>解决覆盖冲突</h4><p>实现多个接⼝时，可能会遇到同⼀⽅法继承多个实现的问题：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">()</span></span> &#123; print(<span class="string">&quot;A&quot;</span>) &#125;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">bar</span><span class="params">()</span></span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">interface</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">()</span></span> &#123; print(<span class="string">&quot;B&quot;</span>) &#125;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">bar</span><span class="params">()</span></span> &#123; print(<span class="string">&quot;bar&quot;</span>) &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">C</span> : <span class="type">A</span> &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">bar</span><span class="params">()</span></span> &#123; print(<span class="string">&quot;bar&quot;</span>) &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">D</span> : <span class="type">A</span>, <span class="type">B</span> &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">super</span>&lt;A&gt;.foo()</span><br><span class="line">        <span class="keyword">super</span>&lt;B&gt;.foo()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">bar</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">super</span>&lt;B&gt;.bar()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上例中，接⼝ A 和 B 都定义了⽅法 foo() 和 bar()。 两者都实现了 foo(), 但是只有 B 实 现了 bar() (bar() 在 A 中没有标记为抽象， 因为在接⼝中没有⽅法体时默认为抽象）。 现在，如果实现 A 的⼀个具体类 C，那么必须要重写 bar() 并实现这个抽象⽅法。 </p>
<p>然⽽，如果从 A 和 B 派⽣ D，需要实现从多个接⼝继承的所有⽅法，并指明 D 应该如 何实现它们。这⼀规则既适⽤于继承单个实现（bar()）的⽅法也适⽤于继承多个实现 （foo()）的⽅法。</p>
<h3 id="函数式（SAM）接⼝"><a href="#函数式（SAM）接⼝" class="headerlink" title="函数式（SAM）接⼝"></a>函数式（SAM）接⼝</h3><p>只有⼀个抽象⽅法的接⼝称为函数式接⼝或 单⼀抽象⽅法（SAM）接⼝。函数式接⼝ 可以有多个⾮抽象成员，但只能有⼀个抽象成员。 可以⽤ <code>fun</code> 修饰符在 Kotlin 中声明⼀个函数式接⼝。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="keyword">interface</span> KRunnable &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">invoke</span><span class="params">()</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="SAM转换"><a href="#SAM转换" class="headerlink" title="SAM转换"></a>SAM转换</h4><p>对于函数式接口，可以通过 <a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/lambdas.html#lambda-%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0">lambda 表达式</a>实现 SAM 转换，从而使代码更简洁、更有可读性。</p>
<p>使用 lambda 表达式可以替代手动创建实现函数式接口的类。 通过 SAM 转换， Kotlin can convert any lambda expression whose signature matches the signature of the interface’s single method into the code, which dynamically instantiates the interface implementation.</p>
<p>例如，有这样一个 Kotlin 函数式接口：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="keyword">interface</span> IntPredicate &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">accept</span><span class="params">(i: <span class="type">Int</span>)</span></span>: <span class="built_in">Boolean</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果不使用 SAM 转换，那么你需要像这样编写代码：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个类的实例</span></span><br><span class="line"><span class="keyword">val</span> isEven = <span class="keyword">object</span> : IntPredicate &#123;</span><br><span class="line">   <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">accept</span><span class="params">(i: <span class="type">Int</span>)</span></span>: <span class="built_in">Boolean</span> &#123;</span><br><span class="line">       <span class="keyword">return</span> i % <span class="number">2</span> == <span class="number">0</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过利用 Kotlin 的 SAM 转换，可以改为以下等效代码：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过 lambda 表达式创建一个实例</span></span><br><span class="line"><span class="keyword">val</span> isEven = IntPredicate &#123; it % <span class="number">2</span> == <span class="number">0</span> &#125;</span><br></pre></td></tr></table></figure>

<p>可以通过更短的 lambda 表达式替换所有不必要的代码。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="keyword">interface</span> IntPredicate &#123;</span></span><br><span class="line">   <span class="function"><span class="keyword">fun</span> <span class="title">accept</span><span class="params">(i: <span class="type">Int</span>)</span></span>: <span class="built_in">Boolean</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> isEven = IntPredicate &#123; it % <span class="number">2</span> == <span class="number">0</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">   println(<span class="string">&quot;Is 7 even? - <span class="subst">$&#123;isEven.accept(<span class="number">7</span>)&#125;</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="函数式接口与类型别名比较"><a href="#函数式接口与类型别名比较" class="headerlink" title="函数式接口与类型别名比较"></a>函数式接口与类型别名比较</h4><p>函数式接口和<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/type-aliases.html">类型别名</a>用途并不相同。 类型别名只是现有类型的名称——它们不会创建新的类型，而函数式接口却会创建新类型。 You can provide extensions that are specific to a particular functional interface to be inapplicable for plain functions or their type aliases.</p>
<p>类型别名只能有一个成员，而函数式接口可以有多个非抽象成员以及一个抽象成员。 函数式接口还可以实现以及继承其他接口。</p>
<p>函数式接口比类型别名更灵活并且提供了更多的功能, but they can be more costly both syntactically and at runtime because they can require conversions to a specific interface. When you choose which one to use in your code, consider your needs:</p>
<ul>
<li>If your API needs to accept a function (any function) with some specific parameter and return types – use a simple functional type or define a type alias to give a shorter name to the corresponding functional type.</li>
<li>If your API accepts a more complex entity than a function – for example, it has non-trivial contracts and&#x2F;or operations on it that can’t be expressed in a functional type’s signature – declare a separate functional interface for it.</li>
</ul>
<h3 id="可见性修饰符"><a href="#可见性修饰符" class="headerlink" title="可见性修饰符"></a>可见性修饰符</h3><p>在 Kotlin 中有这四个可见性修饰符：<code>private</code>、 <code>protected</code>、 <code>internal</code> 和 <code>public</code>。 默认可见性是 <code>public</code>。</p>
<h4 id="包"><a href="#包" class="headerlink" title="包"></a>包</h4><p>函数、属性和类、对象和接口可以直接在包内的顶层声明：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> foo</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">baz</span><span class="params">()</span></span> &#123; …… &#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bar</span> &#123; …… &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>如果你不使用任何可见性修饰符，默认为 <code>public</code>，这意味着你的声明将随处可见。</li>
<li>如果你声明为 <code>private</code>，它只会在声明它的文件内可见。</li>
<li>如果你声明为 <code>internal</code>，它会在相同<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/visibility-modifiers.html#%E6%A8%A1%E5%9D%97">模块</a>内随处可见。</li>
<li><code>protected</code> 修饰符不适用于顶层声明。</li>
</ul>
<h4 id="类成员-1"><a href="#类成员-1" class="headerlink" title="类成员"></a>类成员</h4><p>对于类内部声明的成员：</p>
<ul>
<li><code>private</code> 意味着只该成员在这个类内部（包含其所有成员）可见；</li>
<li><code>protected</code> 意味着该成员具有与 <code>private</code> 一样的可见性，但也在子类中可见。</li>
<li><code>internal</code> 意味着能见到类声明的<em>本模块内</em>的任何客户端都可见其 <code>internal</code> 成员。</li>
<li><code>public</code> 移位置能见到类声明的任何客户端都可见其 <code>public</code> 成员。</li>
</ul>
<blockquote>
<p>在 Kotlin 中，外部类不能访问内部类的 private 成员。</p>
</blockquote>
<p>如果你覆盖一个 <code>protected</code> 或 <code>internal</code> 成员并且没有显式指定其可见性，该成员还会具有与原始成员相同的可见性。</p>
<h4 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">C</span> <span class="keyword">private</span> <span class="keyword">constructor</span>(a: <span class="built_in">Int</span>) &#123; …… &#125;</span><br></pre></td></tr></table></figure>

<p>这里的构造函数是私有的。默认情况下，所有构造函数都是 <code>public</code>，这实际上等于类可见的地方它就可见（即 一个 <code>internal</code> 类的构造函数只能在相同模块内可见).</p>
<h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><p>可见性修饰符 <code>internal</code> 意味着该成员只在相同模块内可见。更具体地说， 一个模块是编译在一起的一套 Kotlin 文件，例如：</p>
<ul>
<li>一个 IntelliJ IDEA 模块</li>
<li>一个 Maven 项目</li>
<li>一个 Gradle 源代码集（例外是 <code>test</code> 源代码集可以访问 <code>main</code> 的 internal 声明）</li>
<li>一次 <code>&lt;kotlinc&gt;</code> Ant 任务执行所编译的一套文件</li>
</ul>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>Kotlin 能够对一个类扩展新功能而无需继承该类或者使用像<em>装饰者</em>这样的设计模式。 这通过叫做<em>扩展</em>的特殊声明完成。</p>
<p>例如，你可以为一个你不能修改的、来自第三方库中的类编写一个新的函数。 这个新增的函数就像那个原始类本来就有的函数一样，可以用寻常方式调用。 这种机制称为<em>扩展函数</em>。此外，也有<em>扩展属性</em>， 允许你为一个已经存在的类添加新的属性。</p>
<h4 id="扩展函数"><a href="#扩展函数" class="headerlink" title="扩展函数"></a>扩展函数</h4><p>声明一个扩展函数需用一个<em>接收者类型</em>也就是被扩展的类型来作为他的前缀。 下面代码为 <code>MutableList&lt;Int&gt;</code> 添加一个<code>swap</code> 函数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> MutableList<span class="type">&lt;Int&gt;</span>.<span class="title">swap</span><span class="params">(index1: <span class="type">Int</span>, index2: <span class="type">Int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> tmp = <span class="keyword">this</span>[index1] <span class="comment">// “this”对应该列表</span></span><br><span class="line">    <span class="keyword">this</span>[index1] = <span class="keyword">this</span>[index2]</span><br><span class="line">    <span class="keyword">this</span>[index2] = tmp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个 <code>this</code> 关键字在扩展函数内部对应到接收者对象（传过来的在点符号前的对象） 现在，可以对任意 <code>MutableList&lt;Int&gt;</code> 调用该函数了：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list = mutableListOf(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">list.swap(<span class="number">0</span>, <span class="number">2</span>) <span class="comment">// “swap()”内部的“this”会保存“list”的值</span></span><br></pre></td></tr></table></figure>

<p>这个函数对任何 <code>MutableList&lt;T&gt;</code> 起作用，可以泛化它：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="type">&lt;T&gt;</span> MutableList<span class="type">&lt;T&gt;</span>.<span class="title">swap</span><span class="params">(index1: <span class="type">Int</span>, index2: <span class="type">Int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> tmp = <span class="keyword">this</span>[index1] <span class="comment">// “this”对应该列表</span></span><br><span class="line">    <span class="keyword">this</span>[index1] = <span class="keyword">this</span>[index2]</span><br><span class="line">    <span class="keyword">this</span>[index2] = tmp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为了在接收者类型表达式中使用泛型，需要在函数名前声明泛型参数。</p>
<h4 id="扩展是静态解析的"><a href="#扩展是静态解析的" class="headerlink" title="扩展是静态解析的"></a>扩展是静态解析的</h4><p>扩展不能真正的修改他们所扩展的类。通过定义一个扩展，并没有在一个类中插入新成员， 只不过是可以通过该类型的变量用点表达式去调用这个新函数。</p>
<p>扩展函数是<em>静态</em>分发的，即他们不是根据接收者类型的虚方法。 调用的扩展函数是由函数调用所在的表达式的类型来决定的， 而不是由表达式运行时求值结果决定的。例如：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Shape</span></span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Rectangle</span>: <span class="type">Shape</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> Shape.<span class="title">getName</span><span class="params">()</span></span> = <span class="string">&quot;Shape&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> Rectangle.<span class="title">getName</span><span class="params">()</span></span> = <span class="string">&quot;Rectangle&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">printClassName</span><span class="params">(s: <span class="type">Shape</span>)</span></span> &#123;</span><br><span class="line">        println(s.getName())</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    printClassName(Rectangle())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个例子会输出 <em>Shape</em>，因为调用的扩展函数只取决于参数 <code>s</code> 的声明类型，该类型是 <code>Shape</code> 类。</p>
<p>如果一个类定义有一个成员函数与一个扩展函数，而这两个函数又有相同的接收者类型、 相同的名字，并且都适用给定的参数，这种情况<em>总是取成员函数</em>。 例如：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Example</span> &#123;</span><br><span class="line">        <span class="function"><span class="keyword">fun</span> <span class="title">printFunctionType</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;Class method&quot;</span>) &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> Example.<span class="title">printFunctionType</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;Extension function&quot;</span>) &#125;</span><br><span class="line">    Example().printFunctionType()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码输出 <em>Class method</em>。</p>
<p>当然，扩展函数重载同样名字但不同签名成员函数也完全可以：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Example</span> &#123;</span><br><span class="line">        <span class="function"><span class="keyword">fun</span> <span class="title">printFunctionType</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;Class method&quot;</span>) &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> Example.<span class="title">printFunctionType</span><span class="params">(i: <span class="type">Int</span>)</span></span> &#123; println(<span class="string">&quot;Extension function #<span class="variable">$i</span>&quot;</span>) &#125;</span><br><span class="line">    Example().printFunctionType(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="可空接收者"><a href="#可空接收者" class="headerlink" title="可空接收者"></a>可空接收者</h4><p>注意可以为可空的接收者类型定义扩展。这样的扩展可以在对象变量上调用， 即使其值为 null，并且可以在函数体内检测 <code>this == null</code>。</p>
<p>这样，就可以在没有检测 null 的时候调用 Kotlin 中的toString()：检测发生在扩展函数的内部：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> Any?.<span class="title">toString</span><span class="params">()</span></span>: String &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span> == <span class="literal">null</span>) <span class="keyword">return</span> <span class="string">&quot;null&quot;</span></span><br><span class="line">    <span class="comment">// 空检测之后，“this”会自动转换为非空类型，所以下面的 toString()</span></span><br><span class="line">    <span class="comment">// 解析为 Any 类的成员函数</span></span><br><span class="line">    <span class="keyword">return</span> toString()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="扩展属性"><a href="#扩展属性" class="headerlink" title="扩展属性"></a>扩展属性</h4><p>与扩展函数类似，Kotlin 支持扩展属性：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> &lt;T&gt; List&lt;T&gt;.lastIndex: <span class="built_in">Int</span></span><br><span class="line">    <span class="keyword">get</span>() = size - <span class="number">1</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>由于扩展没有实际的将成员插入类中，因此对扩展属性来说<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/properties.html#%E5%B9%95%E5%90%8E%E5%AD%97%E6%AE%B5">幕后字段</a>是无效的。这就是为什么<em>扩展属性不能有初始化器</em>。他们的行为只能由显式提供的 getter&#x2F;setter 定义。</p>
</blockquote>
<p>例如:</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> House.number = <span class="number">1</span> <span class="comment">// 错误：扩展属性不能有初始化器</span></span><br></pre></td></tr></table></figure>



<h4 id="伴生对象的扩展"><a href="#伴生对象的扩展" class="headerlink" title="伴生对象的扩展"></a>伴生对象的扩展</h4><p>如果一个类定义有一个<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/object-declarations.html#%E4%BC%B4%E7%94%9F%E5%AF%B9%E8%B1%A1">伴生对象</a> ，你也可以为伴生对象定义扩展函数与属性。就像伴生对象的常规成员一样， 可以只使用类名作为限定符来调用伴生对象的扩展成员：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">companion</span> <span class="keyword">object</span> &#123; &#125;  <span class="comment">// 将被称为 &quot;Companion&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> MyClass.Companion.<span class="title">printCompanion</span><span class="params">()</span></span> &#123; println(<span class="string">&quot;companion&quot;</span>) &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    MyClass.printCompanion()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="扩展的作用域"><a href="#扩展的作用域" class="headerlink" title="扩展的作用域"></a>扩展的作用域</h4><p>大多数情况都在顶层定义扩展——直接在包里：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.declarations</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> List<span class="type">&lt;String&gt;</span>.<span class="title">getLongestString</span><span class="params">()</span></span> &#123; <span class="comment">/*……*/</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如需使用所定义包之外的一个扩展，只需在调用方导入它：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.usage</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.example.declarations.getLongestString</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> list = listOf(<span class="string">&quot;red&quot;</span>, <span class="string">&quot;green&quot;</span>, <span class="string">&quot;blue&quot;</span>)</span><br><span class="line">    list.getLongestString()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="扩展声明为成员"><a href="#扩展声明为成员" class="headerlink" title="扩展声明为成员"></a>扩展声明为成员</h4><p>可以在一个类内部为另一个类声明扩展。在这样的扩展内部，有多个<em>隐式接收者</em>—— 其中的对象成员可以无需通过限定符访问。扩展声明所在的类的实例称为<em>分发接收者</em>，扩展方法调用所在的接收者类型的实例称为<em>扩展接收者</em>。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Host</span>(<span class="keyword">val</span> hostname: String) &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">printHostname</span><span class="params">()</span></span> &#123; print(hostname) &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Connection</span>(<span class="keyword">val</span> host: Host, <span class="keyword">val</span> port: <span class="built_in">Int</span>) &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">printPort</span><span class="params">()</span></span> &#123; print(port) &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> Host.<span class="title">printConnectionString</span><span class="params">()</span></span> &#123;</span><br><span class="line">         printHostname()   <span class="comment">// 调用 Host.printHostname()</span></span><br><span class="line">        print(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">         printPort()   <span class="comment">// 调用 Connection.printPort()</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">connect</span><span class="params">()</span></span> &#123;</span><br><span class="line">         <span class="comment">/*……*/</span></span><br><span class="line">         host.printConnectionString()   <span class="comment">// 调用扩展函数</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    Connection(Host(<span class="string">&quot;kotl.in&quot;</span>), <span class="number">443</span>).connect()</span><br><span class="line">    <span class="comment">//Host(&quot;kotl.in&quot;).printConnectionString()  // 错误，该扩展函数在 Connection 外不可用</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对于分发接收者与扩展接收者的成员名字冲突的情况，扩展接收者优先。要引用分发接收者的成员你可以使用 <a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/this-expressions.html#%E9%99%90%E5%AE%9A%E7%9A%84-this">限定的 <code>this</code> 语法</a>。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Connection</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> Host.<span class="title">getConnectionString</span><span class="params">()</span></span> &#123;</span><br><span class="line">        toString()         <span class="comment">// 调用 Host.toString()</span></span><br><span class="line">        <span class="keyword">this</span><span class="symbol">@Connection</span>.toString()  <span class="comment">// 调用 Connection.toString()</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>声明为成员的扩展可以声明为 <code>open</code> 并在子类中覆盖。这意味着这些函数的分发对于分发接收者类型是虚拟的，但对于扩展接收者类型是静态的。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Base</span> &#123; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="type">Base</span>() &#123; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">BaseCaller</span> &#123;</span><br><span class="line">    <span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> Base.<span class="title">printFunctionInfo</span><span class="params">()</span></span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Base extension function in BaseCaller&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">open</span> <span class="function"><span class="keyword">fun</span> Derived.<span class="title">printFunctionInfo</span><span class="params">()</span></span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Derived extension function in BaseCaller&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">call</span><span class="params">(b: <span class="type">Base</span>)</span></span> &#123;</span><br><span class="line">        b.printFunctionInfo()   <span class="comment">// 调用扩展函数</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DerivedCaller</span>: <span class="type">BaseCaller</span>() &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> Base.<span class="title">printFunctionInfo</span><span class="params">()</span></span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Base extension function in DerivedCaller&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> Derived.<span class="title">printFunctionInfo</span><span class="params">()</span></span> &#123;</span><br><span class="line">        println(<span class="string">&quot;Derived extension function in DerivedCaller&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    BaseCaller().call(Base())   <span class="comment">// “Base extension function in BaseCaller”</span></span><br><span class="line">    DerivedCaller().call(Base())  <span class="comment">// “Base extension function in DerivedCaller”——分发接收者虚拟解析</span></span><br><span class="line">    DerivedCaller().call(Derived())  <span class="comment">// “Base extension function in DerivedCaller”——扩展接收者静态解析</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="关于可见性的说明"><a href="#关于可见性的说明" class="headerlink" title="关于可见性的说明"></a>关于可见性的说明</h4><ul>
<li>在文件顶层声明的扩展可以访问同一文件中的其他 <code>private</code> 顶层声明。</li>
<li>如果扩展是在其接收者类型外部声明的，那么它不能访问接收者的 <code>private</code> 或 <code>protected</code> 成员。</li>
</ul>
<h3 id="数据类"><a href="#数据类" class="headerlink" title="数据类"></a>数据类</h3><p>创建一些只保存数据的类是件寻常的事。 在这些类中，一些标准功能以及一些工具函数往往是由数据机械推导而来的。在 Kotlin 中，这叫做 <em>数据类</em> 并以 <code>data</code> 标记：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">data</span> <span class="keyword">class</span> <span class="title class_">User</span>(<span class="keyword">val</span> name: String, <span class="keyword">val</span> age: <span class="built_in">Int</span>)</span><br></pre></td></tr></table></figure>

<p>编译器自动从主构造函数中声明的所有属性导出以下成员：</p>
<ul>
<li><code>equals()</code>&#x2F;<code>hashCode()</code> 对</li>
<li><code>toString()</code> 格式是 <code>&quot;User(name=John, age=42)&quot;</code></li>
<li><a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/destructuring-declarations.html"><code>componentN()</code> 函数</a> 按声明顺序对应于所有属性。</li>
<li><code>copy()</code> 函数（见下文）</li>
</ul>
<p>为了确保生成的代码的一致性以及有意义的行为，数据类必须满足以下要求：</p>
<ul>
<li>主构造函数需要至少有一个参数。</li>
<li>主构造函数的所有参数需要标记为 <code>val</code> 或 <code>var</code>。</li>
<li>数据类不能是抽象、开放、密封或者内部的。</li>
</ul>
<p>此外，数据类成员的生成遵循关于成员继承的这些规则：</p>
<ul>
<li>如果在数据类体中有显式实现 <code>equals()</code>、 <code>hashCode()</code> 或者 <code>toString()</code>，或者这些函数在父类中有 <code>final</code> 实现，那么不会生成这些函数，而会使用现有函数。</li>
<li>如果超类型具有 <code>open</code> 的 <code>componentN()</code> 函数并且返回兼容的类型， 那么会为数据类生成相应的函数，并覆盖超类的实现。如果超类型的这些函数由于签名不兼容或者是 final 而导致无法覆盖，那么会报错。</li>
<li>不允许为 <code>componentN()</code> 以及 <code>copy()</code> 函数提供显式实现。</li>
</ul>
<p>数据类可以扩展其他类（示例请参见<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/sealed-classes.html">密封类</a>）。</p>
<blockquote>
<p>在 JVM 中，如果生成的类需要含有一个无参的构造函数，那么属性必须指定默认值。（参见<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/classes.html#%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0">构造函数</a>）。</p>
</blockquote>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">data</span> <span class="keyword">class</span> <span class="title class_">User</span>(<span class="keyword">val</span> name: String = <span class="string">&quot;&quot;</span>, <span class="keyword">val</span> age: <span class="built_in">Int</span> = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h4 id="在类体中声明的属性"><a href="#在类体中声明的属性" class="headerlink" title="在类体中声明的属性"></a>在类体中声明的属性</h4><p>请注意，对于那些自动生成的函数，编译器只使用在主构造函数内部定义的属性。 如需在生成的实现中排除一个属性，请将其声明在类体中：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">data</span> <span class="keyword">class</span> <span class="title class_">Person</span>(<span class="keyword">val</span> name: String) &#123;</span><br><span class="line">    <span class="keyword">var</span> age: <span class="built_in">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 <code>toString()</code>、 <code>equals()</code>、 <code>hashCode()</code> 以及 <code>copy()</code> 的实现中只会用到 <code>name</code> 属性， 并且只有一个 component 函数 <code>component1()</code>。虽然两个 <code>Person</code> 对象可以有不同的年龄， 但它们会视为相等。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">data</span> <span class="keyword">class</span> <span class="title class_">Person</span>(<span class="keyword">val</span> name: String) &#123;</span><br><span class="line">    <span class="keyword">var</span> age: <span class="built_in">Int</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">//sampleStart</span></span><br><span class="line">    <span class="keyword">val</span> person1 = Person(<span class="string">&quot;John&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> person2 = Person(<span class="string">&quot;John&quot;</span>)</span><br><span class="line">    person1.age = <span class="number">10</span></span><br><span class="line">    person2.age = <span class="number">20</span></span><br><span class="line"><span class="comment">//sampleEnd</span></span><br><span class="line">    println(<span class="string">&quot;person1 == person2: <span class="subst">$&#123;person1 == person2&#125;</span>&quot;</span>)</span><br><span class="line">    println(<span class="string">&quot;person1 with age <span class="subst">$&#123;person1.age&#125;</span>: <span class="subst">$&#123;person1&#125;</span>&quot;</span>)</span><br><span class="line">    println(<span class="string">&quot;person2 with age <span class="subst">$&#123;person2.age&#125;</span>: <span class="subst">$&#123;person2&#125;</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h4><p>Use the <code>copy()</code> function to copy an object, allowing you to alter <em>some</em> of its properties while keeping the rest unchanged. The implementation of this function for the <code>User</code> class above would be as follows:</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">copy</span><span class="params">(name: <span class="type">String</span> = this.name, age: <span class="type">Int</span> = this.age)</span></span> = User(name, age)</span><br></pre></td></tr></table></figure>

<p>然后可以这样写：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> jack = User(name = <span class="string">&quot;Jack&quot;</span>, age = <span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> olderJack = jack.copy(age = <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="数据类与解构声明"><a href="#数据类与解构声明" class="headerlink" title="数据类与解构声明"></a>数据类与解构声明</h4><p>为数据类生成的 <em>component 函数</em> 使它们可在<a target="_blank" rel="noopener" href="https://book.kotlincn.net/text/destructuring-declarations.html">解构声明</a>中使用：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> jane = User(<span class="string">&quot;Jane&quot;</span>, <span class="number">35</span>)</span><br><span class="line"><span class="keyword">val</span> (name, age) = jane</span><br><span class="line">println(<span class="string">&quot;<span class="variable">$name</span>, <span class="variable">$age</span> years of age&quot;</span>) <span class="comment">// 输出 &quot;Jane, 35 years of age&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="标准数据类"><a href="#标准数据类" class="headerlink" title="标准数据类"></a>标准数据类</h4><p>标准库提供了 <code>Pair</code> 与 <code>Triple</code> 类。尽管在很多情况下具名数据类是更好的设计选择， 因为它们通过为属性提供有意义的名称使代码更具可读性。</p>
<h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><p>Kotlin 中的类可以有类型参数，与 Java 类似：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Box</span>&lt;<span class="type">T</span>&gt;(t: T) &#123;</span><br><span class="line">    <span class="keyword">var</span> value = t</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>创建这样类的实例只需提供类型参数即可：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> box: Box&lt;<span class="built_in">Int</span>&gt; = Box&lt;<span class="built_in">Int</span>&gt;(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>但是如果类型参数可以推断出来，例如从构造函数的参数或者从其他途径， 就可以省略类型参数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> box = Box(<span class="number">1</span>) <span class="comment">// 1 具有类型 Int，所以编译器推算出它是 Box&lt;Int&gt;</span></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/12/23/kotlin%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/23/kotlin%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">Kotlin基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-23 18:13:33" itemprop="dateCreated datePublished" datetime="2021-12-23T18:13:33+08:00">2021-12-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-05-14 15:08:26" itemprop="dateModified" datetime="2022-05-14T15:08:26+08:00">2022-05-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><h4 id="包的定义和导入"><a href="#包的定义和导入" class="headerlink" title="包的定义和导入"></a>包的定义和导入</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.demo</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kotlin.text.*</span><br></pre></td></tr></table></figure>



<h4 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">(args: <span class="type">Array</span>&lt;<span class="type">String</span>&gt;)</span></span> &#123;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;hello world&quot;</span>) <span class="comment">//将其参数打到标准输出</span></span><br><span class="line">println(<span class="string">&quot;hello world&quot;</span>) <span class="comment">//输出其参数并添加换行符</span></span><br></pre></td></tr></table></figure>



<h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">add</span><span class="params">(a: <span class="type">Int</span>, b: <span class="type">Int</span>)</span></span>: <span class="built_in">Int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//函数体可以是表达式。其返回类型可以推断出来。</span></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">add2</span><span class="params">(a: <span class="type">Int</span>, b: <span class="type">Int</span>)</span></span> = a + b</span><br><span class="line"></span><br><span class="line"><span class="comment">//返回无意义的值, Unit 返回类型可以省略</span></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">printSum</span><span class="params">(a: <span class="type">Int</span>, b: <span class="type">Int</span>)</span></span>: <span class="built_in">Unit</span> &#123;</span><br><span class="line">    println(<span class="string">&quot;sum of <span class="variable">$a</span> and <span class="variable">$b</span> is <span class="subst">$&#123;a + b&#125;</span>&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    add(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a: <span class="built_in">Int</span> = <span class="number">10</span> <span class="comment">// var 变量</span></span><br><span class="line"><span class="keyword">val</span> b: <span class="built_in">Int</span> = <span class="number">5</span>  <span class="comment">// val 常量</span></span><br></pre></td></tr></table></figure>



<h4 id="类"><a href="#类" class="headerlink" title="类"></a>类</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// class定义类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Shape</span></span><br><span class="line"><span class="comment">//类的属性可以在其声明或主体中列出</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>(<span class="keyword">var</span> height: <span class="built_in">Double</span>, <span class="keyword">var</span> length: <span class="built_in">Double</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> perimeter = (height + length) * <span class="number">2</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具有类声明中所列参数的默认构造函数会自动可用。</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>(<span class="keyword">var</span> height: <span class="built_in">Double</span>, <span class="keyword">var</span> length: <span class="built_in">Double</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> perimeter = (height + length) * <span class="number">2</span> </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> rectangle = Rectangle(<span class="number">5.0</span>, <span class="number">2.0</span>)</span><br><span class="line">    println(<span class="string">&quot;The perimeter is <span class="subst">$&#123;rectangle.perimeter&#125;</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>类之间继承由冒号（<code>:</code>）声明。默认情况下类都是 final 的；如需让一个类可继承， 请将其标记为 <code>open</code></p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">open</span> <span class="keyword">class</span> <span class="title class_">Shape</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>(<span class="keyword">var</span> height: <span class="built_in">Double</span>, <span class="keyword">var</span> length: <span class="built_in">Double</span>): Shape() &#123;</span><br><span class="line">    <span class="keyword">var</span> perimeter = (height + length) * <span class="number">2</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="习惯用法"><a href="#习惯用法" class="headerlink" title="习惯用法"></a>习惯用法</h3><h4 id="函数默认参数"><a href="#函数默认参数" class="headerlink" title="函数默认参数"></a>函数默认参数</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">foo</span><span class="params">(a: <span class="type">Int</span> = <span class="number">0</span>, b: <span class="type">String</span> = <span class="string">&quot;&quot;</span>)</span></span></span><br></pre></td></tr></table></figure>



<h4 id="过滤list"><a href="#过滤list" class="headerlink" title="过滤list"></a>过滤list</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> positives = list.filter&#123; x -&gt; x &gt; <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment">//或者</span></span><br><span class="line"><span class="keyword">val</span> positives = list.filter&#123; it &gt; <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure>



<h4 id="检测元素是否在集合中"><a href="#检测元素是否在集合中" class="headerlink" title="检测元素是否在集合中"></a>检测元素是否在集合中</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="string">&quot;abc&quot;</span> <span class="keyword">in</span> list)</span><br><span class="line"><span class="keyword">if</span> (<span class="string">&quot;abc&quot;</span> !<span class="keyword">in</span> list)</span><br></pre></td></tr></table></figure>



<h4 id="字符串内插"><a href="#字符串内插" class="headerlink" title="字符串内插"></a>字符串内插</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> name = <span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">println(<span class="string">&quot;name is <span class="variable">$name</span>&quot;</span>)</span><br></pre></td></tr></table></figure>



<h4 id="when"><a href="#when" class="headerlink" title="when"></a>when</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">when</span>(x) &#123;</span><br><span class="line">    <span class="keyword">is</span> A -&gt; ...</span><br><span class="line">    <span class="keyword">is</span> B -&gt; ...</span><br><span class="line">    <span class="keyword">else</span> -&gt; ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="快速生成List"><a href="#快速生成List" class="headerlink" title="快速生成List"></a>快速生成List</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list = listOf(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br></pre></td></tr></table></figure>



<h4 id="快速生成map"><a href="#快速生成map" class="headerlink" title="快速生成map"></a>快速生成map</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> map = mapOf(<span class="string">&quot;a&quot;</span> to <span class="number">1</span>, <span class="string">&quot;b&quot;</span> to <span class="number">2</span>, <span class="string">&quot;c&quot;</span> to <span class="number">3</span>)</span><br></pre></td></tr></table></figure>



<h4 id="访问map"><a href="#访问map" class="headerlink" title="访问map"></a>访问map</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">println(map[<span class="string">&quot;key&quot;</span>])</span><br><span class="line">map[<span class="string">&quot;key&quot;</span>] = value</span><br></pre></td></tr></table></figure>



<h4 id="遍历map或pair型list"><a href="#遍历map或pair型list" class="headerlink" title="遍历map或pair型list"></a>遍历map或pair型list</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ((k, v) <span class="keyword">in</span> map) &#123;</span><br><span class="line">    println(<span class="string">&quot;<span class="variable">$k</span> is <span class="variable">$v</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="区间迭代"><a href="#区间迭代" class="headerlink" title="区间迭代"></a>区间迭代</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1.</span><span class="number">.100</span>) &#123; ... &#125; <span class="comment">//闭区间 1到100 含100</span></span><br><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span> until <span class="number">100</span>) &#123; ... &#125; <span class="comment">//半开区间， 不包含100</span></span><br><span class="line"><span class="keyword">for</span> (x <span class="keyword">in</span> <span class="number">2.</span><span class="number">.10</span> step <span class="number">2</span>) &#123; ... &#125;</span><br><span class="line"><span class="keyword">for</span> (x <span class="keyword">in</span> <span class="number">10</span> downTo <span class="number">1</span>) &#123; ... &#125;</span><br><span class="line">(<span class="number">1.</span><span class="number">.10</span>).forEach &#123; ... &#125;</span><br></pre></td></tr></table></figure>



<h4 id="延迟属性"><a href="#延迟属性" class="headerlink" title="延迟属性"></a>延迟属性</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> p: String <span class="keyword">by</span> lazy &#123;</span><br><span class="line">    <span class="comment">// 计算该字符串</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="扩展函数"><a href="#扩展函数" class="headerlink" title="扩展函数"></a>扩展函数</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> String.<span class="title">spaceToCamelCase</span><span class="params">()</span></span> &#123; ... &#125;</span><br><span class="line"><span class="string">&quot;Convert this to camelcase&quot;</span>.spaceToCamelCase()</span><br></pre></td></tr></table></figure>



<h4 id="静态类"><a href="#静态类" class="headerlink" title="静态类"></a>静态类</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">object</span> Resource &#123;</span><br><span class="line">    <span class="keyword">val</span> name = <span class="string">&quot;Name&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="实例化一个抽象类"><a href="#实例化一个抽象类" class="headerlink" title="实例化一个抽象类"></a>实例化一个抽象类</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractClass</span> &#123;</span><br><span class="line">    <span class="keyword">abstract</span> <span class="function"><span class="keyword">fun</span> <span class="title">doSomething</span><span class="params">()</span></span></span><br><span class="line">    <span class="keyword">abstract</span> <span class="function"><span class="keyword">fun</span> <span class="title">sleep</span><span class="params">()</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> myObject = <span class="keyword">object</span>: AbstractClass() &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">doSomething</span><span class="params">()</span></span> &#123; ... &#125;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">fun</span> <span class="title">sleep</span><span class="params">()</span></span> &#123; ... &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    myObject.doSomething()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="if-not-null-缩写"><a href="#if-not-null-缩写" class="headerlink" title="if-not-null 缩写"></a>if-not-null 缩写</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> files = File(<span class="string">&quot;Test&quot;</span>).listFiles()</span><br><span class="line">println(files?.size) <span class="comment">//如果 files 不是 null，那么输出其大小</span></span><br></pre></td></tr></table></figure>



<h4 id="if-not-null-else-缩写"><a href="#if-not-null-else-缩写" class="headerlink" title="if-not-null-else 缩写"></a>if-not-null-else 缩写</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> files = File(<span class="string">&quot;Test&quot;</span>).listFiles()</span><br><span class="line">println(file?.size ?: <span class="string">&quot;empty&quot;</span>) <span class="comment">//如果 files 为 null，那么输出“empty”</span></span><br></pre></td></tr></table></figure>



<h4 id="if-null-执行一个语句"><a href="#if-null-执行一个语句" class="headerlink" title="if null 执行一个语句"></a>if null 执行一个语句</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> values = ...</span><br><span class="line"><span class="keyword">val</span> email = values[<span class="string">&quot;email&quot;</span>] ?: <span class="keyword">throw</span> IllegalStateException(<span class="string">&quot;Email is missing!&quot;</span>)</span><br></pre></td></tr></table></figure>



<h4 id="在可能会空的集合中取第一元素"><a href="#在可能会空的集合中取第一元素" class="headerlink" title="在可能会空的集合中取第一元素"></a>在可能会空的集合中取第一元素</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> emails = …… <span class="comment">// 可能会是空集合</span></span><br><span class="line"><span class="keyword">val</span> mainEmail = emails.firstOrNull() ?: <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>



<h4 id="if-not-null-执行语句"><a href="#if-not-null-执行语句" class="headerlink" title="if not null 执行语句"></a>if not null 执行语句</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> value = ...</span><br><span class="line">value?.let &#123;</span><br><span class="line">    ... <span class="comment">// 代码会执行到此处, 假如data不为null</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="映射可空值（如果非空的话）"><a href="#映射可空值（如果非空的话）" class="headerlink" title="映射可空值（如果非空的话）"></a>映射可空值（如果非空的话）</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> value = ...</span><br><span class="line"><span class="keyword">val</span> mapped = value?.let &#123; transformValue(it) &#125; ?: defaultValue</span><br><span class="line"><span class="comment">//如果该值或其转换结果为空，那么返回 defaultValue。</span></span><br></pre></td></tr></table></figure>



<h4 id="返回when表达式"><a href="#返回when表达式" class="headerlink" title="返回when表达式"></a>返回when表达式</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">transform</span><span class="params">(color: <span class="type">String</span>)</span></span>: <span class="built_in">Int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">when</span>(color) &#123;</span><br><span class="line">        <span class="string">&quot;red&quot;</span> -&gt; <span class="number">0</span></span><br><span class="line">        <span class="string">&quot;green&quot;</span> -&gt; <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span> -&gt; <span class="keyword">throw</span> IllegalArgumentException(<span class="string">&quot;Invalid color param value&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="try-catch-表达式"><a href="#try-catch-表达式" class="headerlink" title="try-catch 表达式"></a>try-catch 表达式</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">val</span> result = <span class="keyword">try</span> &#123;</span><br><span class="line">        count()</span><br><span class="line">    &#125; <span class="keyword">catch</span> (e: ArithmeticException) &#123;</span><br><span class="line">        <span class="keyword">throw</span> IllegalStateException(e)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//使用result</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="if-表达式"><a href="#if-表达式" class="headerlink" title="if 表达式"></a>if 表达式</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> y = <span class="keyword">if</span> (x == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="string">&quot;one&quot;</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (x == <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="string">&quot;two&quot;</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="string">&quot;other&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="返回类型为-Unit-的方法的构建器风格用法"><a href="#返回类型为-Unit-的方法的构建器风格用法" class="headerlink" title="返回类型为 Unit 的方法的构建器风格用法"></a>返回类型为 Unit 的方法的构建器风格用法</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">arrayOfMinusOnes</span><span class="params">(size: <span class="type">Int</span>)</span></span>: IntArray &#123;</span><br><span class="line">    <span class="keyword">return</span> IntArray(size).apply &#123; fill(-<span class="number">1</span>) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="但表达式函数"><a href="#但表达式函数" class="headerlink" title="但表达式函数"></a>但表达式函数</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">theAnswer</span><span class="params">()</span></span> = <span class="number">42</span></span><br><span class="line"><span class="comment">//等价于</span></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">theAnswer</span><span class="params">()</span></span>: <span class="built_in">Int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">42</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>单表达式函数与其它惯用法一起使用能简化代码，例如和 <code>when</code> 表达式一起使用：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">transform</span><span class="params">(color: <span class="type">String</span>)</span></span>: <span class="built_in">Int</span> = <span class="keyword">when</span> (color) &#123;</span><br><span class="line">    <span class="string">&quot;Red&quot;</span> -&gt; <span class="number">0</span></span><br><span class="line">    <span class="string">&quot;Green&quot;</span> -&gt; <span class="number">1</span></span><br><span class="line">    <span class="string">&quot;Blue&quot;</span> -&gt; <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span> -&gt; <span class="keyword">throw</span> IllegalArgumentException(<span class="string">&quot;Invalid color param value&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="对一个对象实例调用多个方法-（with）"><a href="#对一个对象实例调用多个方法-（with）" class="headerlink" title="对一个对象实例调用多个方法 （with）"></a>对一个对象实例调用多个方法 （with）</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Turtle</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">penDown</span><span class="params">()</span></span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">penUp</span><span class="params">()</span></span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">turn</span><span class="params">(degrees: <span class="type">Double</span>)</span></span></span><br><span class="line">    <span class="function"><span class="keyword">fun</span> <span class="title">forward</span><span class="params">(pixels: <span class="type">Double</span>)</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> myTurtle = Turtle()</span><br><span class="line">with(myTurtle) &#123; <span class="comment">// 画一个 100 像素的正方形</span></span><br><span class="line">    penDown()</span><br><span class="line">    <span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1.</span><span class="number">.4</span>) &#123;</span><br><span class="line">        forward(<span class="number">100.0</span>)</span><br><span class="line">        turn(<span class="number">90.0</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    penUp()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="配置对象的属性（apply）"><a href="#配置对象的属性（apply）" class="headerlink" title="配置对象的属性（apply）"></a>配置对象的属性（apply）</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> myRectangle = Rectangle().apply &#123;</span><br><span class="line">    length = <span class="number">4</span></span><br><span class="line">    breadth = <span class="number">5</span></span><br><span class="line">    color = <span class="number">0xFAFAFA</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这对于配置未出现在对象构造函数中的属性非常有用</p>
<h4 id="Java-7-的-try-with-resources"><a href="#Java-7-的-try-with-resources" class="headerlink" title="Java 7 的 try-with-resources"></a>Java 7 的 try-with-resources</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> stream = Files.newInputStream(Paths.<span class="keyword">get</span>(<span class="string">&quot;/some/file.txt&quot;</span>))</span><br><span class="line">stream.buffered().reader().use &#123; reader -&gt;</span><br><span class="line">    println(reader.readText())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="需要泛型信息的泛型函数"><a href="#需要泛型信息的泛型函数" class="headerlink" title="需要泛型信息的泛型函数"></a>需要泛型信息的泛型函数</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  public final class Gson &#123;</span></span><br><span class="line"><span class="comment">//     ……</span></span><br><span class="line"><span class="comment">//     public &lt;T&gt; T fromJson(JsonElement json, Class&lt;T&gt; classOfT) throws JsonSyntaxException &#123;</span></span><br><span class="line"><span class="comment">//     ……</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="function"><span class="keyword">fun</span> <span class="type">&lt;<span class="keyword">reified</span> T: Any&gt;</span> Gson.<span class="title">fromJson</span><span class="params">(json: <span class="type">JsonElement</span>)</span></span>: T = <span class="keyword">this</span>.fromJson(json, T::<span class="keyword">class</span>.java)</span><br></pre></td></tr></table></figure>



<h4 id="可空布尔"><a href="#可空布尔" class="headerlink" title="可空布尔"></a>可空布尔</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> b: <span class="built_in">Boolean</span>? = ……</span><br><span class="line"><span class="keyword">if</span> (b == <span class="literal">true</span>) &#123;</span><br><span class="line">    ……</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// `b` 是 false 或者 null</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="交换两个变量"><a href="#交换两个变量" class="headerlink" title="交换两个变量"></a>交换两个变量</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = <span class="number">1</span></span><br><span class="line"><span class="keyword">var</span> b = <span class="number">2</span></span><br><span class="line">a = b.also &#123; b = a &#125;</span><br></pre></td></tr></table></figure>



<h4 id="将代码标记为不完整（TODO）"><a href="#将代码标记为不完整（TODO）" class="headerlink" title="将代码标记为不完整（TODO）"></a>将代码标记为不完整（TODO）</h4><p>Kotlin 的标准库有一个 <code>TODO()</code> 函数，该函数总是抛出一个 <code>NotImplementedError</code>。 其返回类型为 <code>Nothing</code>，因此无论预期类型是什么都可以使用它。 还有一个接受原因参数的重载：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">calcTaxes</span><span class="params">()</span></span>: BigDecimal = TODO(<span class="string">&quot;Waiting for feedback from accounting&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>IntelliJ IDEA 的 kotlin 插件理解 <code>TODO()</code> 的语言，并且会自动在 TODO 工具窗口中添加代码指示。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/11/30/CentOS%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99-kernel-panic-not-syncing-VFS-Unable-to-mount-root-fs-on-unknown-block/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/30/CentOS%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99-kernel-panic-not-syncing-VFS-Unable-to-mount-root-fs-on-unknown-block/" class="post-title-link" itemprop="url">CentOS启动报错:kernel panic-not syncing:VFS:Unable to mount root fs on unknown block</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-11-30 15:28:20" itemprop="dateCreated datePublished" datetime="2021-11-30T15:28:20+08:00">2021-11-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-05 16:15:03" itemprop="dateModified" datetime="2023-02-05T16:15:03+08:00">2023-02-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>这是更新内核出现的问题。</p>
<p>解决方法，在开机启动时，选择下面的旧版本的内核启动，正常进入后，需要设置内核启动项来改变默认启动内核。</p>
<p>以下操作需要root权限。</p>
<p>1.查看当前默认内核启动项 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grub2-editenv list</span><br></pre></td></tr></table></figure>



<p>2.查看当前系统使用内核</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure>



<p>3.查看可以使用的内核项</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk -F\&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print i++ &quot; : &quot; $2&#125;&#x27; /etc/grub2.cfg</span><br></pre></td></tr></table></figure>



<p>4.更改默认启动内核项</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grub2-set-default 1</span><br></pre></td></tr></table></figure>



<p>5.重启系统</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">117</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
