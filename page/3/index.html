<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="拾荒者">
<meta property="og:url" content="http://fhclk.github.io/page/3/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="fhclk">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fhclk.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/" class="post-title-link" itemprop="url">Flink运行时架构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-08 20:03:21" itemprop="dateCreated datePublished" datetime="2022-04-08T20:03:21+08:00">2022-04-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Flink运行时组件"><a href="#Flink运行时组件" class="headerlink" title="Flink运行时组件"></a>Flink运行时组件</h1><h2 id="作业管理器（JobManager）"><a href="#作业管理器（JobManager）" class="headerlink" title="作业管理器（JobManager）"></a>作业管理器（JobManager）</h2><ul>
<li><p>控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager 所控制执行。</p>
</li>
<li><p>JobManager 会先接收到要执行的应用程序，这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。</p>
</li>
<li><p>JobManager 会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。</p>
</li>
<li><p>JobManager 会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</p>
</li>
</ul>
<h2 id="任务管理器（TaskManager）"><a href="#任务管理器（TaskManager）" class="headerlink" title="任务管理器（TaskManager）"></a>任务管理器（TaskManager）</h2><ul>
<li><p>Flink中的工作进程。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了TaskManager能够执行的任务数量。</p>
</li>
<li><p>启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。</p>
</li>
<li><p>在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。</p>
</li>
</ul>
<h2 id="资源管理器（ResourceManager）"><a href="#资源管理器（ResourceManager）" class="headerlink" title="资源管理器（ResourceManager）"></a>资源管理器（ResourceManager）</h2><ul>
<li><p>主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger 插槽是Flink中定义的处理资源单元。</p>
</li>
<li><p>Flink为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s，以及standalone部署。</p>
</li>
<li><p>当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。</p>
</li>
</ul>
<h2 id="分发器（Dispacher）"><a href="#分发器（Dispacher）" class="headerlink" title="分发器（Dispacher）"></a>分发器（Dispacher）</h2><ul>
<li><p>可以跨作业运行，它为应用提交提供了REST接口。</p>
</li>
<li><p>当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。</p>
</li>
<li><p>Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。</p>
</li>
<li><p>Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。</p>
</li>
</ul>
<h1 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h1><p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230108223719006.png" alt="image-20230108223719006"></p>
<h1 id="作业提交流程"><a href="#作业提交流程" class="headerlink" title="作业提交流程"></a>作业提交流程</h1><p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230115170314557.png" alt="image-20230115170314557"></p>
<h2 id="Standalone模式作业提交流程"><a href="#Standalone模式作业提交流程" class="headerlink" title="Standalone模式作业提交流程"></a>Standalone模式作业提交流程</h2><p>会话模式</p>
<p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230115210857012.png" alt="image-20230115210857012"></p>
<h2 id="YARN模式作业提交流程"><a href="#YARN模式作业提交流程" class="headerlink" title="YARN模式作业提交流程"></a>YARN模式作业提交流程</h2><p>会话模式</p>
<p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230115211021376.png" alt="image-20230115211021376"></p>
<p>单作业模式</p>
<p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230115211429146.png" alt="image-20230115211429146"></p>
<h1 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h1><h2 id="程序和数据流（DataFlow）"><a href="#程序和数据流（DataFlow）" class="headerlink" title="程序和数据流（DataFlow）"></a>程序和数据流（DataFlow）</h2><p>所有的Flink程序都是由三部分组成：Source、Transformation和Sink。</p>
<p>Source负责读取数据源，Transformation利用各种算子进行加工处理，Sink负责输出。</p>
<img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230115213603733.png" alt="image-20230115213603733" style="zoom:67%;">

<p>在运行时，Flink上运行的程序会被映射成“逻辑数据流”（dataflows），它包含了source、transformation、sink。</p>
<p>每一个dataflow以一个或多个sources开始以一个或多个sink结束。dataflow类似于任意的有向无环图（DAG）。</p>
<p>在大部分情况下，程序中转换运算（transformations）跟dataflow中的算子（operator）是一一对应的关系。</p>
<img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230115214233131.png" alt="image-20230115214233131" style="zoom:67%;">



<h2 id="并行度（Parallelism）"><a href="#并行度（Parallelism）" class="headerlink" title="并行度（Parallelism）"></a>并行度（Parallelism）</h2><p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116122736986.png" alt="image-20230116122736986"></p>
<p>每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中完全独立地执行。</p>
<p>一个特定算子地子任务（subtask）的个数被称之为其并行度（parallelism）。</p>
<p>代码中设置并行度有几种方式，一种是直接在算子上设置；一种是在StreamExecutionEnvironment上设置，这种设置是全局设置，但不推荐这种方法设置并行度。</p>
<h2 id="数据传输模式"><a href="#数据传输模式" class="headerlink" title="数据传输模式"></a>数据传输模式</h2><ul>
<li>一个程序中，不同的算子可能具有不同的并行度。</li>
<li>算子之间传输数据的形式可以是one-to-one（forwarding）的模式，也可以是redistributing的模式，具体是哪一种，取决于算子的种类。</li>
<li>One-to-one：stream维护着分区及元素的顺序（比如source和map之间）。这意味着map算子的子任务看到的元素的个数及顺序跟source算子的子任务生产的元素的个数、顺序相同。map、filter、flatMap等算子都是one-to-one的对应关系。</li>
<li>Redistributing：stream的分区会发生改变。每一个算子的子任务依据所选择的transformation发送数据到不同的目标任务。例如，keyBy基于hashCode重分区、而broadcast和rebalance会随机重新分区，这些算子都会引起redistribute过程，而redistribute过程就类似于Spark中的shuffle过程。</li>
</ul>
<h2 id="算子链（Operator-Chains）"><a href="#算子链（Operator-Chains）" class="headerlink" title="算子链（Operator Chains）"></a>算子链（Operator Chains）</h2><p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116164848641.png" alt="image-20230116164848641"></p>
<ul>
<li>Flink采用了一种称为任务链的优化技术，可以在特定条件下减少本地通信的开销。为了满足任务链的要求，必须将两个或多个算子设为相同的并行度，并通过本地转发（local forward）的方式进行连接。</li>
<li>相同并行度one-to-one操作，Flink这样相连的算子链接在一起形成一个task，原来的算子称为里面的subtask。</li>
<li>并行度相同，并且是one-to-one操作，两个条件缺一不可。</li>
</ul>
<h2 id="执行图"><a href="#执行图" class="headerlink" title="执行图"></a>执行图</h2><ul>
<li>Flink中的执行图可以分成四层：StreamGraph -&gt; JobGrapth -&gt; ExecutionGraph -&gt; 物理执行图</li>
<li>StreamGraph：是根据用户通过Stream API编写的代码生成的最初的图。用来表示程序的拓扑结构。</li>
<li>JobGraph：StreamGraph经过优化后生成了JobGraph，提交给JobManager的数据结构。主要的优化为，将多个符合条件的节点chain在一起作为一个节点。</li>
<li>ExecutionGraph：JobManager根据JobGraph生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。</li>
<li>物理执行图：JobManager根据ExecutionGraph对Job进行调度后，在各个TaskManager上部署Task后形成的“图”，并不是一个具体的数据结构。</li>
</ul>
<p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116171054322.png" alt="image-20230116171054322"></p>
<p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116170759873.png" alt="image-20230116170759873"></p>
<p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116170914958.png" alt="image-20230116170914958"></p>
<h2 id="任务（Task）和任务槽（Task-Slots）"><a href="#任务（Task）和任务槽（Task-Slots）" class="headerlink" title="任务（Task）和任务槽（Task Slots）"></a>任务（Task）和任务槽（Task Slots）</h2><p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116194255123.png" alt="image-20230116194255123"></p>
<p>Flink中每一个TaskManager都是一个JVM进程，它可能会在独立的线程上执行一个或多个子任务。</p>
<p>为了控制一个TaskManager能接收多少个task，TaskManager通过task slot来进行控制（一个TaskManager至少有一个slot）</p>
<h2 id="任务共享Slot"><a href="#任务共享Slot" class="headerlink" title="任务共享Slot"></a>任务共享Slot</h2><p><img src="/2022/04/08/Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E6%9E%B6%E6%9E%84/image-20230116195243234.png" alt="image-20230116195243234"></p>
<p>默认情况下，Flink运行子任务共享slot。这样的结果是，一个slot可以保存作业的整个管道。</p>
<p>当我们将资源密集型和非密集型的任务放到一个slot中，它们就可以自行分配资源占用的比例，从而保证最重的活平均分配给所有的TaskManager。</p>
<h2 id="Slot和并行度"><a href="#Slot和并行度" class="headerlink" title="Slot和并行度"></a>Slot和并行度</h2><p><strong>Task Slot</strong></p>
<ul>
<li>静态概念，是指TaskManager具有的并发执行能力</li>
<li>通过参数taskmanager.numberOfTaskSlots进行配置</li>
</ul>
<p><strong>并行度（parallelism）</strong></p>
<ul>
<li>动态概念，也就是TaskManager运行程序时实际使用的并发能力</li>
<li>通过参数parallelism.default进行配置</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/04/05/Flink%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">Flink部署</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-05 20:11:23" itemprop="dateCreated datePublished" datetime="2022-04-05T20:11:23+08:00">2022-04-05</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h1><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>地址：<a target="_blank" rel="noopener" href="https://archive.apache.org/dist/flink/flink-1.14.4/">https://archive.apache.org/dist/flink/flink-1.14.4/</a></p>
<p>上传至服务器并解压</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 software]# tar -zxvf flink-1.14.4-bin-scala_2.12.tgz </span><br><span class="line">(base) [root@node1 software]# mv flink-1.14.4 ../server/</span><br></pre></td></tr></table></figure>

<h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/start-cluster.sh </span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host node1.st.cn.</span><br><span class="line">Starting taskexecutor daemon on host node1.st.cn.</span><br></pre></td></tr></table></figure>



<h2 id="提交作业（Job）"><a href="#提交作业（Job）" class="headerlink" title="提交作业（Job）"></a>提交作业（Job）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/flink run examples/streaming/WordCount.jar </span><br><span class="line">Executing WordCount example with default input data set.</span><br><span class="line">Use --input to specify file input.</span><br><span class="line">Printing result to stdout. Use --output to specify output path.</span><br><span class="line">Job has been submitted with JobID a07000e74ea02367d29e972662fd9914</span><br><span class="line">Program execution finished</span><br><span class="line">Job with JobID a07000e74ea02367d29e972662fd9914 has finished.</span><br><span class="line">Job Runtime: 1390 ms</span><br><span class="line"></span><br><span class="line">(base) [root@node1 flink-1.14.4]# tail log/flink-*-taskexecutor-*.out</span><br><span class="line">(nymph,1)</span><br><span class="line">(in,3)</span><br><span class="line">(thy,1)</span><br><span class="line">(orisons,1)</span><br><span class="line">(be,4)</span><br><span class="line">(all,2)</span><br><span class="line">(my,1)</span><br><span class="line">(sins,1)</span><br><span class="line">(remember,1)</span><br><span class="line">(d,4)</span><br></pre></td></tr></table></figure>



<h2 id="停止集群"><a href="#停止集群" class="headerlink" title="停止集群"></a>停止集群</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/stop-cluster.sh </span><br></pre></td></tr></table></figure>



<h1 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h1><h2 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h2><p>node1节点 -  JobManager</p>
<p>node2节点  -  TaskManager</p>
<p>node3节点  -  TaskManager</p>
<h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><ol>
<li><p>修改conf下的flink-conf.yaml文件。修改jobmanager.rpc.address为node1</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">node1</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>修改workers文件，添加node2和node3节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim conf/workers</span><br><span class="line">node2</span><br><span class="line">node3</span><br></pre></td></tr></table></figure>


</li>
<li><p>将flink拷贝到node2和node3节点上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 server]# scp -r flink-1.14.4 root@node2:/export/server/</span><br><span class="line">(base) [root@node1 server]# scp -r flink-1.14.4 root@node3:/export/server/</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/start-cluster.sh</span><br><span class="line">(base) [root@node1 flink-1.14.4]# jps</span><br><span class="line">4080 StandaloneSessionClusterEntrypoint</span><br><span class="line">4165 Jps</span><br></pre></td></tr></table></figure>

<p>分别在node2和node3上使用jps查看进程。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node2 ~]# jps</span><br><span class="line">2441 Jps</span><br><span class="line">2317 TaskManagerRunner</span><br></pre></td></tr></table></figure>
</li>
<li><p>web查看 <a target="_blank" rel="noopener" href="http://node1:8081/">http://node1:8081/</a></p>
<p><img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230109222916850.png" alt="image-20230109222916850"></p>
</li>
<li><p>关闭集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/stop-cluster.sh </span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="提交Job"><a href="#提交Job" class="headerlink" title="提交Job"></a>提交Job</h2><h3 id="Flink-web上提交"><a href="#Flink-web上提交" class="headerlink" title="Flink web上提交"></a>Flink web上提交</h3><h3 id="命令行提交"><a href="#命令行提交" class="headerlink" title="命令行提交"></a>命令行提交</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/flink run -m node1:8081 -c com.st.wc.StreamWordCount -p 2 ~/data/FlinkStudy-1.0-SNAPSHOT.jar</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">打印出jobId</span></span><br></pre></td></tr></table></figure>



<h3 id="命令行取消"><a href="#命令行取消" class="headerlink" title="命令行取消"></a>命令行取消</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/flink cancel jobId</span><br></pre></td></tr></table></figure>



<h1 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h1><h2 id="会话模式（Session-Mode）"><a href="#会话模式（Session-Mode）" class="headerlink" title="会话模式（Session Mode）"></a>会话模式（Session Mode）</h2><p>会话模式最符合常规思维。需要先启动一个集群，保持一个会话，在这个会话中通过客户端提交作业。集群启动时所有资源已经确定，所以所有提交的作业会竞争集群中的资源。</p>
<p>会话模式适合单个规模小、执行时间短的大量作业。</p>
<h2 id="单作业模式（Per-Job-Mode）"><a href="#单作业模式（Per-Job-Mode）" class="headerlink" title="单作业模式（Per-Job Mode）"></a>单作业模式（Per-Job Mode）</h2><p>会话模式因为资源共享会导致很多问题，所以为了更好的隔离资源，可以考虑为每个提交的作业启动一个集群，这就是所谓的单作业模式。</p>
<p>一个集群对应一个作业。由客户端运行应用程序，然后启动集群，作业被提交各JobManager，进而分发给TaskManager执行。作业完成后，集群就会关闭，释放资源。</p>
<p>这些特性使得单作业模式在生产环境中更加稳定，所以是实际应用的首选模式。</p>
<p>Flink本身无法直接这样运行，一般需要借助资源管理框架来启动集群，如YARN、Kubernetes。</p>
<h2 id="应用模式（Application-Mode）"><a href="#应用模式（Application-Mode）" class="headerlink" title="应用模式（Application Mode）"></a>应用模式（Application Mode）</h2><p>会话模式和单作业模式中，应用代码都是在客户端上执行，然后由客户端提交给JobManager的。但是这种方式客户端需要占用大量网络带宽，去下载依赖和把二进制数据发送给JobManager。</p>
<p>解决方法是，不用客户端，直接把应用提交到JobManager上运行。而这意味着需要为每一个提交的应用单独启动一个JobManager，即创建一个集群。这个JobManager只为执行这一个应用存在，执行结束后JobManager就关闭了，这就是所谓的应用模式。</p>
<p>应用模式下，直接由JobManager执行应用程序，即使这个应用包含了多个作业，也只创建一个一个集群。</p>
<h1 id="独立模式（Standalone）"><a href="#独立模式（Standalone）" class="headerlink" title="独立模式（Standalone）"></a>独立模式（Standalone）</h1><p>独立运行，不依赖任何资源管理平台。</p>
<h1 id="YARN模式"><a href="#YARN模式" class="headerlink" title="YARN模式"></a>YARN模式</h1><p>Flink1.8之前需要与Hadoop的版本匹配，具体内容参考Flink官网。</p>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="配置HADOOP-CLASSPATH环境变量"><a href="#配置HADOOP-CLASSPATH环境变量" class="headerlink" title="配置HADOOP_CLASSPATH环境变量"></a>配置HADOOP_CLASSPATH环境变量</h3><p>编辑&#x2F;etc&#x2F;profile文件，添加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure>

<p>刷新环境变量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h3 id="修改yarn-site-xml"><a href="#修改yarn-site-xml" class="headerlink" title="修改yarn-site.xml"></a>修改yarn-site.xml</h3><p>修改&#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 关闭yarn内存检查 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认为 true --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 因为对于 flink 使用 yarn 模式下，很容易内存超标，这个时候 yarn 会自动杀掉 job，因此需要关掉--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h2 id="启用集群"><a href="#启用集群" class="headerlink" title="启用集群"></a>启用集群</h2><p>Flink提供了两种在YARN上运行的模式，分别为Session-Cluster和Per-Job-Cluster模式。</p>
<h3 id="Session-Cluster模式"><a href="#Session-Cluster模式" class="headerlink" title="Session-Cluster模式"></a>Session-Cluster模式</h3><p>Session-Cluster 模式需要先启动集群，然后再提交作业，接着会向 yarn 申请一块空间后，资源永远保持不变。如果资源满了，下一个作业就无法提交，只能等到yarn 中的其中一个作业执行完成后，释放了资源，下个作业才会正常提交。所有作业共享 Dispatcher 和 ResourceManager；共享资源；适合规模小执行时间短的作业。</p>
<p>在 yarn 中初始化一个 flink 集群，开辟指定的资源，以后提交任务都向这里提交。这个 flink 集群会常驻在 yarn 集群中，除非手工停止。</p>
<p><img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230112210400794.png" alt="image-20230112210400794"></p>
<h4 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h4><ol>
<li><p>启动Hadoop集群</p>
<p><code>start-all.sh</code></p>
</li>
<li><p>启动yarn-session</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/yarn-session.sh -n 2 -s 2 -jm 1024 -nm test -d</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<p>-n(–container)：TaskManager 的数量。</p>
<p>-s(–slots)： 每个 TaskManager 的 slot 数量，默认一个 slot 一个 core，默认每个</p>
<p>taskmanager 的 slot 的个数为 1，有时可以多一些 taskmanager，做冗余。</p>
<p>-jm：JobManager 的内存（单位 MB)。</p>
<p>-tm：每个 taskmanager 的内存（单位 MB)。</p>
<p>-nm：yarn 的 appName(现在 yarn 的 ui 上的名字)。</p>
<p>-d：后台执行。</p>
<p><img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230112213516777.png" alt="image-20230112213516777"></p>
</li>
<li><p>执行任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/flink run -c com.st.wc.StreamWordCount ~/data/flinkStudy-1.0-SNAPSHOT.jar  --host localhost -port 7777</span><br></pre></td></tr></table></figure>


</li>
<li><p>到yarn控制台查看任务状态</p>
<p><img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230112213240807.png" alt="image-20230112213240807"></p>
</li>
<li><p>取消yarn-session</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# yarn application --kill application_1673529466861_0001</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Per-Job-Cluster"><a href="#Per-Job-Cluster" class="headerlink" title="Per Job Cluster"></a>Per Job Cluster</h3><p>一个 Job 会对应一个集群，每提交一个作业会根据自身的情况，都会单独向 yarn申请资源，直到作业执行完成，一个作业的失败与否并不会影响下一个作业的正常提交和运行。独享 Dispatcher 和 ResourceManager，按需接受资源申请；适合规模大长时间运行的作业。</p>
<p>每次提交都会创建一个新的 flink 集群，任务之间互相独立，互不影响，方便管理。任务执行完成之后创建的集群也会消失。</p>
<p><img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230112213800713.png" alt="image-20230112213800713"></p>
<h4 id="启用-1"><a href="#启用-1" class="headerlink" title="启用"></a>启用</h4><ol>
<li><p>启动Hadoop集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>


</li>
<li><p>不启动yarn-session，直接运行job</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/flink run -d -t yarn-per-job -c com.st.wc.StreamWordCount ~/data/flinkStudy-1.0-SNAPSHOT.jar --host localhost -port 7777</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">早期另一种写法</span></span><br><span class="line">(base) [root@node1 flink-1.14.4]# ./bin/flink run -m yarn-cluster -c com.st.wc.StreamWordCount ~/data/flinkStudy-1.0-SNAPSHOT.jar --host localhost -port 7777</span><br></pre></td></tr></table></figure></li>
</ol>
<p>​		<img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230112214233687.png" alt="image-20230112214233687"></p>
<ol start="3">
<li>到yarn控制台查看任务状态</li>
</ol>
<p><img src="/2022/04/05/Flink%E9%83%A8%E7%BD%B2/image-20230112214257160.png" alt="image-20230112214257160"></p>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><p>idea maven打包， 插件maven-assembly-plugin</p>
<p>在pom.xml添加插件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">           <span class="comment">&lt;!-- 该插件用于将Scala代码编译成class文件 --&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.alchim31.maven<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                       <span class="comment">&lt;!-- 声明绑定到maven的compile阶段 --&gt;</span></span><br><span class="line">                       <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                           <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                       <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                       <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                       <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                       <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                       <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                           <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                       <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                   <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">               <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/04/04/Flink%E4%B8%8A%E6%89%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/04/Flink%E4%B8%8A%E6%89%8B/" class="post-title-link" itemprop="url">Flink上手</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-04 20:02:34" itemprop="dateCreated datePublished" datetime="2022-04-04T20:02:34+08:00">2022-04-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>idea创建maven项目FlinkStudy</p>
<p>pom.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.st<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flinkStudy<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">flink.versin</span>&gt;</span>1.13.0<span class="tag">&lt;/<span class="name">flink.versin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.binary.version</span>&gt;</span>2.12<span class="tag">&lt;/<span class="name">scala.binary.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">slf4j.version</span>&gt;</span>1.7.30<span class="tag">&lt;/<span class="name">slf4j.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.versin&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.versin&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.versin&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;slf4j.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;slf4j.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-to-slf4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.14.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>在目录<code>src/main/resources</code>下添加文件：log4j.properties</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">error, stdout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%-4r [%t] %-5p %c %x - %m%n</span></span><br></pre></td></tr></table></figure>



<h1 id="批处理示例"><a href="#批处理示例" class="headerlink" title="批处理示例"></a>批处理示例</h1><p>准备数据</p>
<p>在项目根目录下创建文件夹input，创建文件words.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hello world</span><br><span class="line">hello hadoop</span><br><span class="line">hello flink</span><br><span class="line">hello java</span><br></pre></td></tr></table></figure>



<p>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.st.wc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.Types;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.ExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.AggregateOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.FlatMapOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.UnsortedGrouping;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BatchWordCount</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1. 创建执行环境</span></span><br><span class="line">        <span class="type">ExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 从文件中读取数据</span></span><br><span class="line">        DataSource&lt;String&gt; lineDataSource = env.readTextFile(<span class="string">&quot;input/words.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 对每行数据进行分组，转换成二元组</span></span><br><span class="line">        FlatMapOperator&lt;String, Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = lineDataSource.flatMap((String line, Collector&lt; Tuple2&lt;String, Long&gt; &gt; out) -&gt; &#123;</span><br><span class="line">            <span class="comment">// 将一行文本进行分词</span></span><br><span class="line">            String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="comment">// 将每个单词转换成二元组</span></span><br><span class="line">            <span class="keyword">for</span> (String word: words) &#123;</span><br><span class="line">                out.collect(Tuple2.of(word, <span class="number">1L</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).returns(Types.TUPLE(Types.STRING, Types.LONG));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 按照word进行分组</span></span><br><span class="line">        UnsortedGrouping&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneGroup = wordAndOneTuple.groupBy(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 分组内进行聚合统计</span></span><br><span class="line">        AggregateOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneGroup.sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6. 打印结果</span></span><br><span class="line">        sum.print();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(hadoop,1)</span><br><span class="line">(flink,1)</span><br><span class="line">(world,1)</span><br><span class="line">(hello,4)</span><br><span class="line">(java,1)</span><br></pre></td></tr></table></figure>



<p>从Flink1.12开始，官方不再推荐使用DataSet API的方式，更推荐使用批流一体DataStream API方式。</p>
<h1 id="流处理示例"><a href="#流处理示例" class="headerlink" title="流处理示例"></a>流处理示例</h1><p>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.st.wc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.Types;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BoundedStreamWordCount</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1. 创建流式执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 读取文件</span></span><br><span class="line">        DataStreamSource&lt;String&gt; lineDataStreamSource = env.readTextFile(<span class="string">&quot;input/words.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 转换计算</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = lineDataStreamSource.flatMap((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; &#123;</span><br><span class="line">            String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                out.collect(Tuple2.of(word, <span class="number">1l</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).returns(Types.TUPLE(Types.STRING, Types.LONG));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 分组</span></span><br><span class="line">        KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKeyedStream = wordAndOneTuple.keyBy(data -&gt; data.f0);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 求和</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneKeyedStream.sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6. 打印</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7. 启动执行难</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">3&gt; (java,1)</span><br><span class="line">13&gt; (flink,1)</span><br><span class="line">9&gt; (world,1)</span><br><span class="line">5&gt; (hello,1)</span><br><span class="line">5&gt; (hello,2)</span><br><span class="line">5&gt; (hello,3)</span><br><span class="line">5&gt; (hello,4)</span><br><span class="line">15&gt; (hadoop,1)</span><br></pre></td></tr></table></figure>

<h1 id="模拟数据流示例"><a href="#模拟数据流示例" class="headerlink" title="模拟数据流示例"></a>模拟数据流示例</h1><p>在服务器上按照NetCat工具</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# yum install -y nc</span><br></pre></td></tr></table></figure>

<p>启用NetCat</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# nc -lk 7777</span><br></pre></td></tr></table></figure>

<p>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.st.wc;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.Types;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StreamWordCount</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 1. 创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 读取文本流</span></span><br><span class="line">        DataStreamSource&lt;String&gt; lineDataStream = env.socketTextStream(<span class="string">&quot;node1&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 转换计算</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = lineDataStream.flatMap((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; &#123;</span><br><span class="line">            String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                out.collect(Tuple2.of(word, <span class="number">1l</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).returns(Types.TUPLE(Types.STRING, Types.LONG));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 分组</span></span><br><span class="line">        KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKeyedStream = wordAndOneTuple.keyBy(data -&gt; data.f0);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 求和</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneKeyedStream.sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6. 打印</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7. 启动执行难</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在linux上输入数据流，观察idea日志输出</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# nc -lk 7777</span><br><span class="line">hello world</span><br><span class="line">hello hadoop</span><br><span class="line">hello Spark</span><br><span class="line">Hello Flink</span><br></pre></td></tr></table></figure>

<p>idea输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&quot;C:\Program Files\Java\jdk1.8.0_152\bin\java.exe&quot; &quot;-javaagent:E:\Program Files\IntelliJ IDEA ...</span><br><span class="line">...</span><br><span class="line">com.st.wc.StreamWordCount</span><br><span class="line">9&gt; (world,1)</span><br><span class="line">5&gt; (hello,1)</span><br><span class="line">15&gt; (hadoop,1)</span><br><span class="line">5&gt; (hello,2)</span><br><span class="line">16&gt; (Spark,1)</span><br><span class="line">5&gt; (hello,3)</span><br><span class="line">2&gt; (Hello,1)</span><br><span class="line">16&gt; (Flink,1)</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/04/01/Flink%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">Flink基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-01 16:32:57" itemprop="dateCreated datePublished" datetime="2022-04-01T16:32:57+08:00">2022-04-01</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。Flink 被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。</p>
<h2 id="Flink框架处理流程"><a href="#Flink框架处理流程" class="headerlink" title="Flink框架处理流程"></a>Flink框架处理流程</h2><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105113544522.png" alt="image-20230105113544522" style="zoom:80%;">

<h2 id="Flink的应用场景"><a href="#Flink的应用场景" class="headerlink" title="Flink的应用场景"></a>Flink的应用场景</h2><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105114103338.png" alt="image-20230105114103338" style="zoom:80%;">



<h2 id="Flink的优势"><a href="#Flink的优势" class="headerlink" title="Flink的优势"></a>Flink的优势</h2><ul>
<li>低延迟</li>
<li>高吞吐</li>
<li>结果的准确性和良好的容错性</li>
</ul>
<h2 id="数据处理框架的演变"><a href="#数据处理框架的演变" class="headerlink" title="数据处理框架的演变"></a>数据处理框架的演变</h2><h3 id="传统数据处理框架"><a href="#传统数据处理框架" class="headerlink" title="传统数据处理框架"></a>传统数据处理框架</h3><h4 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a>事务处理</h4><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105115937806.png" alt="image-20230105115937806" style="zoom: 80%;">

<h4 id="分析处理"><a href="#分析处理" class="headerlink" title="分析处理"></a>分析处理</h4><p>将数据从业务数据库复制到数仓，再进行分析和查询。</p>
<img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105130252994.png" alt="image-20230105130252994" style="zoom:80%;">



<h3 id="有状态的流式处理"><a href="#有状态的流式处理" class="headerlink" title="有状态的流式处理"></a>有状态的流式处理</h3><p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105130357991.png" alt="image-20230105130357991"></p>
<p>将业务数据通过管道的方式传输到应用逻辑处理程序中，应用逻辑存储到内存中（本地状态），定时的将处理完的数据存储到持久化存储中。</p>
<p>存在的问题，在集群中，各个节点进行应用逻辑处理时都存储在各自的内存中，处理完成后再进行集合，容易出现乱序的问题，因为各节点处理速度是不确定的。</p>
<h3 id="lambda架构"><a href="#lambda架构" class="headerlink" title="lambda架构"></a>lambda架构</h3><p>用两套系统，同时保证低延迟和结果准确。</p>
<p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105131612625.png" alt="image-20230105131612625"></p>
<p>批处理，处理速度慢，但能够保证数据的准确。实时层，处理速度快，不能保证数据的准确。最后进行数据合并，保证最终数据的准确。</p>
<p>缺点：需要同时维护两套系统，开发维护难度大。</p>
<h3 id="新一代流处理器-Flink"><a href="#新一代流处理器-Flink" class="headerlink" title="新一代流处理器 - Flink"></a>新一代流处理器 - Flink</h3><p>核心特点</p>
<ul>
<li>高吞吐、低延迟</li>
<li>结果的准确性</li>
<li>精确一次（exactly - once）的状态一致性保证</li>
<li>可以与众多常用存储系统连接</li>
<li>高可用，支持动态扩展</li>
</ul>
<h2 id="流处理的应用场景"><a href="#流处理的应用场景" class="headerlink" title="流处理的应用场景"></a>流处理的应用场景</h2><h3 id="事件驱动型"><a href="#事件驱动型" class="headerlink" title="事件驱动型"></a>事件驱动型</h3><p>事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。比较典型的就是以 kafka 为代表的消息队列几乎都是事件驱动型应用。</p>
<p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105132421767.png" alt="image-20230105132421767"></p>
<h3 id="数据分析型"><a href="#数据分析型" class="headerlink" title="数据分析型"></a>数据分析型</h3><h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h4><p>批处理的特点是有界、持久、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。</p>
<h4 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h4><p>流处理的特点是无界、实时, 无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。</p>
<p>在 spark 的世界观中，一切都是由批次组成的，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。</p>
<p>而在 flink 的世界观中，一切都是由流组成的，离线数据是有界限的流，实时数据是一个没有界限的流，这就是所谓的有界流和无界流。</p>
<h4 id="无界数据流"><a href="#无界数据流" class="headerlink" title="无界数据流"></a>无界数据流</h4><p>无界数据流有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理 event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）获取 event，以便能够推断结果完整性。</p>
<h4 id="有界数据流"><a href="#有界数据流" class="headerlink" title="有界数据流"></a>有界数据流</h4><p>有界数据流有明确定义的开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。</p>
<p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105132445886.png" alt="image-20230105132445886"></p>
<h3 id="数据管道型"><a href="#数据管道型" class="headerlink" title="数据管道型"></a>数据管道型</h3><p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105150744099.png" alt="image-20230105150744099"></p>
<h3 id="Flink分层API"><a href="#Flink分层API" class="headerlink" title="Flink分层API"></a>Flink分层API</h3><ul>
<li>越顶层越抽象，表达含义越简明，使用越方便</li>
<li>越底层越具体，表达能力越丰富，使用越灵活</li>
</ul>
<img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105151207986.png" alt="image-20230105151207986" style="zoom:80%;">

<p>最底层级的抽象仅仅提供了有状态流，它将通过过程函数（Process Function）被嵌入到 DataStream API 中。底层过程函数（Process Function） 与 DataStream API相集成，使其可以对某些特定的操作进行底层的抽象，它允许用户可以自由地处理来自一个或多个数据流的事件，并使用一致的容错的状态。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以处理复杂的计算。</p>
<p>实际上，大多数应用并不需要上述的底层抽象，而是针对核心 API（Core APIs）进行编程，比如 DataStream API（有界或无界流数据）以及 DataSet API（有界数据集）。这些 API 为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换（transformations），连接（joins），聚合（aggregations），窗口操作（windows）等等。DataSet API 为有界数据集提供了额外的支持，例如循环与迭代。这些 API处理的数据类型以类（classes）的形式由各自的编程语言所表示。</p>
<p>Table API 是以表为中心的声明式编程，其中表可能会动态变化（在表达流数据时）。Table API 遵循（扩展的）关系模型：表有二维数据结构（schema）（类似于关系数据库中的表），同时 API 提供可比较的操作，例如 select、project、join、group-by、aggregate 等。Table API 程序声明式地定义了什么逻辑操作应该执行，而不是准确地确定这些操作代码的看上去如何。</p>
<p>尽管 Table API 可以通过多种类型的用户自定义函数（UDF）进行扩展，其仍不如核心 API 更具表达能力，但是使用起来却更加简洁（代码量更少）。除此之外，Table API 程序在执行之前会经过内置优化器进行优化。</p>
<p>你可以在表与 DataStream&#x2F;DataSet 之间无缝切换，以允许程序将 Table API 与DataStream 以及 DataSet 混合使用。</p>
<p>Flink 提 供 的 最高 层 级 的 抽 象 是 SQL 。 这 一 层抽 象 在 语 法 与 表 达能 力 上 与Table API 类似，但是是以 SQL 查询表达式的形式表现程序。SQL 抽象与 Table API交互密切，同时 SQL 查询可以直接在 Table API 定义的表上执行。</p>
<p>目前 Flink 作为批处理还不是主流，不如 Spark 成熟，所以 DataSet 使用的并不是很多。Flink Table API 和 Flink SQL 也并不完善，大多都由各大厂商自己定制。所以我们主要学习 DataStream API 的使用。实际上 Flink 作为最接近 Google DataFlow模型的实现，是流批统一的观点，所以基本上使用 DataStream 就可以了。</p>
<h3 id="Flink和Spark的区别"><a href="#Flink和Spark的区别" class="headerlink" title="Flink和Spark的区别"></a>Flink和Spark的区别</h3><h4 id="数据处理架构"><a href="#数据处理架构" class="headerlink" title="数据处理架构"></a>数据处理架构</h4><h5 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h5><p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105152919040.png" alt="image-20230105152919040"></p>
<p>原则上是批处理，只是拆分成很小的批次。</p>
<h5 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h5><p><img src="/2022/04/01/Flink%E5%9F%BA%E7%A1%80/image-20230105153036876.png" alt="image-20230105153036876"></p>
<h4 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h4><h5 id="Spark-1"><a href="#Spark-1" class="headerlink" title="Spark"></a>Spark</h5><p>Spark采用RDD模型，Spark streaming的DStream实际上就是一组小批数据RDD的集合</p>
<h5 id="Flink-1"><a href="#Flink-1" class="headerlink" title="Flink"></a>Flink</h5><p>Flink基本数据模型是数据流，以及事件（Event）序列</p>
<h4 id="运行时架构"><a href="#运行时架构" class="headerlink" title="运行时架构"></a>运行时架构</h4><h5 id="Spark-2"><a href="#Spark-2" class="headerlink" title="Spark"></a>Spark</h5><p>Spark是批计算，将DAG划分为不同的stage，一个完成后才可以计算下一个。</p>
<h5 id="Flink-2"><a href="#Flink-2" class="headerlink" title="Flink"></a>Flink</h5><p>Flink是标准的流式执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/03/24/SOA%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/24/SOA%E6%9E%B6%E6%9E%84%E6%80%9D%E6%83%B3/" class="post-title-link" itemprop="url">SOA架构思想</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-24 23:24:42" itemprop="dateCreated datePublished" datetime="2022-03-24T23:24:42+08:00">2022-03-24</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>SOA（service oriented architecture）面向服务的架构</p>
<p>SOA是伴随着单体式的建设系统的方式产生的。在微服务之前都是单体应用，它们是竖井式的一个一个的竖井垂直建立起来的，业务系统越建越多，业务系统之间的集成和协同问题就越发昆明，在这个原因下，出现了SOA的架构思想。</p>
<h1 id="架构思想"><a href="#架构思想" class="headerlink" title="架构思想"></a>架构思想</h1><p>对于SOA有一个标准的定义，SOA架构思想是要去找到当前系统中可以复用的服务能力，这个服务能力本身也具备粗粒度、无状态一些关键的服务特征，在找到了这些可复用的能力以后，我们可以基于这些接口服务来灵活的组装和编排上层的业务应用和业务流程，这个就是SOA最核心的架构思想。</p>
<p>简单理解：</p>
<ol>
<li>要找到可重用的服务。</li>
<li>灵活的组合和编排服务来满足业务流程。</li>
</ol>
<p>在找到可重用的服务后，需要对这些服务进行统一的管控治理，而着一些能力往往就是涉及到我们常说的ESB的企业服务总线，在往上面走，这些服务要去组合和编排，去满足业务流程，这个往往会涉及到BPM业务流程管理和BPEL流程编排着一些关键内容。所以会看到SOA的架构思想往往跟实现的一些技术和产品有一个对应。</p>
<p>举例：</p>
<p>一个公司要去拓展自媒体业务，新建一个自媒体团队，进行分析，发现自媒体业务流程，包括前期文案的编写，视频录制，美工裁剪，最后的运营和宣传。把自媒体业务分解后，可以将原有的团队人员来做具体的工作，如产品做前期文案编写，ui做视频裁剪，市场做营运和宣传，在原有的产品和技术团队找到对应的人做不同的事，这样就最大化的复用了企业已有的资源和能力，而不是将所有的东西都从头重新去完完全全独立的去建设一套，这个就是SOA架构思想。</p>
<p>SOA架构思想并不过时，SOA里面强调的可复用、解耦、灵活的组装编排，在很多场景都会出现和应用到。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/03/22/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/22/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">Kafka源码解析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-22 21:03:38" itemprop="dateCreated datePublished" datetime="2022-03-22T21:03:38+08:00">2022-03-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h1 id="生产者源码"><a href="#生产者源码" class="headerlink" title="生产者源码"></a>生产者源码</h1><h1 id="消费者源码"><a href="#消费者源码" class="headerlink" title="消费者源码"></a>消费者源码</h1><h1 id="服务器源码"><a href="#服务器源码" class="headerlink" title="服务器源码"></a>服务器源码</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/03/20/Kafka%E7%94%9F%E4%BA%A7%E8%B0%83%E4%BC%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/20/Kafka%E7%94%9F%E4%BA%A7%E8%B0%83%E4%BC%98/" class="post-title-link" itemprop="url">Kafka生产调优</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-20 20:32:22" itemprop="dateCreated datePublished" datetime="2022-03-20T20:32:22+08:00">2022-03-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="硬件配置选择"><a href="#硬件配置选择" class="headerlink" title="硬件配置选择"></a>硬件配置选择</h1><h1 id="Kafka生产者"><a href="#Kafka生产者" class="headerlink" title="Kafka生产者"></a>Kafka生产者</h1><h1 id="Kafka-Broker"><a href="#Kafka-Broker" class="headerlink" title="Kafka Broker"></a>Kafka Broker</h1><h1 id="Kafka消费者"><a href="#Kafka消费者" class="headerlink" title="Kafka消费者"></a>Kafka消费者</h1><h1 id="总体"><a href="#总体" class="headerlink" title="总体"></a>总体</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/" class="post-title-link" itemprop="url">Kafka外部系统集成</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-18 21:02:14" itemprop="dateCreated datePublished" datetime="2022-03-18T21:02:14+08:00">2022-03-18</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="集成Flume"><a href="#集成Flume" class="headerlink" title="集成Flume"></a>集成Flume</h1><p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230202132247145.png" alt="image-20230202132247145"></p>
<h2 id="Flume生产者"><a href="#Flume生产者" class="headerlink" title="Flume生产者"></a>Flume生产者</h2><p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230202132414125.png" alt="image-20230202132414125"></p>
<ol>
<li><p>启动kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# ./bin/zk.sh start</span><br><span class="line">(base) [root@node1 ~]# ./bin/kf.sh start</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动kafka消费者</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka]# ./bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic first</span><br></pre></td></tr></table></figure>


</li>
<li><p>配置flume</p>
<p>文件名file_to_kafka.conf</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 组件定义</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 2 配置 source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">f1</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = <span class="string">/root/data/applog/app.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/root/data/flume/taildir_position.json</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 3 配置 channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 4 配置 sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.kafka.bootstrap.servers</span> = <span class="string">node1:9092,node2:9092,node3:9092</span></span><br><span class="line"><span class="attr">a1.sinks.k1.kafka.topic</span> = <span class="string">first</span></span><br><span class="line"><span class="attr">a1.sinks.k1.kafka.flumeBatchSize</span> = <span class="string">20</span></span><br><span class="line"><span class="attr">a1.sinks.k1.kafka.producer.acks</span> = <span class="string">1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.kafka.producer.linger.ms</span> = <span class="string">1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 5 拼接组件</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>启动flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/file_to_kafka.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>


</li>
<li><p>向&#x2F;root&#x2F;data&#x2F;app.log 里追加数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# echo hello &gt;&gt; /root/data/applog/app.log</span><br><span class="line">(base) [root@node1 ~]# echo hello flume &gt;&gt; /root/data/applog/app.log</span><br></pre></td></tr></table></figure>


</li>
<li><p>查看 kafka 消费者消费情况</p>
<p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230202160913784.png" alt="image-20230202160913784"></p>
</li>
</ol>
<h2 id="Flume消费者"><a href="#Flume消费者" class="headerlink" title="Flume消费者"></a>Flume消费者</h2><p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230202161059358.png" alt="image-20230202161059358"></p>
<ol>
<li><p>配置flume</p>
<p>文件名：kafka_to_file.conf</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 组件定义</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 2 配置 source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">org.apache.flume.source.kafka.KafkaSource</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">50</span></span><br><span class="line"><span class="attr">a1.sources.r1.batchDurationMillis</span> = <span class="string">200</span></span><br><span class="line"><span class="attr">a1.sources.r1.kafka.bootstrap.servers</span> = <span class="string">node1:9092</span></span><br><span class="line"><span class="attr">a1.sources.r1.kafka.topics</span> = <span class="string">first</span></span><br><span class="line"><span class="attr">a1.sources.r1.kafka.consumer.group.id</span> = <span class="string">custom.g.id</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 3 配置 channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 4 配置 sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>启动flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/kafka_to_file.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动kafka生产者</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka]# ./bin/kafka-console-producer.sh --bootstrap-server node1:9092 --topic first</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello flume</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello hadoop</span></span><br><span class="line"><span class="meta prompt_">&gt;</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>观察控制台输出</p>
<p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230202163426516.png" alt="image-20230202163426516"></p>
</li>
</ol>
<h1 id="集成Flink"><a href="#集成Flink" class="headerlink" title="集成Flink"></a>集成Flink</h1><p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230130220442486.png" alt="image-20230130220442486"></p>
<h1 id="集成SpringBoot"><a href="#集成SpringBoot" class="headerlink" title="集成SpringBoot"></a>集成SpringBoot</h1><p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230130220559057.png" alt="image-20230130220559057"></p>
<h1 id="集成Spark"><a href="#集成Spark" class="headerlink" title="集成Spark"></a>集成Spark</h1><p><img src="/2022/03/18/Kafka%E5%A4%96%E9%83%A8%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90/image-20230130220639873.png" alt="image-20230130220639873"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/03/17/Kafka-Kraft%E6%A8%A1%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/17/Kafka-Kraft%E6%A8%A1%E5%BC%8F/" class="post-title-link" itemprop="url">Kafka-Kraft模式</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-17 21:10:01" itemprop="dateCreated datePublished" datetime="2022-03-17T21:10:01+08:00">2022-03-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Kafka-Kraft架构"><a href="#Kafka-Kraft架构" class="headerlink" title="Kafka-Kraft架构"></a>Kafka-Kraft架构</h1><p>Kafka 现有架构中，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kafka 集群管理。</p>
<p>Kafka-kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。</p>
<p>这样做的好处有以下几个：</p>
<ul>
<li>Kafka 不再依赖外部框架，而是能够独立运行；</li>
<li>controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升；</li>
<li>由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制；</li>
<li>controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</li>
</ul>
<h1 id="Kafka-Kraft-集群部署"><a href="#Kafka-Kraft-集群部署" class="headerlink" title="Kafka-Kraft 集群部署"></a>Kafka-Kraft 集群部署</h1><ol>
<li><p>再次解压一份 kafka 安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 software]# tar -zxvf kafka_2.12-3.3.2.tgz </span><br></pre></td></tr></table></figure>


</li>
<li><p>重命名为 kafka2</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 software]# mv kafka_2.12-3.3.2 ../server/kafka2</span><br></pre></td></tr></table></figure>


</li>
<li><p>在 node1上修改&#x2F;export&#x2F;server&#x2F;kafka2&#x2F;config&#x2F;kraft&#x2F;server.properties 配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kraft]# vim server.properties </span><br></pre></td></tr></table></figure>

<p>内容</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#kafka 的角色（controller 相当于主机、broker 节点相当于从机，主机类似 zk 功能）</span></span><br><span class="line"><span class="attr">process.roles</span>=<span class="string">broker, controller</span></span><br><span class="line"><span class="comment">#节点 ID</span></span><br><span class="line"><span class="attr">node.id</span>=<span class="string">2</span></span><br><span class="line"><span class="comment">#controller 服务协议别名</span></span><br><span class="line"><span class="attr">controller.listener.names</span>=<span class="string">CONTROLLER</span></span><br><span class="line"><span class="comment">#全 Controller 列表</span></span><br><span class="line"><span class="attr">controller.quorum.voters</span>=<span class="string">2@node1:9093,3@node2:9093,4@node3:9093</span></span><br><span class="line"><span class="comment">#不同服务器绑定的端口</span></span><br><span class="line"><span class="attr">listeners</span>=<span class="string">PLAINTEXT://:9092,CONTROLLER://:9093</span></span><br><span class="line"><span class="comment">#broker 服务协议别名</span></span><br><span class="line"><span class="attr">inter.broker.listener.name</span>=<span class="string">PLAINTEXT</span></span><br><span class="line"><span class="comment">#broker 对外暴露的地址</span></span><br><span class="line"><span class="attr">advertised.Listeners</span>=<span class="string">PLAINTEXT://node1:9092</span></span><br><span class="line"><span class="comment">#协议别名到安全协议的映射</span></span><br><span class="line"><span class="attr">listener.security.protocol.map</span>=<span class="string">CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span></span><br><span class="line"><span class="comment">#kafka 数据存储目录</span></span><br><span class="line"><span class="attr">log.dirs</span>=<span class="string">/export/server/kafka2/data</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>分发 kafka2</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 server]# scp -r kafka2 root@node2:$PWD/</span><br><span class="line">(base) [root@node1 server]# scp -r kafka2 root@node3:$PWD/</span><br></pre></td></tr></table></figure>

<ul>
<li><p>在node2和node3上需要对 node.id 相应改变 ， 值需要和controller.quorum.voters 对应。</p>
</li>
<li><p>在 node2和node3上需要根据各自的主机名称，修改相应的advertised.Listeners 地址。</p>
</li>
</ul>
</li>
<li><p>初始化集群数据目录</p>
<p>a. 首先生成存储目录唯一ID</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka2]# ./bin/kafka-storage.sh random-uuid</span><br><span class="line">y0XwsF6dSOyAQoRyAYssJw</span><br></pre></td></tr></table></figure>

<p>b. 用该 ID 格式化 kafka 存储目录（三台节点）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka2]# ./bin/kafka-storage.sh format -t y0XwsF6dSOyAQoRyAYssJw -c ./config/kraft/server.properties </span><br><span class="line">(base) [root@node2 kafka2]# ./bin/kafka-storage.sh format -t y0XwsF6dSOyAQoRyAYssJw -c ./config/kraft/server.properties </span><br><span class="line">(base) [root@node3 kafka2]# ./bin/kafka-storage.sh format -t y0XwsF6dSOyAQoRyAYssJw -c ./config/kraft/server.properties </span><br></pre></td></tr></table></figure>


</li>
<li><p>启动 kafka 集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka2]# ./bin/kafka-server-start.sh -daemon ./config/server.properties </span><br><span class="line">(base) [root@node2 kafka2]# ./bin/kafka-server-start.sh -daemon ./config/server.properties </span><br><span class="line">(base) [root@node3 kafka2]# ./bin/kafka-server-start.sh -daemon ./config/server.properties </span><br></pre></td></tr></table></figure>


</li>
<li><p>停止 kafka 集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka2]# ./bin/kafka-server-stop.sh</span><br><span class="line">(base) [root@node2 kafka2]# ./bin/kafka-server-stop.sh</span><br><span class="line">(base) [root@node3 kafka2]# ./bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="Kafka-Kraft-集群启动停止脚本"><a href="#Kafka-Kraft-集群启动停止脚本" class="headerlink" title="Kafka-Kraft 集群启动停止脚本"></a>Kafka-Kraft 集群启动停止脚本</h1><ol>
<li><p>在~&#x2F;bin 目录下创建文件 kf2.sh 脚本文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# vim bin/kf2.sh </span><br></pre></td></tr></table></figure>

<p>内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">echo &quot;--------&gt;&gt; kafka2 基于Kraft,不依赖于Zookeeper&quot;</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line"> for i in node1 node2 node3</span><br><span class="line"> do</span><br><span class="line"> echo &quot; --------启动 $i Kafka2-------&quot;</span><br><span class="line"> ssh $i &quot;/export/server/kafka2/bin/kafka-server-start.sh -daemon /export/server/kafka2/config/kraft/server.properties&quot;</span><br><span class="line"> done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line"> for i in node1 node2 node3</span><br><span class="line"> do</span><br><span class="line"> echo &quot; --------停止 $i Kafka2-------&quot;</span><br><span class="line"> ssh $i &quot;/export/server/kafka2/bin/kafka-server-stop.sh &quot;</span><br><span class="line"> done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br><span class="line">~</span><br></pre></td></tr></table></figure>


</li>
<li><p>添加执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# chmod u+x bin/kf2.sh </span><br></pre></td></tr></table></figure>


</li>
<li><p>启动集群命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# ./bin/kf2.sh start</span><br></pre></td></tr></table></figure>


</li>
<li><p>停止集群命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# ./bin/kf2.sh stop</span><br></pre></td></tr></table></figure></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/03/16/Kafka-Eagle%E7%9B%91%E6%8E%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/16/Kafka-Eagle%E7%9B%91%E6%8E%A7/" class="post-title-link" itemprop="url">Kafka-Eagle监控</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-16 20:19:41" itemprop="dateCreated datePublished" datetime="2022-03-16T20:19:41+08:00">2022-03-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用。Kafka-Eagle 的安装依赖于 MySQL，MySQL 主要用来存储可视化展示的数据。</p>
<h1 id="Kafka环境准备"><a href="#Kafka环境准备" class="headerlink" title="Kafka环境准备"></a>Kafka环境准备</h1><ol>
<li><p>关闭Kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# ./bin/kf.sh stop</span><br></pre></td></tr></table></figure>


</li>
<li><p>修改&#x2F;export&#x2F;server&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka]# vim bin/kafka-server-start.sh </span><br></pre></td></tr></table></figure>

<p>修改如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then</span><br><span class="line">    export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>为</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then</span><br><span class="line">    export KAFKA_HEAP_OPTS=&quot;-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70&quot;</span><br><span class="line">    export JMX_PORT=&quot;9999&quot;</span><br><span class="line">    #export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>修改之后在启动 Kafka 之前要同步其他节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 kafka]# scp bin/kafka-server-start.sh root@node2:$PWD/bin/</span><br><span class="line">(base) [root@node1 kafka]# scp bin/kafka-server-start.sh root@node3:$PWD/bin/</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="Kafka-Eagle安装"><a href="#Kafka-Eagle安装" class="headerlink" title="Kafka-Eagle安装"></a>Kafka-Eagle安装</h1><ol>
<li><p>官网</p>
<p><a target="_blank" rel="noopener" href="https://www.kafka-eagle.org/">https://www.kafka-eagle.org/</a></p>
</li>
<li><p>下载解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 software]# tar -zxvf kafka-eagle-bin-3.0.1.tar.gz</span><br><span class="line">(base) [root@node1 software]# cd kafka-eagle-bin-3.0.1/</span><br><span class="line">(base) [root@node1 kafka-eagle-bin-3.0.1]# tar -zxvf efak-web-3.0.1-bin.tar.gz </span><br><span class="line">(base) [root@node1 kafka-eagle-bin-3.0.1]# mv efak-web-3.0.1 /export/server/efak</span><br></pre></td></tr></table></figure>


</li>
<li><p>修改配置文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># multi zookeeper &amp; kafka cluster list</span></span><br><span class="line"><span class="comment"># Settings prefixed with &#x27;kafka.eagle.&#x27; will be deprecated, use &#x27;efak.&#x27; instead</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="attr">efak.zk.cluster.alias</span>=<span class="string">cluster1</span></span><br><span class="line"><span class="attr">cluster1.zk.list</span>=<span class="string">node1:2181,node2:2181,node3:2181/kafka</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka offset storage</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="attr">cluster1.efak.offset.storage</span>=<span class="string">kafka</span></span><br><span class="line"><span class="attr">cluster2.efak.offset.storage</span>=<span class="string">zk</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="comment"># kafka mysql jdbc driver address</span></span><br><span class="line"><span class="comment">######################################</span></span><br><span class="line"><span class="attr">efak.driver</span>=<span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="attr">efak.url</span>=<span class="string">jdbc:mysql://node1:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span></span><br><span class="line"><span class="attr">efak.username</span>=<span class="string">root</span></span><br><span class="line"><span class="attr">efak.password</span>=<span class="string">hadoop</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 conf]# vim /etc/profile</span><br></pre></td></tr></table></figure>

<p>在末尾添加</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#KAFKA-EFAK</span></span><br><span class="line"><span class="attr">export</span> <span class="string">KE_HOME=/export/server/efak</span></span><br><span class="line"><span class="attr">export</span> <span class="string">PATH=$PATH:$KE_HOME/bin</span></span><br></pre></td></tr></table></figure>

<p>使生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 conf]# source /etc/profile</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动</p>
<p>启动之前需要先启动 ZK 以及 Kafka。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 ~]# ./bin/zk.sh start</span><br><span class="line">(base) [root@node1 ~]# ./bin/kf.sh start</span><br></pre></td></tr></table></figure>

<p>启动Efak</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 efak]# ./bin/ke.sh start</span><br><span class="line">[2023-01-30 17:44:02] INFO: [Job done!]</span><br><span class="line">Welcome to</span><br><span class="line">    ______    ______    ___     __ __</span><br><span class="line">   / ____/   / ____/   /   |   / //_/</span><br><span class="line">  / __/     / /_      / /| |  / ,&lt;   </span><br><span class="line"> / /___    / __/     / ___ | / /| |  </span><br><span class="line">/_____/   /_/       /_/  |_|/_/ |_|  </span><br><span class="line">( Eagle For Apache Kafka )</span><br><span class="line"></span><br><span class="line">Version v3.0.1 -- Copyright 2016-2022</span><br><span class="line">*******************************************************************</span><br><span class="line">* EFAK Service has started success.</span><br><span class="line">* Welcome, Now you can visit &#x27;http://192.168.88.151:8048&#x27;</span><br><span class="line">* Account:admin ,Password:123456</span><br><span class="line">*******************************************************************</span><br><span class="line">* &lt;Usage&gt; ke.sh [start|status|stop|restart|stats] &lt;/Usage&gt;</span><br><span class="line">* &lt;Usage&gt; https://www.kafka-eagle.org/ &lt;/Usage&gt;</span><br><span class="line">*******************************************************************</span><br></pre></td></tr></table></figure>

<p>关闭Efak</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@node1 efak]# ./bin/ke.sh stop</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="Kafka-Eagle页面"><a href="#Kafka-Eagle页面" class="headerlink" title="Kafka-Eagle页面"></a>Kafka-Eagle页面</h1><p><img src="/2022/03/16/Kafka-Eagle%E7%9B%91%E6%8E%A7/image-20230130175035021.png" alt="image-20230130175035021"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">162</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
