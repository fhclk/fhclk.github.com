<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="拾荒者">
<meta property="og:url" content="http://fhclk.github.io/page/6/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="fhclk">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fhclk.github.io/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/14/Hadoop-MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/14/Hadoop-MapReduce/" class="post-title-link" itemprop="url">Hadoop-MapReduce</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-14 10:17:09" itemprop="dateCreated datePublished" datetime="2021-08-14T10:17:09+08:00">2021-08-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分布式计算分而治之思想"><a href="#分布式计算分而治之思想" class="headerlink" title="分布式计算分而治之思想"></a>分布式计算分而治之思想</h1><h2 id="分布式计算"><a href="#分布式计算" class="headerlink" title="分布式计算"></a>分布式计算</h2><p>分布式计算是一种计算方法，它将应用分解成许多小的部分，分配给多台计算机进行处理。从而节约整体计算时间，提高计算效率。</p>
<h2 id="MapReduce思想"><a href="#MapReduce思想" class="headerlink" title="MapReduce思想"></a>MapReduce思想</h2><p>MapReduce思想核心：<strong>先分再合，分而治之</strong>。即把一个复杂的问题，按照一定的“分解”方法分为等价的规模较小的若干部分，然后逐个解决，分别找出各部分的结果，然后把各部分的结果组成整个问题的最终结果。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213101954806.png" alt="image-20221213101954806"></p>
<ul>
<li>Map表示第一阶段，负责“拆分”：即把复杂的任务分解成若干个“简单的子任务”来处理。可以进行拆分的前提是这些小任务可以并行计算，彼此间几乎没有依赖关系。</li>
<li>Reduce表示第二阶段，负责“合并”：即对map阶段的结果进行全局汇总。</li>
<li>这两个阶段合起来就是MapReduce思想的体现。</li>
</ul>
<h2 id="大数据处理场景"><a href="#大数据处理场景" class="headerlink" title="大数据处理场景"></a>大数据处理场景</h2><p>采用MapReduce分而治之策略，首先Map阶段进行拆分，把大数据拆分成若个份小数据，多个程序同时并行计算产生中间结果；然后Reduce聚合阶段，通过程序对并行的结果进行最终的汇总计算，得出最终结果。</p>
<p><strong>不可拆分的计算任务或相互间有依赖关系的数据无法进行并行计算</strong></p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213102715695.png" alt="image-20221213102715695"></p>
<h2 id="构建抽象编程模型"><a href="#构建抽象编程模型" class="headerlink" title="构建抽象编程模型"></a>构建抽象编程模型</h2><ul>
<li><p>MapReduce借鉴了函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型。</p>
<p>map：对一组数据元素进行某种重复式的处理</p>
<p>reduce：对Map的中间结果进行某种进一步的结果处理</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213103050117.png" alt="image-20221213103050117"></p>
</li>
<li><p>MapReduce中定义了如下的Map和Reduce两个抽象的编程接口，由用户去编程实现：</p>
<p>map：（k1; v1) -&gt; (k2; v2)</p>
<p>reduce：(k2: [v2]) -&gt; (k3; v3)</p>
</li>
<li><p>通过以上两个编程接口，可以看出MapReduce处理的数据类型是&lt;key, value&gt;键值对。</p>
</li>
</ul>
<h2 id="统一架构，隐藏底层细节"><a href="#统一架构，隐藏底层细节" class="headerlink" title="统一架构，隐藏底层细节"></a>统一架构，隐藏底层细节</h2><p>MapReduce设计并统一了计算框架，隐藏了绝大多数系统层面的处理细节。</p>
<h1 id="MapReduce介绍"><a href="#MapReduce介绍" class="headerlink" title="MapReduce介绍"></a>MapReduce介绍</h1><p>Hadoop MapReduce是一个分布式计算框架，用于轻松编写分布式应用程序，这些应用程序以可靠，容错的方式并行处理大型硬件集群（多节点）上的大量数据（TB级别）。</p>
<p>MapReduce是一种面向海量数据处理的一种指导思想，也是一种用于大规模数据进行分布式计算的编程模型。</p>
<p><strong>MapReduce特点</strong></p>
<ul>
<li><p>易于编程</p>
<p>提供了用于二次开发的接口</p>
</li>
<li><p>良好的扩展</p>
<p>可以通过增加机器（计算节点）来扩展它的计算能力</p>
</li>
<li><p>高容错性</p>
<p>分布式搭建和部署，当某一个节点出现故障时，可以把上面的任务转移到另一个节点上运行，不影响整个任务。这个过程Hadoop内部完成</p>
</li>
<li><p>适合海量数据的离线处理</p>
<p>可以处理GB、TB、PB级别数据</p>
</li>
</ul>
<p><strong>MapReduce局限性</strong></p>
<ul>
<li>实时计算性能差</li>
<li>不能进行流式计算</li>
</ul>
<h1 id="MapReduce实例进程"><a href="#MapReduce实例进程" class="headerlink" title="MapReduce实例进程"></a>MapReduce实例进程</h1><p>一个完整的MapReduce程序在分布式运行时有三类</p>
<ul>
<li>MRAppMaster：负责整个MR程序的过程调度及状态协调</li>
<li>MapTask：负责map阶段的整个数据处理流程</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213110013345.png" alt="image-20221213110013345"></p>
<h1 id="MapReduce阶段组成"><a href="#MapReduce阶段组成" class="headerlink" title="MapReduce阶段组成"></a>MapReduce阶段组成</h1><ul>
<li>一个MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，或者只有Map阶段。</li>
<li>不能有很多个Map阶段、多个Reduce阶段的情形。</li>
<li>如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序串行运行。</li>
</ul>
<img src="/2021/08/14/Hadoop-MapReduce/image-20221213111404853.png" alt="image-20221213111404853" style="zoom: 80%;">



<h1 id="MapReduce数据类型"><a href="#MapReduce数据类型" class="headerlink" title="MapReduce数据类型"></a>MapReduce数据类型</h1><p>整个MapReduce程序中，数据都是以KV兼职对的形式流转的。</p>
<p>在实际编程解决各种业务问题中，需要考虑每个阶段的输入输出kv分别是什么。</p>
<p>MapReduce中内置了很多默认属性，比如排序、分组等，都和数据的k有关。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213113122471.png" alt="image-20221213113122471"></p>
<h1 id="MapReduce执行流程"><a href="#MapReduce执行流程" class="headerlink" title="MapReduce执行流程"></a>MapReduce执行流程</h1><h2 id="MapReduce整体执行流程图"><a href="#MapReduce整体执行流程图" class="headerlink" title="MapReduce整体执行流程图"></a>MapReduce整体执行流程图</h2><p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213142024380.png" alt="image-20221213142024380"></p>
<h2 id="Map阶段执行流程"><a href="#Map阶段执行流程" class="headerlink" title="Map阶段执行流程"></a>Map阶段执行流程</h2><ul>
<li>第一阶段：把输入目录下文件按照一定的标准逐个进行逻辑切片，形成切片规划。默认Split size &#x3D; Block size （128M），每一个切片由一个MapTask处理。（getSplits）</li>
<li>第二阶段：对切片中的数据按照一定的规则读取解析返回&lt;key, value&gt;对。默认是按行读取数据。key是每一行的起始位置偏移量，value是本行的文本内容。（TextInutFormat）</li>
<li>第三阶段：调用Mapper类中的map方法处理数据。每读取解析出来的一个&lt;key, value&gt;，调用一次map方法。</li>
<li>第四阶段：按照一定的规则对map输出的键值对进行分区partition。默认不分区，因为只有一个reducetask。分区的数量就是reducetask运行的数量。</li>
<li>第五阶段：Map输出数据写入内存缓冲区，达到比例溢出到磁盘上。溢出spill的时候根据key进行排序sort。默认根据key字典排序。</li>
<li>第六阶段：对所有溢出文件进行最终的merge合并，成为一个文件。</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213142808652.png" alt="image-20221213142808652"></p>
<h2 id="Reduce阶段执行流程"><a href="#Reduce阶段执行流程" class="headerlink" title="Reduce阶段执行流程"></a>Reduce阶段执行流程</h2><ul>
<li>第一阶段：ReduceTask会主动从MapTask复制拉取属于需要自己处理的数据。</li>
<li>第二阶段：把拉取来的数据，全部进行merge合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</li>
<li>第三阶段：对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法。最后把这些输出的键值对写入到HDFS文件中。</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213143229439.png" alt="image-20221213143229439"></p>
<h2 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h2><h3 id="shuffle概念"><a href="#shuffle概念" class="headerlink" title="shuffle概念"></a>shuffle概念</h3><p>Shuffle的本意是洗牌、混洗的意思，把一组有规则地数据尽量打乱成无规则地数据。</p>
<p>在MapReduce中，Shuffle更像是洗牌的逆过程，指的是将map端的无规则输出按指定的规则“打乱”成具有一定规则的数据，以便reduce端接收处理。</p>
<p>一般把从Map产生输出开始到Reduce取得数据作为输入之前的过程称之为shuffle。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213144448734.png" alt="image-20221213144448734"></p>
<h3 id="Map端Shuffle"><a href="#Map端Shuffle" class="headerlink" title="Map端Shuffle"></a>Map端Shuffle</h3><p>Collect阶段：将MapTask的结果收集输出到默认大小为100M的环形缓冲区，保存之前会对key进行分区的计算，默认Hash分区。</p>
<p>Spill阶段：当内存的数据达到一定的阈值的时候，就会将数据写入磁盘，在将数据写入磁盘之前需要对数据进行一次排序的操作，如果配置了combiner，还会将有相同分区号和key的数据进行排序。</p>
<p>Merge阶段：把所有溢出的文件进行一次合并操作，以确保一个MapTask最终只产生一个中间数据文件。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213144901309.png" alt="image-20221213144901309"></p>
<h3 id="Reduce端Shuffle"><a href="#Reduce端Shuffle" class="headerlink" title="Reduce端Shuffle"></a>Reduce端Shuffle</h3><p>Copy阶段：ReduceTask启动Fetcher线程到已经完成MapTask的节点上复制一份属于自己的数据。</p>
<p>Merge阶段：在ReduceTask远程复制数据的同时，会在后台开启两个线程对内存到本地的数据文件进行合并操作。</p>
<p>Sort阶段：在对数据进行合并的同时，会进行排序操作，由于MapTask阶段已经对数据进行了局部的排序，ReduceTask只需保证Copy的数据的最终整体有效性即可。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213145258144.png" alt="image-20221213145258144"></p>
<h3 id="shuffle机制弊病"><a href="#shuffle机制弊病" class="headerlink" title="shuffle机制弊病"></a>shuffle机制弊病</h3><p>Shuffle是MapReduce成的核心与精髓，是MapReduce的灵魂所在。</p>
<p>Shuffle也是MapReduce被诟病最多的地方。MapReduce相比较于Spark、Flink计算引擎慢的原因，根Shuffle机制有很大的关系。Shuffle频繁涉及到数据在内存、磁盘之间的多次往复。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/13/Hadoop-HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/13/Hadoop-HDFS/" class="post-title-link" itemprop="url">Hadoop-HDFS</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-13 10:07:09" itemprop="dateCreated datePublished" datetime="2021-08-13T10:07:09+08:00">2021-08-13</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>数据</strong>：指存储的内容本身，比如文件、视频、图片等，这些数据底层最终是存储在磁盘等存储介质上的，一般用户无需关心，只需要基于目录树进行增删改查即可，实际针对数据的操作有文件系统完成。</p>
<p><strong>元数据</strong>：</p>
<p>元数据（metadata）又称之为解释性数据，记录数据的数据。</p>
<p>文件系统元数据一般指文件大小、最后修改时间、底层存储位置、属性、所属用户、权限等信息。</p>
<h2 id="分布式存储系统核心属性"><a href="#分布式存储系统核心属性" class="headerlink" title="分布式存储系统核心属性"></a>分布式存储系统核心属性</h2><ul>
<li><p>分布式存储</p>
<p>问题：数据量大，单机存储遇到瓶颈。</p>
<p>解决：</p>
<p>单机纵向扩展：增加磁盘</p>
<p>多机横向扩展：增加机器</p>
</li>
<li><p>元数据记录</p>
<p>问题：文件分布在不同机器上不利于查找</p>
<p>解决：</p>
<p>元数据记录下文件及其存储位置信息（文件名、大小、存储机器IP），快速定位文件位置</p>
</li>
<li><p>分块机制</p>
<p>问题：文件过大导致单机存不下、上传下载效率低</p>
<p>解决：文件分块存储在不同的机器，针对块并行操作提高效率</p>
</li>
<li><p>副本机制</p>
<p>问题：硬件出现故障，输入容易丢失</p>
<p>解决：不同机器设置备份，冗余存储，保障数据安全</p>
</li>
</ul>
<h1 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h1><p>HDFS（Hadoop Distributed File System），Hadoop分布式文件系统，其主要是解决大数据如何存储问题，适于存储大型数据（TB和PB），它使用多台计算机存储文件，并且提供统一的访问接口，像访问一个普通文件系统一样使用分布式文件系统。</p>
<h2 id="HDFS应用场景"><a href="#HDFS应用场景" class="headerlink" title="HDFS应用场景"></a>HDFS应用场景</h2><p>适合场景：</p>
<p>大文件、数据流式访问、一次写入多次读取、低成本部署（廉价PC）、高容错</p>
<p>不适合场景：</p>
<p>小文件、数据交互式访问、频繁任意修改、低延迟处理</p>
<h2 id="HDFS重要特性"><a href="#HDFS重要特性" class="headerlink" title="HDFS重要特性"></a>HDFS重要特性</h2><ul>
<li>主从架构</li>
<li>分块存储</li>
<li>副本机制</li>
<li>元数据记录</li>
<li>抽象统一的目录树结构（namespace）</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212155509725.png" alt="image-20221212155509725"></p>
<h3 id="主从架构"><a href="#主从架构" class="headerlink" title="主从架构"></a>主从架构</h3><ul>
<li>HDFS集群是标准的master&#x2F;slave主从架构集群</li>
<li>一般一个HDFS集群是有一个Namenode和一定数目的Datanode组成</li>
<li>Namenode是HDFS主节点，Datanode是HDFS从节点，两种角色各司其职，共同协调完成分布式的文件存储服务</li>
</ul>
<h3 id="分块存储"><a href="#分块存储" class="headerlink" title="分块存储"></a>分块存储</h3><ul>
<li>HDFS中的文件在物理上是分块存储（block）的，默认大小是128M，不足128M则本身就是一块。</li>
<li>块的大小可以通过配置参数来规定，参数位于hdfs-default.xml中： dfs.blocksize</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212160026689.png" alt="image-20221212160026689"></p>
<h3 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h3><ul>
<li>文件的所有block都会有副本。副本系数可以在文件创建的时候指定，也可以在之后通过命令改变</li>
<li>副本数由参数dfs.replication控制，默认是3，也就是会额外再复制2份，连同本身供3份</li>
</ul>
<h3 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h3><p>HDFS中，Namenode管理的元数据有两种类型：</p>
<p><strong>文件自身属性信息</strong></p>
<p>文件名称、权限、修改时间、文件大小、复制因子、数据块大小</p>
<p><strong>文件块位置映射信息</strong></p>
<p>记录文件块和DataNode之间的映射信息，即那块位于哪个节点上。</p>
<h3 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h3><p>HDFS支持传统的层次型文件组织结构。用户可以创建目录，然后将文件保存在这些目录里，文件系统名字空间的层次结构和大多数现有的文件系统类似，用户可以创建、修改、移动或重命名文件。</p>
<p>Namenode负责维护文件系统的namespace名称空间，任何文件系统名称空间或属性的修改都将被Namenode记录下来。</p>
<p>HDFS会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs:&#x2F;&#x2F;namenode:port&#x2F;dir&#x2F;file.data</p>
<h3 id="数据块存储"><a href="#数据块存储" class="headerlink" title="数据块存储"></a>数据块存储</h3><p>文件的各个block的具体存储管理由Datanode节点承担。</p>
<p>每一个block都可以在多个Datanode上存储。</p>
<h1 id="HDFS-shell"><a href="#HDFS-shell" class="headerlink" title="HDFS shell"></a>HDFS shell</h1><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs [generic options]</span><br></pre></td></tr></table></figure>



<h2 id="文件系统协议"><a href="#文件系统协议" class="headerlink" title="文件系统协议"></a>文件系统协议</h2><p>本地文件系统： file:&#x2F;&#x2F;&#x2F;</p>
<p>分布式文件系统： hdfs:&#x2F;&#x2F;&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls file:/// #操作本地文件系统</span><br><span class="line">hadoop fs -ls hdfs:///node1:8020/  #操作HDFS分布式文件系统</span><br><span class="line">hadoop hs -ls / #直接根目录，没有指定协议，将加载fs.defaultFS值</span><br></pre></td></tr></table></figure>



<p>hdfs dfs 只能操作HDFS文件系统相关（包括Local FS间的操作），常用。</p>
<p>hadoop fs可操作任意文件系统，不仅仅是hdfs文件系统，适用范围更广。</p>
<h1 id="HDFS工作流程与机制"><a href="#HDFS工作流程与机制" class="headerlink" title="HDFS工作流程与机制"></a>HDFS工作流程与机制</h1><h2 id="HDFS集群角色与职责"><a href="#HDFS集群角色与职责" class="headerlink" title="HDFS集群角色与职责"></a>HDFS集群角色与职责</h2><h3 id="主角色：namenode"><a href="#主角色：namenode" class="headerlink" title="主角色：namenode"></a>主角色：namenode</h3><p>NameNode是Hadoop分布式文件系统的核心，架构中的主角色。</p>
<p>NameNode维护和管理文件系统元数据，包括名称空间目录树结构、文件和块的位置信息、访问权限等信息。</p>
<p>NameNode成为了访问HDFS的唯一入口。</p>
<p>NameNode内部通过内存和磁盘文件两种方式管理元数据。</p>
<p>其中磁盘上的元数据文件包括Fsimage内存元数据镜像文件和edits log（Journal）编辑日志。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212162816232.png" alt="image-20221212162816232"></p>
<h3 id="从角色：datanode"><a href="#从角色：datanode" class="headerlink" title="从角色：datanode"></a>从角色：datanode</h3><p>DataNode具体负责数据块存储。</p>
<p>DataNode的数量决定了HDFS集群的整体数据存储能力。通过和NameNode配合维护着数据块。</p>
<h3 id="主角色辅助角色：secondarynamenode"><a href="#主角色辅助角色：secondarynamenode" class="headerlink" title="主角色辅助角色：secondarynamenode"></a>主角色辅助角色：secondarynamenode</h3><p>SecondaryNameNode充当NameNode的辅助节点，但不能替代NameNode。</p>
<p>主要是帮助主角色进行元数据文件的合并动作。</p>
<h3 id="namenode职责"><a href="#namenode职责" class="headerlink" title="namenode职责"></a>namenode职责</h3><p>NameNode仅存储HDFS的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</p>
<p>NameNode知道HDFS中任何给定文件的快列表及其位置。使用此信息NameNode知道如何从块中构建文件。</p>
<p>NameNode不持久化存储每个文件中各个块所在的datanode的位置信息，这些信息会在系统启动时从DataNode重建。</p>
<p>NameNode是Hadoop集群中的单点故障。</p>
<p>NameNode所在机器通常会配置有大量内存（RAM）</p>
<h3 id="datanode职责"><a href="#datanode职责" class="headerlink" title="datanode职责"></a>datanode职责</h3><p>DataNode负责最终数据块block的存储。是集群的从角色，也称为Slave。</p>
<p>DataNode启动时，会将自己注册到NameNode并汇报自己负责持有的块列表。</p>
<p>当某个DataNode关闭时，不会影响数据的可用性。NameNode将安排由其他DataNode管理的块进行副本复制。</p>
<p>DataNode所在机器通常配置有大量的硬盘空间，因为实际数据存储在DataNode中。</p>
<h2 id="HDFS写数据流程（上传文件）"><a href="#HDFS写数据流程（上传文件）" class="headerlink" title="HDFS写数据流程（上传文件）"></a>HDFS写数据流程（上传文件）</h2><h3 id="Pipeline管道"><a href="#Pipeline管道" class="headerlink" title="Pipeline管道"></a>Pipeline管道</h3><p>Pipeline是HDFS在上传文件写数据过程中采用的一种数据传输方式。</p>
<p>客户端将数据写入第一个数据节点，第一个数据节点保存数据之后再将块复制到第二个数据节点，后者保存后将其复制到第三个数据节点。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212230023760.png" alt="image-20221212230023760"></p>
<p>数据以管道的方式，顺序的沿着一个方向传输，这样能够充分利用每个机器的带宽，避免网络瓶颈和高延迟时的连接，最小化推送所有数据的延时。</p>
<p>在线性推送模式下，每台机器所有的出口带宽都用于以最快的速度传输数据，而不是在多个接受者之间分配带宽。</p>
<h3 id="ACK应答响应"><a href="#ACK应答响应" class="headerlink" title="ACK应答响应"></a>ACK应答响应</h3><p>ACK（Acknowledge character）即是确认字符，在数据通信中，接收方发送给发送方的一种传输类控制字符。表示发来的数据已确认接收无误。</p>
<p>在HDFS pipeline管道传输数据的过程中，传输的反方向会进行ACK校验，确保数据传输安全。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212230559137.png" alt="image-20221212230559137"></p>
<h3 id="默认3副本存储策略"><a href="#默认3副本存储策略" class="headerlink" title="默认3副本存储策略"></a>默认3副本存储策略</h3><p>默认副本存储策略是由BlockPlacementPolicyDefault指定。</p>
<ul>
<li>第一块副本：优先客户端本地，否则随机</li>
<li>第二块副本：不同于第一块副本的不同机架</li>
<li>第三块副本：第二块副本相同机架不通过机器</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212232028347.png" alt="image-20221212232028347"></p>
<h3 id="写数据完整流程图"><a href="#写数据完整流程图" class="headerlink" title="写数据完整流程图"></a>写数据完整流程图</h3><p><img src="/2021/08/13/Hadoop-HDFS/image-20221212225725826.png" alt="image-20221212225725826"></p>
<h3 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h3><ol>
<li>HDFS客户端创建对象实例DistributedFileSystem，该对象中封装了与HDFS文件系统操作相关的方法。</li>
<li>调用DistributedFileSystem对象的create()方法，通过RPC请求NameNode创建文件。NameNode执行各种检查判断：目标文件是否存在、父目录是否存在、客户端是否具有创建该文件的权限。检查通过，NameNode就会为本次请求记下一条记录，返回FSDataOutputStream输出流对象给客户端用于写数据。</li>
<li>客户端通过FSDataOutputStream输出流开始写入数据。</li>
<li>客户端写入数据时，将数据分成一个个数据包（packet默认64K），内部组件DataStreamer请求NameNode挑选出适合存储数据副本的一组DataNode地址，默认是3副本存储。DataStreamer将数据包流式传输到pipeline的第一个DataNode，该DataNode存储数据包并将它们发送到pipeline的第二个DataNode。同样，第二个DataNode存储数据包并且发送给第三个DataNode。</li>
<li>传输的反方向上，会通过ACK机制校验数据包传输是否成功。</li>
<li>客户端完成数据写入后，在FSDataOutputStream输出流上调用close()方法关闭。</li>
<li>DistributedFileSystem联系NameNode告知其文件写入完成，等待NameNode确认。因为NameNode已经知道文件是由哪些块组成（DataStream请求分配数据块），因此仅需等待最小复制块即可成功返回。最小复制是由参数dfs.namenode.replication.min指定，默认是1。</li>
</ol>
<h2 id="HDFS读数据流程（下载文件）"><a href="#HDFS读数据流程（下载文件）" class="headerlink" title="HDFS读数据流程（下载文件）"></a>HDFS读数据流程（下载文件）</h2><h3 id="读数据完整流程图"><a href="#读数据完整流程图" class="headerlink" title="读数据完整流程图"></a>读数据完整流程图</h3><p><img src="/2021/08/13/Hadoop-HDFS/image-20221213094517559.png" alt="image-20221213094517559"></p>
<h3 id="读数据流程"><a href="#读数据流程" class="headerlink" title="读数据流程"></a>读数据流程</h3><ol>
<li>HDFS客户端创建对象实例DistributedFileSystem，调用该对象的open()方法来打开希望读取的文件。</li>
<li>DistributedFileSystem使用RPC调用namenode来确定文件中前几块的块位置（分批次读取）信息。对于每个块，namenode返回具体有该模块所有副本的datanode位置地址列表，并且该地址列表是排序好的，与客户端的网络拓扑距离近的排序靠前。</li>
<li>DistributedFileSystem将FSDataInputStream输入流返回到客户端以供其读取数据。</li>
<li>客户端在FSDataInputStream输入流上调用read()方法。然后，已存储DataNode地址的InputStream连接到文件中第一个块的最近的DataNode。数据从DataNode流回客户端，结果客户端可以在流上重复调用read()。</li>
<li>当该块结束时，FSDataInputStream将关闭与DataNode的连接，然后寻找下一个block块的最佳datanode位置。这些操作对用户来说是透明的。所以用户感觉起来它一直在读取一个连续的流。客户端从流中读取数据时，也会根据需要询问NameNode来检索下一批数据块的DataNode位置信息。</li>
<li>一旦客户端完成读取，就对FSDataInputStream调用close()方法。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/12/Hadoop-%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/12/Hadoop-%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">Hadoop-部署</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-12 11:13:02" itemprop="dateCreated datePublished" datetime="2021-08-12T11:13:02+08:00">2021-08-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>操作系统：Centos 7.7</p>
<p>安装目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /export/server</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Hadoop集群分布式安装"><a href="#Hadoop集群分布式安装" class="headerlink" title="Hadoop集群分布式安装"></a>Hadoop集群分布式安装</h1><h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><table>
<thead>
<tr>
<th>主机</th>
<th>角色</th>
</tr>
</thead>
<tbody><tr>
<td>node1</td>
<td>NN    DN   RM  NM</td>
</tr>
<tr>
<td>node2</td>
<td>SNN  DN           NM</td>
</tr>
<tr>
<td>node3</td>
<td>DN          NM</td>
</tr>
</tbody></table>
<h2 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h2><blockquote>
<p>3台机器都需要操作</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主机名</span> </span><br><span class="line">cat /etc/hostname</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hosts映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.88.151 node1.itcast.cn node1</span><br><span class="line">192.168.88.152 node2.itcast.cn node2</span><br><span class="line">192.168.88.153 node3.itcast.cn node3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JDK 1.8安装  上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下</span></span><br><span class="line">cd /export/server/</span><br><span class="line">tar zxvf jdk-8u241-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">	</span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="meta prompt_">	</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新加载环境变量文件</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">集群时间同步</span></span><br><span class="line">ntpdate ntp5.aliyun.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">防火墙关闭</span></span><br><span class="line">firewall-cmd --state	#查看防火墙状态</span><br><span class="line">systemctl stop firewalld.service  #停止firewalld服务</span><br><span class="line">systemctl disable firewalld.service  #开机禁用firewalld服务</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh免密登录（只需要配置node1至node1、node2、node3即可）</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">node1生成公钥私钥 (一路回车)</span></span><br><span class="line">ssh-keygen  </span><br><span class="line"><span class="meta prompt_">	</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">node1配置免密登录到node1 node2 node3</span></span><br><span class="line">ssh-copy-id node1</span><br><span class="line">ssh-copy-id node2</span><br><span class="line">ssh-copy-id node3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><p>上传Hadoop安装包到node1 &#x2F;export&#x2F;server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br></pre></td></tr></table></figure>



<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>修改配置文件(配置文件路径 hadoop-3.3.0&#x2F;etc&#x2F;hadoop)</p>
<ul>
<li><p>hadoop-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件最后添加</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line"></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root </span><br></pre></td></tr></table></figure>
</li>
<li><p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置Hadoop本地保存数据路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/data/hadoop-3.3.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS web UI用户身份 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 整合hive 用户代理设置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 文件系统垃圾桶保存时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node2:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施物理内存限制 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn历史服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node1:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史日志保存的时间 7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>workers</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node1.itcast.cn</span><br><span class="line">node2.itcast.cn</span><br><span class="line">node3.itcast.cn</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="同步到node2和node3节点"><a href="#同步到node2和node3节点" class="headerlink" title="同步到node2和node3节点"></a>同步到node2和node3节点</h2><p>分发同步hadoop安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server</span><br><span class="line"></span><br><span class="line">scp -r hadoop-3.3.0 root@node2:$PWD</span><br><span class="line">scp -r hadoop-3.3.0 root@node3:$PWD</span><br></pre></td></tr></table></figure>



<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>将hadoop添加到环境变量（3台机器）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop-3.3.0</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">别忘了scp给其他两台机器哦</span></span><br></pre></td></tr></table></figure>



<h2 id="Hadoop集群启动"><a href="#Hadoop集群启动" class="headerlink" title="Hadoop集群启动"></a>Hadoop集群启动</h2><ul>
<li><p>（&#x3D;&#x3D;首次启动&#x3D;&#x3D;）格式化namenode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>脚本一键启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# start-dfs.sh </span><br><span class="line">Starting namenodes on [node1]</span><br><span class="line">Last login: Thu Nov  5 10:44:10 CST 2020 on pts/0</span><br><span class="line">Starting datanodes</span><br><span class="line">Last login: Thu Nov  5 10:45:02 CST 2020 on pts/0</span><br><span class="line">Starting secondary namenodes [node2]</span><br><span class="line">Last login: Thu Nov  5 10:45:04 CST 2020 on pts/0</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Last login: Thu Nov  5 10:45:08 CST 2020 on pts/0</span><br><span class="line">Starting nodemanagers</span><br><span class="line">Last login: Thu Nov  5 10:45:44 CST 2020 on pts/0</span><br></pre></td></tr></table></figure>
</li>
<li><p>Web  UI页面</p>
<ul>
<li>HDFS集群：<a target="_blank" rel="noopener" href="http://node1:9870/">http://node1:9870/</a></li>
<li>YARN集群：<a target="_blank" rel="noopener" href="http://node1:8088/">http://node1:8088/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>运行hadoop3官方自带mr示例出错。</p>
<ul>
<li><p>错误信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</span><br><span class="line"></span><br><span class="line">Please check whether your etc/hadoop/mapred-site.xml contains the below configuration:</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>解决  mapred-site.xml,增加以下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h1 id="Hadoop编译安装（了解）"><a href="#Hadoop编译安装（了解）" class="headerlink" title="Hadoop编译安装（了解）"></a>Hadoop编译安装（了解）</h1><ul>
<li><p>安装编译相关的依赖</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc gcc-c++ make autoconf automake libtool curl lzo-devel zlib-devel openssl openssl-devel ncurses-devel snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop libXtst zlib -y</span><br><span class="line"></span><br><span class="line">yum install -y doxygen cyrus-sasl* saslwrapper-devel*</span><br></pre></td></tr></table></figure>
</li>
<li><p>手动安装cmake </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">yum卸载已安装cmake 版本低</span></span><br><span class="line">yum erase cmake</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar zxvf CMake-3.19.4.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/CMake-3.19.4</span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证</span></span><br><span class="line">[root@node4 ~]# cmake -version</span><br><span class="line">cmake version 3.19.4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果没有正确显示版本 请断开SSH连接 重写登录</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>手动安装snappy</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载已经安装的</span></span><br><span class="line"></span><br><span class="line">rm -rf /usr/local/lib/libsnappy*</span><br><span class="line">rm -rf /lib64/libsnappy*</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传解压</span></span><br><span class="line">tar zxvf snappy-1.1.3.tar.gz </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/snappy-1.1.3</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装</span></span><br><span class="line">[root@node4 snappy-1.1.3]# ls -lh /usr/local/lib |grep snappy</span><br><span class="line">-rw-r--r-- 1 root root 511K Nov  4 17:13 libsnappy.a</span><br><span class="line">-rwxr-xr-x 1 root root  955 Nov  4 17:13 libsnappy.la</span><br><span class="line">lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so -&gt; libsnappy.so.1.3.0</span><br><span class="line">lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so.1 -&gt; libsnappy.so.1.3.0</span><br><span class="line">-rwxr-xr-x 1 root root 253K Nov  4 17:13 libsnappy.so.1.3.0</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装配置JDK 1.8</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压安装包</span></span><br><span class="line">tar zxvf jdk-8u65-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">java -version</span><br><span class="line"></span><br><span class="line">java version &quot;1.8.0_241&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_241-b07)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装配置maven</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压安装包</span></span><br><span class="line">tar zxvf apache-maven-3.5.4-bin.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export MAVEN_HOME=/export/server/apache-maven-3.5.4</span><br><span class="line">export MAVEN_OPTS=&quot;-Xms4096m -Xmx4096m&quot;</span><br><span class="line">export PATH=:$MAVEN_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">[root@node4 ~]# mvn -v</span><br><span class="line">Apache Maven 3.5.4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加maven 阿里云仓库地址 加快国内编译速度</span></span><br><span class="line">vim /export/server/apache-maven-3.5.4/conf/settings.xml</span><br><span class="line"></span><br><span class="line">&lt;mirrors&gt;</span><br><span class="line">     &lt;mirror&gt;</span><br><span class="line">           &lt;id&gt;alimaven&lt;/id&gt;</span><br><span class="line">           &lt;name&gt;aliyun maven&lt;/name&gt;</span><br><span class="line">           &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;</span><br><span class="line">           &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</span><br><span class="line">      &lt;/mirror&gt;</span><br><span class="line">&lt;/mirrors&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装ProtocolBuffer 3.7.1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载之前版本的protobuf</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar zxvf protobuf-3.7.1.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/protobuf-3.7.1</span><br><span class="line">./autogen.sh</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">[root@node4 protobuf-3.7.1]# protoc --version</span><br><span class="line">libprotoc 3.7.1</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传解压源码包</span></span><br><span class="line">tar zxvf hadoop-3.3.0-src.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译</span></span><br><span class="line">cd /root/hadoop-3.3.0-src</span><br><span class="line"></span><br><span class="line">mvn clean package -Pdist,native -DskipTests -Dtar -Dbundle.snappy -Dsnappy.lib=/usr/local/lib</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">参数说明：</span></span><br><span class="line"></span><br><span class="line">Pdist,native ：把重新编译生成的hadoop动态库；</span><br><span class="line">DskipTests ：跳过测试</span><br><span class="line">Dtar ：最后把文件以tar打包</span><br><span class="line">Dbundle.snappy ：添加snappy压缩支持【默认官网下载的是不支持的】</span><br><span class="line">Dsnappy.lib=/usr/local/lib ：指snappy在编译机器上安装后的库路径</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译之后的安装包路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/root/hadoop-3.3.0-src/hadoop-dist/target</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">Hadoop-基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-10 21:10:22" itemprop="dateCreated datePublished" datetime="2021-08-10T21:10:22+08:00">2021-08-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hadoop介绍"><a href="#Hadoop介绍" class="headerlink" title="Hadoop介绍"></a>Hadoop介绍</h1><p>Hadoop是指Apache的一款开源软件，Java实现。它允许用户使用简单的编程模型实现跨机器集群对海量数据进行分布式计算处理。</p>
<h2 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h2><p>HDFS（分布式文件存储系统）：解决海量数据存储</p>
<p>YARN（集群资源管理和任务调度框架）：解决资源调度任务</p>
<p>MapReduce（分布式计算框架）：解决海量数据计算</p>
<h2 id="Hadoop特性"><a href="#Hadoop特性" class="headerlink" title="Hadoop特性"></a>Hadoop特性</h2><ol>
<li><p>scalability（扩容能力）</p>
<p>Hadoop是在可用的计算机集群间分配数据并完成计算任务的，这些集群可方便灵活的方式扩展到数以千计的节点</p>
</li>
<li><p>Economical （成本低）</p>
<p>Hadoop集群允许通过部署普通廉价的机器组成集群来处理大数据，以至于成本很低，看重的集群整体能力</p>
</li>
<li><p>efficiency（效率高）</p>
<p>通过并发数据，Hadoop可以在节点之间动态并行的移动数据，使得速度非常快</p>
</li>
<li><p>reliablility（可靠性）</p>
<p>能自动维护数据的多份复制，并且在任务失败后能自动的重新部署计算任务</p>
</li>
</ol>
<h2 id="Hadoop集群概述"><a href="#Hadoop集群概述" class="headerlink" title="Hadoop集群概述"></a>Hadoop集群概述</h2><p>Hadoop集群包括两个集群：HDFS集群、YARN集群。</p>
<p>两个集群逻辑上分离、通常物理上在一起。它们相互之间没有依赖、互不影响。某些角色进程部署在同一台物理服务器上。</p>
<p>两个集群都是标准的主从架构集群。</p>
<p><img src="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/image-20221212112847844.png" alt="image-20221212112847844"></p>
<p>Hadoop集群 &#x3D; HDFS集群 + YARN集群</p>
<p><img src="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/hdfs-yarn%E9%9B%86%E7%BE%A4.png" alt="hdfs-yarn集群"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/07/14/Spring-Boot-%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/14/Spring-Boot-%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95/" class="post-title-link" itemprop="url">Spring Boot 知识清单</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-14 14:44:55" itemprop="dateCreated datePublished" datetime="2021-07-14T14:44:55+08:00">2021-07-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Spring-Ioc-容器"><a href="#Spring-Ioc-容器" class="headerlink" title="Spring Ioc 容器"></a>Spring Ioc 容器</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/04/15/Android-Jetpack%E4%B9%8BLiveData/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/Android-Jetpack%E4%B9%8BLiveData/" class="post-title-link" itemprop="url">Android Jetpack之LiveData</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-15 09:31:20" itemprop="dateCreated datePublished" datetime="2021-04-15T09:31:20+08:00">2021-04-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="LiveData介绍"><a href="#LiveData介绍" class="headerlink" title="LiveData介绍"></a>LiveData介绍</h4><h5 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h5><p>LiveData是一个重要组件，也是一个同名抽象类。</p>
<blockquote>
<p>LiveData是一种可观察的数据存储器类。与常规的可观察类不同，LiveData具有生命周期感知能力，意指它遵循其他应用组件（如Activity&#x2F;Fragment）的生命周期。这种感知能力可确保LiveData仅更新处于活跃生命周期状态的应用组件观察者。</p>
</blockquote>
<p>解读：     </p>
<ol>
<li>LiveData是一个数据持有者，给源数据包装一层。</li>
<li>源数据使用LiveData包装后，可以被observer观察，数据有更新时observer可感知。</li>
<li>但observer的感知，只发生在（Activity&#x2F;Fragment）活跃生命周期状态（STARTED、RESUMED）。</li>
</ol>
<p>也就是说，<strong>LiveData使得数据的更新能以观察者模式被observer感知，且此感知只发生在LifecycleOwner的活跃生命周期状态</strong>。</p>
<h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><p>使用LiveData具有以下优势：</p>
<ul>
<li><strong>确保界面符合数据状态</strong>，当生命周期状态变化时，LiveData通知Observer，可以在observer中更新界面。观察者可以在生命周期状态更改时刷新界面，而不是在每次数据变化时刷新界面。</li>
<li><strong>不会发生内存泄漏</strong>，observer会在LifecycleOwner状态变为DESTROYED后自动remove。</li>
<li><strong>不会因Activity停止而导致崩溃</strong>，如果LifecycleOwner生命周期处于非活跃状态，则它不会接收任何LiveData事件。</li>
<li><strong>不需要手动解除观察</strong>，开发者不需要在onPause或onDestroy方法中解除对LiveData的观察，因为LiveData能感知生命周期状态变化，所以会自动管理所有这些操作。</li>
<li><strong>数据始终保持最新状态</strong>，数据更新时，若LifecycleOwner为非活跃状态，那么会在变为活跃时接收最新数据。例如，曾经在后台的Activity会在返回前台后，observer立即接收最新的数据。</li>
</ul>
<h4 id="LiveData的使用"><a href="#LiveData的使用" class="headerlink" title="LiveData的使用"></a>LiveData的使用</h4><h5 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h5><p>基本用法：</p>
<ol>
<li>创建LiveData实例，指定源数据类型。</li>
<li>创建Observer实例，实现onChanged()方法，用于接收源数据变化并刷新UI。</li>
<li>LiveData实例使用observe()方法添加观察者，并传入LifecycleOwner。</li>
<li>LiveData实例使用setVale()&#x2F;postVale()更新源数据（子线程要postValue()）。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LiveDataTestActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> MutableLiveData&lt;String&gt; mLiveData;</span><br><span class="line">   </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">       setContentView(R.layout.activity_lifecycle_test);</span><br><span class="line">       </span><br><span class="line">       <span class="comment">//liveData基本使用</span></span><br><span class="line">       mLiveData = <span class="keyword">new</span> <span class="title class_">MutableLiveData</span>&lt;&gt;();</span><br><span class="line">       mLiveData.observe(<span class="built_in">this</span>, <span class="keyword">new</span> <span class="title class_">Observer</span>&lt;String&gt;() &#123;</span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onChanged</span><span class="params">(String s)</span> &#123;</span><br><span class="line">               Log.i(TAG, <span class="string">&quot;onChanged: &quot;</span>+s);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onCreate: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onCreate&quot;</span>);<span class="comment">//activity是非活跃状态，不会回调onChanged。变为活跃时，value被onStart中的value覆盖</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onStart</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onStart();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onStart: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onStart&quot;</span>);<span class="comment">//活跃状态，会回调onChanged。并且value会覆盖onCreate、onStop中设置的value</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onResume</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onResume();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onResume: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onResume&quot;</span>);<span class="comment">//活跃状态，回调onChanged</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onPause</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onPause();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onPause: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onPause&quot;</span>);<span class="comment">//活跃状态，回调onChanged</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onStop</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onStop();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onStop: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onStop&quot;</span>);<span class="comment">//非活跃状态，不会回调onChanged。后面变为活跃时，value被onStart中的value覆盖</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onDestroy</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onDestroy();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onDestroy: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onDestroy&quot;</span>);<span class="comment">//非活跃状态，且此时Observer已被移除，不会回调onChanged</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>注意到 LiveData实例mLiveData的创建是使用MutableLiveData，它是LiveData的实现类，且指定了源数据的类型为String。然后创建了接口Observer的实例，实现其onChanged()方法，用于接收源数据的变化。observer和Activity一起作为参数调用mLiveData的observe()方法，表示observer开始观察mLiveData。然后Activity的所有生命周期方法中都调用了mLiveData的setValue()方法。</p>
<p>另外，除了使用observe()方法添加观察者，也可以使用<strong>observeForever</strong>(Observer) 方法来注册未关联 LifecycleOwner的观察者。在这种情况下，观察者会被视为始终处于活跃状态。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/04/14/Android-Jetpack%E4%B9%8BLifecycle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/14/Android-Jetpack%E4%B9%8BLifecycle/" class="post-title-link" itemprop="url">Android Jetpack之Lifecycle</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-14 13:48:19" itemprop="dateCreated datePublished" datetime="2021-04-14T13:48:19+08:00">2021-04-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="Android-Jepack介绍"><a href="#Android-Jepack介绍" class="headerlink" title="Android Jepack介绍"></a>Android Jepack介绍</h4><blockquote>
<p>Jetpack 是一个由多个库组成的套件，可帮助开发者遵循最佳做法，减少样板代码并编写可在各种Android版本和设备中一致运行的代码，让开发者精力集中编写重要的代码。</p>
</blockquote>
<p>使用Jetpack的好处：</p>
<ul>
<li><strong>遵循最佳做法</strong>，Android Jetpack 组件采用最新的设计方法构建，具有向后兼容性，可以减少崩溃和内存泄露。</li>
<li><strong>消除样本代码</strong>，Android Jetpack 可以管理各种繁琐的 Activity（如后台任务、导航和生命周期管理），以便您可以专注于打造出色的应用。</li>
<li><strong>减少不一致</strong>，这些库可在各种 Android 版本和设备中以一致的方式运作，助您降低复杂性。</li>
</ul>
<h4 id="Lifecycle"><a href="#Lifecycle" class="headerlink" title="Lifecycle"></a>Lifecycle</h4><p>Lifecycle是用来帮助开发者管理Activity和Fragment的生命周期。    </p>
<p>Lifecycle是一个库，它包含Lifecycle类，Lifecycle类用于存储有关组件（如Acitivity或Fragment）的生命周期状态的信息，并允许其他对象观察此状态。   </p>
<p>Lifycycle使用两种主要枚举跟踪其关联组件的生命周期状态：     </p>
<ul>
<li><p>事件     </p>
<p>从框架和Lifecycle类分派的生命周期事件。这些事件映射到Activity和Fragment中的回调事件。        </p>
</li>
<li><p>状态      </p>
<p>由Lifecyle对象跟踪的组件的当前状态</p>
</li>
</ul>
<p><img src="/2021/04/14/Android-Jetpack%E4%B9%8BLifecycle/lifecycle-states.svg" alt="构成 Android Activity 生命周期的状态和事件"></p>
<h5 id="Lifecycle的使用"><a href="#Lifecycle的使用" class="headerlink" title="Lifecycle的使用"></a>Lifecycle的使用</h5><h6 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h6><p>非androidx</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation &quot;android.arch.lifecycle:extensions:1.1.1&quot;</span><br></pre></td></tr></table></figure>



<p>androidx</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    <span class="type">def</span> <span class="variable">lifecycle_version</span> <span class="operator">=</span> <span class="string">&quot;2.3.0&quot;</span></span><br><span class="line">    <span class="type">def</span> <span class="variable">arch_version</span> <span class="operator">=</span> <span class="string">&quot;2.1.0&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// ViewModel</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-viewmodel:$lifecycle_version&quot;</span></span><br><span class="line">    <span class="comment">// LiveData</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-livedata:$lifecycle_version&quot;</span></span><br><span class="line">    <span class="comment">// Lifecycles only (without ViewModel or LiveData)</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-runtime:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Saved state module for ViewModel</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-viewmodel-savedstate:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Annotation processor</span></span><br><span class="line">    annotationProcessor <span class="string">&quot;androidx.lifecycle:lifecycle-compiler:$lifecycle_version&quot;</span></span><br><span class="line">    <span class="comment">// alternately - if using Java8, use the following instead of lifecycle-compiler</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-common-java8:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - helpers for implementing LifecycleOwner in a Service</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-service:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - ProcessLifecycleOwner provides a lifecycle for the whole application process</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-process:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - ReactiveStreams support for LiveData</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-reactivestreams:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - Test helpers for LiveData</span></span><br><span class="line">    testImplementation <span class="string">&quot;androidx.arch.core:core-testing:$arch_version&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看着有很多，实际上如果只使用Lifecycle，只需要引入lifecycle-runtime即可。但通常都是和 ViewModel、 LiveData 配套使用的，所以lifecycle-viewmodel、lifecycle-livedata 一般也会引入。</p>
<h6 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h6><ol>
<li>生命周期拥有者使用getLifecycle()获取Lifecycle实例，然后用addObserve()添加观察者。    </li>
<li>观察者实现LifecycleObserve，方法上用OnLifecycleEvent注解关注对应生命周期，生命周期触发时就会执行对应方法。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyObserver</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">    <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_RESUME)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">connectListener</span><span class="params">()</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_PAUSE)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">disconnectListener</span><span class="params">()</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LifecycleTestActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">        setContentView(R.layout.activity_lifecycle_test);</span><br><span class="line">        <span class="comment">//Lifecycle 生命周期</span></span><br><span class="line">        getLifecycle().addObserver(<span class="keyword">new</span> <span class="title class_">MyObserver</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>Activity（或Fragment）是生命周期的拥有者，通过getLifecycle()方法获取到生命周期Lifecycle对象，Lifecycle对象使用addObserver方法 给自己添加观察者，即MyObserver对象。当Lifecycle的生命周期发生变化时，MyObserver就可以感知到。</p>
<h6 id="MVP架构中的使用"><a href="#MVP架构中的使用" class="headerlink" title="MVP架构中的使用"></a>MVP架构中的使用</h6><p>如果在MVP架构中，可以把presenter作为观察者。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LifecycleTestActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span> <span class="keyword">implements</span> <span class="title class_">IView</span> &#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="type">String</span> <span class="variable">TAG</span> <span class="operator">=</span> <span class="string">&quot;Lifecycle_Test&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">        setContentView(R.layout.activity_lifecycle_test);</span><br><span class="line">        <span class="comment">//Lifecycle 生命周期</span></span><br><span class="line"><span class="comment">//        getLifecycle().addObserver(new MyObserver());</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//MVP中使用Lifecycle</span></span><br><span class="line">        getLifecycle().addObserver(<span class="keyword">new</span> <span class="title class_">MyPresenter</span>(<span class="built_in">this</span>));</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;onCreate: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onResume</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onResume();</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;onResume: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onPause</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onPause();</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;onPause: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">showView</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">hideView</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Presenter</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyPresenter</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TAG</span> <span class="operator">=</span> <span class="string">&quot;Lifecycle_Test&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IView mView;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyPresenter</span><span class="params">(IView view)</span> &#123;mView = view;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnLifecycleEvent(value = Lifecycle.Event.ON_START)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">getDataOnStart</span><span class="params">(LifecycleOwner owner)</span>&#123;</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;getDataOnStart: &quot;</span>);</span><br><span class="line">        </span><br><span class="line">        Util.checkUserStatus(result -&gt; &#123;</span><br><span class="line">                <span class="comment">//checkUserStatus是耗时操作，回调后检查当前生命周期状态</span></span><br><span class="line">                <span class="keyword">if</span> (owner.getLifecycle().getCurrentState().isAtLeast(STARTED)) &#123;</span><br><span class="line">                	start();</span><br><span class="line">                    mView.showView();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@OnLifecycleEvent(value = Lifecycle.Event.ON_STOP)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">hideDataOnStop</span><span class="params">()</span>&#123;</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;hideDataOnStop: &quot;</span>);</span><br><span class="line">        stop();</span><br><span class="line">        mView.hideView();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//IView</span></span><br><span class="line"><span class="keyword">interface</span> <span class="title class_">IView</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">showView</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">hideView</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>这里是让Presenter实现LifecycleObserver接口，同样在方法上注解要触发的生命周期，最后在Activity中作为观察者添加到Lifecycle中。</p>
<p>这样做好处是啥呢？ 当Activity生命周期发生变化时，MyPresenter就可以感知并执行方法，不需要在MainActivity的多个生命周期方法中调用MyPresenter的方法了。</p>
<ul>
<li><strong>所有方法调用操作都由组件本身管理</strong>：Presenter类自动感知生命周期，如果需要在其他的Activity&#x2F;Fragment也使用这个Presenter，只需添加其为观察者即可。</li>
<li><strong>让各个组件存储自己的逻辑，减轻Activity&#x2F;Fragment中代码，更易于管理</strong>；</li>
</ul>
<p>另外，注意到 getDataOnStart()中耗时校验回调后，对当前生命周期状态进行了检查：至少处于STARTED状态才会继续执行start()方法，也就是保证了Activity停止后不会走start()方法；</p>
<h6 id="自定义LifecycleOwner"><a href="#自定义LifecycleOwner" class="headerlink" title="自定义LifecycleOwner"></a>自定义LifecycleOwner</h6><p>在Activity中调用getLifecycle()能获取到Lifecycle实例，getLifecycle()是在接口LifecycleOwner中定义。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 生命周期拥有者</span></span><br><span class="line"><span class="comment"> * 生命周期事件可被 自定义的组件 用来 处理生命周期事件的变化，同时不会在Activity/Fragmen中写任何代码</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">LifecycleOwner</span> &#123;</span><br><span class="line">    <span class="meta">@NonNull</span></span><br><span class="line">    Lifecycle <span class="title function_">getLifecycle</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Support Library 26.1.0及以上、AndroidX的 Fragment 和 Activity 已实现 LifecycleOwner 接口，所以我们在Activity中可以直接使用getLifecycle()。</p>
<p>如果有一个自定义类并希望使其成为LifecycleOwner，可以使用LifecycleRegistry类，它是Lifecycle的实现类，但需要将事件转发到该类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyActivity</span> <span class="keyword">extends</span> <span class="title class_">Activity</span> <span class="keyword">implements</span> <span class="title class_">LifecycleOwner</span> &#123;</span><br><span class="line">       <span class="keyword">private</span> LifecycleRegistry lifecycleRegistry;</span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">           <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line"></span><br><span class="line">           lifecycleRegistry = <span class="keyword">new</span> <span class="title class_">LifecycleRegistry</span>(<span class="built_in">this</span>);</span><br><span class="line">           lifecycleRegistry.markState(Lifecycle.State.CREATED);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onStart</span><span class="params">()</span> &#123;</span><br><span class="line">           <span class="built_in">super</span>.onStart();</span><br><span class="line">           lifecycleRegistry.markState(Lifecycle.State.STARTED);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="meta">@NonNull</span></span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="keyword">public</span> Lifecycle <span class="title function_">getLifecycle</span><span class="params">()</span> &#123;</span><br><span class="line">           <span class="keyword">return</span> lifecycleRegistry;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>MyActivity实现LifecycleOwner，getLifecycle()返回lifecycleRegistry实例。lifecycleRegistry实例则是在onCreate创建，并且在各个生命周期内调用markState()方法完成生命周期事件的传递。这就完成了LifecycleOwner的自定义，也即MyActivity变成了LifecycleOwner，然后就可以和 实现了LifecycleObserver的组件配合使用了。</p>
<p>补充一点，<strong>观察者的方法可以接受一个参数LifecycleOwner</strong>，就可以用来获取当前状态、或者继续添加观察者。 若注解的是ON_ANY还可以接收Event，用于区分是哪个事件。如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">class</span> <span class="title class_">TestObserver</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_CREATE)</span></span><br><span class="line">        <span class="keyword">void</span> <span class="title function_">onCreated</span><span class="params">(LifecycleOwner owner)</span> &#123;</span><br><span class="line"><span class="comment">//            owner.getLifecycle().addObserver(anotherObserver);</span></span><br><span class="line"><span class="comment">//            owner.getLifecycle().getCurrentState();</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_ANY)</span></span><br><span class="line">        <span class="keyword">void</span> <span class="title function_">onAny</span><span class="params">(LifecycleOwner owner, Lifecycle.Event event)</span> &#123;</span><br><span class="line"><span class="comment">//            event.name()</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h6 id="Application生命周期-ProcessLifecycleOwner"><a href="#Application生命周期-ProcessLifecycleOwner" class="headerlink" title="Application生命周期 ProcessLifecycleOwner"></a>Application生命周期 ProcessLifecycleOwner</h6><p>之前对App进入前后台的判断是通过registerActivityLifecycleCallbacks(callback)方法，然后在callback中利用一个全局变量做计数，在onActivityStarted()中计数加1，在onActivityStopped方法中计数减1，从而判断前后台切换。</p>
<p>而使用ProcessLifecycleOwner可以直接获取应用前后台切换状态。（记得先引入lifecycle-process依赖）</p>
<p>使用方式和Activity中类似，只不过要使用ProcessLifecycleOwner.get()获取ProcessLifecycleOwner，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyApplication</span> <span class="keyword">extends</span> <span class="title class_">Application</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onCreate();</span><br><span class="line"></span><br><span class="line">	<span class="comment">//注册App生命周期观察者</span></span><br><span class="line">        ProcessLifecycleOwner.get().getLifecycle().addObserver(<span class="keyword">new</span> <span class="title class_">ApplicationLifecycleObserver</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Application生命周期观察，提供整个应用进程的生命周期</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Lifecycle.Event.ON_CREATE只会分发一次，Lifecycle.Event.ON_DESTROY不会被分发。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 第一个Activity进入时，ProcessLifecycleOwner将分派Lifecycle.Event.ON_START, Lifecycle.Event.ON_RESUME。</span></span><br><span class="line"><span class="comment">     * 而Lifecycle.Event.ON_PAUSE, Lifecycle.Event.ON_STOP，将在最后一个Activit退出后后延迟分发。如果由于配置更改而销毁并重新创建活动，则此延迟足以保证ProcessLifecycleOwner不会发送任何事件。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 作用：监听应用程序进入前台或后台</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ApplicationLifecycleObserver</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_START)</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">onAppForeground</span><span class="params">()</span> &#123;</span><br><span class="line">            Log.w(TAG, <span class="string">&quot;ApplicationObserver: app moved to foreground&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_STOP)</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">onAppBackground</span><span class="params">()</span> &#123;</span><br><span class="line">            Log.w(TAG, <span class="string">&quot;ApplicationObserver: app moved to background&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/02/09/%E5%87%A0%E7%A7%8D%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/09/%E5%87%A0%E7%A7%8D%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/" class="post-title-link" itemprop="url">几种软件开发方法对比</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-02-09 22:16:23" itemprop="dateCreated datePublished" datetime="2021-02-09T22:16:23+08:00">2021-02-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>软件开发方法是一种使用早已定义好的技术集及符号表示习惯来组织软件生产的过程。</p>
<p>本文对净室方法、结构化方法、面向对象方法、原型法、逆向工程等方法进行梳理，并对各种开发方法特点、优点进行对比。</p>
<h1 id="净室方法"><a href="#净室方法" class="headerlink" title="净室方法"></a>净室方法</h1><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>净室软件工程（Cleanroom Software Engineering, CSE)是软件开发的一种形式化方法，可以开发较高质量的软件。它使用盒结构规约进行分析和建模，并且将正确性验证作为发现和排除错误的主要机制，使用统计测试来获取认证软件可靠性所需要的信息。CSE强调在规约和设计上的严格性，还强调统计质量控制技术，包括基于客户对软件的预期使用测试。</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>CSE太理论化，需要更多的数学知识。其正确性验证的步骤比较困难且比较耗时。CSE要求采用<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%A2%9E%E9%87%8F%E5%BC%8F%E5%BC%80%E5%8F%91/5133612">增量式开发</a>、采用盒子结构、采用统计测试方法，普通工程师必须经过加强训练才能掌握。</p>
<p>CSE开发小组不进行传统的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%A8%A1%E5%9D%97%E6%B5%8B%E8%AF%95">模块测试</a>，这是不现实的。工程师可能对编程语言和开发环境还不熟悉，而且编译器或操作系统的bug也可能导致未预期的错误。</p>
<p>CSE毕竟脱胎于传统软件工程，不可避免地带有传统软件工程的一些弊端。</p>
<h1 id="结构化方法"><a href="#结构化方法" class="headerlink" title="结构化方法"></a>结构化方法</h1><h2 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h2><p>结构化方法的主要特点是：开发目标清晰化、开发工作阶段化、开发文档规范化和设计方法结构化。结构化方法特别适合于数据处理领域的问题，但是不适应于规模较大、比较复杂的系统开发。</p>
<p>由结构化分析、结构化设计、结构化程序设计组成，是一种面向数据流的开发方法。</p>
<p>结构化分析是根据分解与抽象的原则，按照系统中数据处理的流程，用数据流图来建立系统的功能类型，从而完成需求分析工作。结构化方法分析模型的核心是数据字典，围绕这个核心，有三个层次的模型，分别是数据模型、功能模型和行为模型（也称为状态模型）。在实际工作中，一般使用E-R图表示数据模型，用DFD表示功能模型，用状态转换图表示行为模型。这三个模型有着密切的关系，它们的建立不具有严格的时序性，而是一个迭代的过程。</p>
<p>结构化设计是根据模块独立性准则、软件结构优化准则将数据流图转换为软件的结构体系，用软件结构图来建立系统的物理模型，实现系统的概要设计。</p>
<p>结构化程序设计使用3种基本控制结构构造程序，任何程序都可以由顺序、选择和重复3种基本控制结构构造。</p>
<p>自顶向下方法是一种决策策略。软件开发涉及作什么决策、如何决策和决策顺序等决策问题。</p>
<p>自顶向下方法在任何时刻所作的决定都是当时对整个设计影响最大的那些决定。如果把所有决定分组或者分级，那么决策顺序是首先作最高级的决定，然后依次地作较低级的决定。同级的决定则按照随机的顺序或者按别的方法。一个决策的级别是看它距离要达到的最终目的（因此是软件的实际实现）的远近程度。从问题本身来看，或是由外(用户所见的）向内（系统的实现）看，以距离实现近的决定为低级决定，远的为高级决定。</p>
<h2 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h2><p>对系统分析和设计人员的要求较高。 </p>
<p>开发周期长，系统复杂，一般属于一种高成本、大投资的工程。</p>
<p>对于大系统而言，自上而下的规划对于下层系统的实施往往缺乏约束力，</p>
<p>从经济角度来看，很难说自顶向下的做法在经济上市合算的。</p>
<h1 id="面向对象方法"><a href="#面向对象方法" class="headerlink" title="面向对象方法"></a>面向对象方法</h1><h2 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h2><p>面向对象方法是系统的描述及信息模型的表示与客观实体相对应，符合人们的思维习惯，有利于系统开发过程中用户与开发人员的交流和沟通，缩短开发周期，提高系统开发的正确性和效率。</p>
<p>面向对象方法包含面向对象分析OOA、面向对象设计OOD、面向对象程序设计OOP。</p>
<p>面向对象的分析模型主要由顶层架构图、用例与用例图、领域概念模型构成。用例建模用来描述待开发系统的功能需求，主要元素是用例和参与者。参与者是指系统以外的，需要使用系统或与系统交互的事物，包括：人或组织、设备、外部系统等，比较隐晦的参与者包括：时间、温度；用例是对系统行为的动态描述，用例获取是需求分析阶段的主要任务之一，用例之间的关系包括：包含、扩展、泛化。</p>
<p>面向对象的设计模型则包含以包图表示的软件体系结构图、以交互图表示的用例实现图、完整精确的类图、针对复杂对象的状态图和用以描述流程化处理过程的活动图等。在面向对象设计中，类可以分为三种类型：实体类、边界类和控制类。类之间的关系包括6种：关联、聚合、组合、依赖、泛化、实现。</p>
<h2 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h2><p>类和继承等特点使得程序会多很多指针操作来定位函数入口和自身要维护虚拟方法表等额外的工作，程序的处理效率相对要低（但程序开发效率高）。</p>
<h1 id="原型法"><a href="#原型法" class="headerlink" title="原型法"></a>原型法</h1><h2 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h2><p>原型是软件系统的初始版本，用来演示概念并尝试设计选择，通常用来发现更多的问题和可能的解决方案。快速迭代式的原型开发能够有效控制成本，根据原型与最终产品之间的关系，原型开发分为三类：抛弃式原型开发利用原型验证和澄清系统的需求描述，重新构造系统：演化式原型开发逐步改进和细化原型，将原型进化直至产生出目标系统；增量式原型开发在建立软件总体设计的基础上，采用增量开发方法，使原型成为最终系统。</p>
<p>以原型开发思想为基础，提出了螺旋模型、敏捷方法等。 </p>
<h2 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h2><p>原型法不适用于开发大型的信息系统；系统难于维护；如果用户合作不好，盲目纠错，会拖延开发进程。</p>
<h1 id="逆向工程"><a href="#逆向工程" class="headerlink" title="逆向工程"></a>逆向工程</h1><h2 id="特点-4"><a href="#特点-4" class="headerlink" title="特点"></a>特点</h2><p>逆向工程与重构工程是目前预防性维护采用的主要技术。所谓软件的逆向工程就是分析已有的程序，寻求比源代码更高级的抽象表现形式。一般认为，凡是在软件生命周期内将软件某种形式的描述转换成更为抽象形式的活动都可称为逆向工程。逆向工程导出的信息可以分为：实现级、结构级、功能级、领域级，信息的抽象级别越高，它与代码的距离就越远，通过逆向工程恢复的难度亦越大，而自动工具支持的可能性相对变小，要求人参与判断和推理的工作增多。</p>
<h1 id="敏捷方法"><a href="#敏捷方法" class="headerlink" title="敏捷方法"></a>敏捷方法</h1><h2 id="Scrum"><a href="#Scrum" class="headerlink" title="Scrum"></a>Scrum</h2><p>Scrum是橄榄球比赛中“争球”的意思，你可以脑补争球时的敏捷、激情和你争我夺。现在Scrum是广泛应用于IT界的一套项目管理工具</p>
<p>Scrum的核心，是把整个项目分成若干个冲刺，每次2-4周，冲完一次再来一次。</p>
<p>Scrum的本质，是把一次漫长的长跑，分割成一段段全力以赴的冲刺，通过一套标准流程方法，提高效率。</p>
<p>Scrum是由三个角色（产品负责人，Scrum Master，团队成员）、四个仪式（冲刺计划会，每日站会，冲刺评审会，冲刺回顾会）和三个物件（产品积压，冲刺积压，燃尽图）组成的一套项目管理方法。</p>
<p>产品负责人，召开冲刺计划会，定下三件事：冲刺目标。定下目标后，把它们从“产品积压”，移入“冲刺积压”。</p>
<p>冲刺方法。选定冲刺方法。</p>
<p>分配任务。团队成员若干人，在6个步骤中，各自主动领取任务。</p>
<p>燃尽，是烧完了的意思。随着时间推移，剩余工作量越来越少。把计划进度，画成一根从左上到右下的直线。然后，把实际进度用红线标在旁边，看着工作量像蜡烛一样，不断燃尽。</p>
<p>冲刺评审会，由主编负责主持，一起审阅最终交付的文章。冲刺回顾会，讨论开始做什么，停止做什么，继续做什么。</p>
<h2 id="极限编程"><a href="#极限编程" class="headerlink" title="极限编程"></a>极限编程</h2><p>XP (Extreme Programming，极限编程)在所有的敏捷型方法中，XP是最引人瞩目的。它源于Smalltalk圈子，特别是Kent Beck和Ward Cunningham在20世纪80年代末的密切合作。XP在一些对费用控制严格的公司中的使用，已经被证明是非常有效的。</p>
<h2 id="水晶方法"><a href="#水晶方法" class="headerlink" title="水晶方法"></a>水晶方法</h2><p>Cockburn的水晶系列方法，水晶系列方法是由AlistairCockburn提出的。它与XP方法一样，都有以人为中心的理念，但在实践上有所不同。Alistair考虑到人们一般很难严格遵循一个纪律约束很强的过程，因此，与XP的高度纪律性不同，Alistair探索了用最少纪律约束而仍能成功的方法，从而在产出效率与易于运作上达到一种平衡。也就是说，虽然水晶系列不如XP那样的产出效率，但会有更多的人能够接受并遵循它。</p>
<h2 id="开源界的开发方法"><a href="#开源界的开发方法" class="headerlink" title="开源界的开发方法"></a>开源界的开发方法</h2><p>开放式源码，这里提到的开放式源码指的是开放源码界所用的一种运作方式。开放式源码项目有一个特别之处，就是程序开发人员在地域上分布很广，这使得它和其他敏捷方法不同，因为一般的敏捷方法都强调项目组成员在同一地点工作。开放源码的一个突出特点就是查错排障(debug)的高度并行性，任何人发现了错误都可将改正源码的“补丁”文件发给维护者。然后由维护者将这些“补丁”或是新增的代码并入源码库。</p>
<h2 id="FDD"><a href="#FDD" class="headerlink" title="FDD"></a>FDD</h2><p>Coad的功用驱动开发方法(FDD-Feature Driven Development)，FDD是由Jeff DeLuca和大师Peter Coad提出来的。像其他方法一样，它致力于短时的迭代阶段和可见可用的功能。在FDD中，一个迭代周期一般是两周。在FDD中，编程开发人员分成两类：首席程序员和“类”程序员(classowner)。首席程序员是最富有经验的开发人员，他们是项目的协调者、设计者和指导者，而“类”程序员则主要做源码编写。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2020/12/12/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/12/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" class="post-title-link" itemprop="url">微服务</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-12 10:11:36" itemprop="dateCreated datePublished" datetime="2020-12-12T10:11:36+08:00">2020-12-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="微服务定义"><a href="#微服务定义" class="headerlink" title="微服务定义"></a>微服务定义</h4><p>微服务架构是一种架构风格和架构思想，它倡导我们在传统软件应用架构的基础上，将系统业务按照功能拆分为更加细粒度的服务，所拆分的每一个服务都是一个独立的应用，这些应用对外提供公共的API，可以独立承担对外服务的职责，通过此种思想方式所开发的软件服务实体就是“微服务”，而围绕着微服务思想构建的一系列体系结构(包括开发、测试、部署等)。</p>
<h5 id="微服务优缺点"><a href="#微服务优缺点" class="headerlink" title="微服务优缺点"></a>微服务优缺点</h5><h6 id="微服务特点一：快速响应需求变化"><a href="#微服务特点一：快速响应需求变化" class="headerlink" title="微服务特点一：快速响应需求变化"></a>微服务特点一：快速响应需求变化</h6><p>采用单体巨型非微服务架构有个问题，系统里面的业务模块非常多，大家一 起发布、修改、编译很难进行协调，很难做到敏捷开发、发 布、上线。</p>
<p>微服务本质上是小微程序，相比较来说，很重要的特点是拆分概念。微服务首先是拆分，把大的拆成小的，把整体拆成部分。每个部分单独开发迭代。</p>
<blockquote>
<p>微服务的优点：拆完以后更灵活，各个子系统可以独立开发、独立测试、独立部署、独立进程，最后再集成。</p>
</blockquote>
<p>独立开发拆分以后自主性更强了，独立开发、独立测试、独立部署、独立进程，是 微服务快速响应业务需求变化的重要特点。</p>
<h6 id="微服务特点二：敏捷开发、敏捷运维DevOps"><a href="#微服务特点二：敏捷开发、敏捷运维DevOps" class="headerlink" title="微服务特点二：敏捷开发、敏捷运维DevOps"></a>微服务特点二：敏捷开发、敏捷运维DevOps</h6><blockquote>
<p>微服务的优点：本质上是拆完以后更好开发。</p>
</blockquote>
<p>总结如下：</p>
<ol>
<li>易于替换；</li>
<li>独立部署；</li>
<li>专注某个任务；</li>
<li>高度解耦；</li>
<li>基于功能进行组织：商品、支付、评论、机票、新闻、酒店、游戏等；</li>
<li>服务可以使用不同的语言、系统、平台；</li>
<li>通信使用语言中立的协议，通常是http；</li>
<li>独立技术栈；</li>
<li>易于测试；</li>
</ol>
<h4 id="微服务Microservice的设计原则"><a href="#微服务Microservice的设计原则" class="headerlink" title="微服务Microservice的设计原则"></a>微服务Microservice的设计原则</h4><blockquote>
<p>需求第一</p>
</blockquote>
<p>一定要以需求为出发点。所有的架构好与坏一定是相对的，相对他处的一个需求背景。因为微服务架构能够在某些业务场景中具备优势，所以它相比传统的架构，他有一些优点但是同时也存在着缺点，它不完美。 </p>
<blockquote>
<p>单一职责</p>
</blockquote>
<p>我们的服务尽量是体现单一职责的思想，粒度不是越细越好，也不是越 粗越好。</p>
<blockquote>
<p>协议统一</p>
</blockquote>
<p>尽量去统一协议，目前的协议主要是 rest。</p>
<blockquote>
<p>独立开发</p>
</blockquote>
<p>独立开发一般咱们这里面提到的我们说的是模块拆分以后开发人员一般是独立我们按照模块进行拆分，然后每个人负责一块，每个人熟悉一块代码和逻辑业务逻辑这样的话开发时间都会相对来说高很多。</p>
<blockquote>
<p>独立部署</p>
</blockquote>
<p>独立部署这也是微服架构的很重要的一个原则，微服务架构拆分以后又会出现可能很多程序很多进程，而且每一个模块不是所有的都更新只需要迭代我那一块就行了，就是体现了我们说叫分而治之的这样一个思想，大家一起统一部署。</p>
<h4 id="微服务Microservice的拆分原则"><a href="#微服务Microservice的拆分原则" class="headerlink" title="微服务Microservice的拆分原则"></a>微服务Microservice的拆分原则</h4><ol>
<li><p>按照业务模块拆分</p>
</li>
<li><p>DDD思路可以借鉴，不能照搬</p>
<p>DDD 本身不是架构设计模式，DDD 是一种但是在向对象设计的一个思想或者原则，它是用来解决复杂业务逻辑的一个拆分问题的，它本身并不解决整个架构层次的问题，它是解决业务层的，理解这一点。</p>
</li>
<li><p>单一职责（Single Responsibility）</p>
</li>
</ol>
<h4 id="微服务设计的关注点"><a href="#微服务设计的关注点" class="headerlink" title="微服务设计的关注点"></a>微服务设计的关注点</h4><ol>
<li>并发性</li>
<li>可用性</li>
<li>安全性</li>
<li>密等性</li>
<li>重用性</li>
</ol>
<h4 id="微服务架构设计的5大考量"><a href="#微服务架构设计的5大考量" class="headerlink" title="微服务架构设计的5大考量"></a>微服务架构设计的5大考量</h4><ol>
<li>微服务拆分</li>
<li>微服务高可用</li>
<li>微数据安全</li>
<li>微服务数据同步</li>
<li>微服务监控</li>
</ol>
<h4 id="微服务的经典设计模式"><a href="#微服务的经典设计模式" class="headerlink" title="微服务的经典设计模式"></a>微服务的经典设计模式</h4><h5 id="微服务架构设计模式"><a href="#微服务架构设计模式" class="headerlink" title="微服务架构设计模式"></a>微服务架构设计模式</h5><ol>
<li>业务分解：DDD模式</li>
<li>DataBase PerService 每数据库单服务</li>
<li>API Gateway pattern API网关模式</li>
<li>Client-side 和 Remote Procedure Invocation 模式</li>
<li>Messaging 和 Procedure Invocation 模式</li>
<li>Single Service per Host 和 Multiple Services per Host 模式</li>
<li>AOP: Microservice chassis pattern</li>
<li>Externalized Configuration</li>
<li>Service Component Test 和 Service Integration Contract Test</li>
<li>Circuit Breaker 断路器模式</li>
<li>Access Token 访问令牌模式</li>
<li>观察者模式： Distributed tracing、 Health check API</li>
<li>UI模式：MVC、MVP、MVVM模式</li>
</ol>
<p><img src="/2020/12/12/%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20210820095240441.png" alt="image-20210820095240441"></p>
<p>如图所示，以微服务架构为中心向外发散，有许多设计模式，正下方有两个，一个叫客户端发现，一个叫服务端发现，服务的注册和发现机制也是一个设计模式，微服架构属于更复杂的分布架构，里面也会用到消息通信，通过消息和数据库、其他微服务进行消息补偿。 </p>
<p>网关的微服务太多，只有一个出口，需要给它同一个代理；安全问题，如图中Access token，和令牌相关的；另外还有高并发的熔断限流，circuit breaker 叫断路器模式，熔断相关，分布式日志、分布式加策、追踪、服务拆分模式、单数据库模式、单实例、单数据库模式多服务共享数据库模式、服务编排模式、统一配置模式等等。</p>
<p>这里主要是分布式架构领域相关的设计模式，还有分布式事务模式，一般用的都是补偿的方式。 </p>
<p>服务拆分的一般借鉴 DDD 模式，但不是照搬，不能完全等同。</p>
<h5 id="微服务设计模式分类"><a href="#微服务设计模式分类" class="headerlink" title="微服务设计模式分类"></a>微服务设计模式分类</h5><h6 id="应用架构模式"><a href="#应用架构模式" class="headerlink" title="应用架构模式"></a>应用架构模式</h6><ol>
<li>单点登录</li>
<li>注册发现</li>
<li>熔断限流</li>
<li>断路器</li>
<li>网关模式</li>
<li>消息补偿模式</li>
<li>令牌模式</li>
</ol>
<h6 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h6><ol>
<li>分库 Single Service</li>
<li>共库多 Service</li>
<li>多库同步</li>
<li>事务性补偿</li>
</ol>
<h6 id="日志追踪模式"><a href="#日志追踪模式" class="headerlink" title="日志追踪模式"></a>日志追踪模式</h6><ol>
<li><p>观察者模式 paterns</p>
</li>
<li><p>Log aggregation</p>
</li>
<li><p>Application metrics</p>
</li>
<li><p>Audit logging</p>
</li>
<li><p>Distributed tracing</p>
</li>
<li><p>Exception tracking</p>
</li>
<li><p>Health check API</p>
</li>
<li><p>Log deployments and changes</p>
</li>
<li><p>分布式链路追踪模式</p>
</li>
</ol>
<h6 id="UI模式"><a href="#UI模式" class="headerlink" title="UI模式"></a>UI模式</h6><ol>
<li>MVC</li>
<li>MVP</li>
<li>MVVM</li>
<li>Server-side page fragment composition</li>
<li>Client-side UI composition</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2020/11/01/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/01/Redis/" class="post-title-link" itemprop="url">Redis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-01 10:10:29" itemprop="dateCreated datePublished" datetime="2020-11-01T10:10:29+08:00">2020-11-01</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Redis（Remote Dictionary Server），即远程字典服务。</p>
<p>redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push&#x2F;pop、add&#x2F;remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。</p>
<p>Redis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/memcached">memcached</a>这类key&#x2F;value存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Java，C&#x2F;C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。 </p>
<p>Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布&#x2F;订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。</p>
<p><code>读的速度是110000次/s,写的速度是81000次/s 。</code></p>
<p><strong>Redis能干嘛？</strong></p>
<p>1、 内存存储、持久化</p>
<p>2、 效率高，可以用于高速存储</p>
<p>3、 法边订阅系统</p>
<p>4、 地图信息分析</p>
<p>5、 计时器、计数器（浏览量）</p>
<p>6、 ……</p>
<p><strong>特性</strong></p>
<p>1、 多样的数据类型</p>
<p>2、 持久化</p>
<p>3、 集群</p>
<p>4、 事务</p>
<p>5、 ……</p>
<h3 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h3><h4 id="Windows安装"><a href="#Windows安装" class="headerlink" title="Windows安装"></a>Windows安装</h4><p>1、下载 <a target="_blank" rel="noopener" href="https://github.com/microsoftarchive/redis/releases">https://github.com/microsoftarchive/redis/releases</a></p>
<p>2、 解压</p>
<p>3、 cmd下执行</p>
<blockquote>
<p>redis-server redis.windows.conf</p>
</blockquote>
<h4 id="Linux安装"><a href="#Linux安装" class="headerlink" title="Linux安装"></a>Linux安装</h4><h5 id="下载Redis"><a href="#下载Redis" class="headerlink" title="下载Redis"></a>下载Redis</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://download.redis.io/releases/redis-6.2.5.tar.gz</span><br></pre></td></tr></table></figure>



<h5 id="解压Redis"><a href="#解压Redis" class="headerlink" title="解压Redis"></a>解压Redis</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf redis-6.2.5.tar.gz </span><br></pre></td></tr></table></figure>



<h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> redis-6.2.5</span><br><span class="line"></span><br><span class="line">make </span><br><span class="line"></span><br><span class="line">make install PREFIX=/usr/bin/redis</span><br></pre></td></tr></table></figure>



<h5 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> /opt/redis-6.2.5/redis.conf /usr/bin/redis/</span><br><span class="line"></span><br><span class="line">vim redis.conf    <span class="comment">#修改daemonize no 改成 yes</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/local/redis/bin</span><br><span class="line"></span><br><span class="line">./redis-server ./redis.conf</span><br><span class="line"></span><br><span class="line">ps -ef |grep redis</span><br></pre></td></tr></table></figure>



<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>1、 Redis默认有16个数据库，默认使用第0个，可以使用select切换数据库</p>
<blockquote>
<p>set key value  #设置key value</p>
<p>get key  #获取key对应的value</p>
<p>keys *   #列出所有keys</p>
<p>DBSIZE  #数量</p>
<p>select #切换数据库</p>
<p>flushdb  #清空数据库</p>
<p>flushall  #清空所有数据库</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name zhangsan</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name1 lisi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name1</span><br><span class="line"><span class="string">&quot;lisi&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) <span class="string">&quot;name1&quot;</span></span><br><span class="line">2) <span class="string">&quot;name&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; select 3</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; keys *</span><br><span class="line">(empty array)</span><br><span class="line">127.0.0.1:6379[3]&gt; DBSIZE</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379[3]&gt; </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ping</span><br><span class="line">PONG</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;name1&quot;</span><br><span class="line">2) &quot;name&quot;</span><br><span class="line">127.0.0.1:6379&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; set x y</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;x&quot;</span><br><span class="line">127.0.0.1:6379&gt; select 3</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379[3]&gt; set a b</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; keys *</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379[3]&gt; flushall</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379[3]&gt; select 0</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>



<blockquote>
<p>Redis是单线程的</p>
</blockquote>
<p>Redis是基于内存操作，CPU不是Redis行能瓶颈，Redis的瓶颈是根据机器的内存和网络带宽</p>
<h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> key1 v1   <span class="comment">#设置值</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get key1</span><br><span class="line"><span class="string">&quot;v1&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; EXISTS key1   <span class="comment">#判断是否存在</span></span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; APPEND key1 <span class="string">&quot;hello&quot;</span>   <span class="comment">#追加字符串</span></span><br><span class="line">(<span class="built_in">integer</span>) 7</span><br><span class="line">127.0.0.1:6379&gt; get key1</span><br><span class="line"><span class="string">&quot;v1hello&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; STRLEN key1    <span class="comment">#获取字符串长度</span></span><br><span class="line">(<span class="built_in">integer</span>) 7</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
