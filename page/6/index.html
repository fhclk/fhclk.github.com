<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="拾荒者">
<meta property="og:url" content="http://fhclk.github.io/page/6/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="fhclk">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fhclk.github.io/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/14/Hadoop-MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/14/Hadoop-MapReduce/" class="post-title-link" itemprop="url">Hadoop-MapReduce</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-14 10:17:09" itemprop="dateCreated datePublished" datetime="2021-08-14T10:17:09+08:00">2021-08-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-13 16:22:30" itemprop="dateModified" datetime="2022-12-13T16:22:30+08:00">2022-12-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分布式计算分而治之思想"><a href="#分布式计算分而治之思想" class="headerlink" title="分布式计算分而治之思想"></a>分布式计算分而治之思想</h1><h2 id="分布式计算"><a href="#分布式计算" class="headerlink" title="分布式计算"></a>分布式计算</h2><p>分布式计算是一种计算方法，它将应用分解成许多小的部分，分配给多台计算机进行处理。从而节约整体计算时间，提高计算效率。</p>
<h2 id="MapReduce思想"><a href="#MapReduce思想" class="headerlink" title="MapReduce思想"></a>MapReduce思想</h2><p>MapReduce思想核心：<strong>先分再合，分而治之</strong>。即把一个复杂的问题，按照一定的“分解”方法分为等价的规模较小的若干部分，然后逐个解决，分别找出各部分的结果，然后把各部分的结果组成整个问题的最终结果。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213101954806.png" alt="image-20221213101954806"></p>
<ul>
<li>Map表示第一阶段，负责“拆分”：即把复杂的任务分解成若干个“简单的子任务”来处理。可以进行拆分的前提是这些小任务可以并行计算，彼此间几乎没有依赖关系。</li>
<li>Reduce表示第二阶段，负责“合并”：即对map阶段的结果进行全局汇总。</li>
<li>这两个阶段合起来就是MapReduce思想的体现。</li>
</ul>
<h2 id="大数据处理场景"><a href="#大数据处理场景" class="headerlink" title="大数据处理场景"></a>大数据处理场景</h2><p>采用MapReduce分而治之策略，首先Map阶段进行拆分，把大数据拆分成若个份小数据，多个程序同时并行计算产生中间结果；然后Reduce聚合阶段，通过程序对并行的结果进行最终的汇总计算，得出最终结果。</p>
<p><strong>不可拆分的计算任务或相互间有依赖关系的数据无法进行并行计算</strong></p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213102715695.png" alt="image-20221213102715695"></p>
<h2 id="构建抽象编程模型"><a href="#构建抽象编程模型" class="headerlink" title="构建抽象编程模型"></a>构建抽象编程模型</h2><ul>
<li><p>MapReduce借鉴了函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型。</p>
<p>map：对一组数据元素进行某种重复式的处理</p>
<p>reduce：对Map的中间结果进行某种进一步的结果处理</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213103050117.png" alt="image-20221213103050117"></p>
</li>
<li><p>MapReduce中定义了如下的Map和Reduce两个抽象的编程接口，由用户去编程实现：</p>
<p>map：（k1; v1) -&gt; (k2; v2)</p>
<p>reduce：(k2: [v2]) -&gt; (k3; v3)</p>
</li>
<li><p>通过以上两个编程接口，可以看出MapReduce处理的数据类型是&lt;key, value&gt;键值对。</p>
</li>
</ul>
<h2 id="统一架构，隐藏底层细节"><a href="#统一架构，隐藏底层细节" class="headerlink" title="统一架构，隐藏底层细节"></a>统一架构，隐藏底层细节</h2><p>MapReduce设计并统一了计算框架，隐藏了绝大多数系统层面的处理细节。</p>
<h1 id="MapReduce介绍"><a href="#MapReduce介绍" class="headerlink" title="MapReduce介绍"></a>MapReduce介绍</h1><p>Hadoop MapReduce是一个分布式计算框架，用于轻松编写分布式应用程序，这些应用程序以可靠，容错的方式并行处理大型硬件集群（多节点）上的大量数据（TB级别）。</p>
<p>MapReduce是一种面向海量数据处理的一种指导思想，也是一种用于大规模数据进行分布式计算的编程模型。</p>
<p><strong>MapReduce特点</strong></p>
<ul>
<li><p>易于编程</p>
<p>提供了用于二次开发的接口</p>
</li>
<li><p>良好的扩展</p>
<p>可以通过增加机器（计算节点）来扩展它的计算能力</p>
</li>
<li><p>高容错性</p>
<p>分布式搭建和部署，当某一个节点出现故障时，可以把上面的任务转移到另一个节点上运行，不影响整个任务。这个过程Hadoop内部完成</p>
</li>
<li><p>适合海量数据的离线处理</p>
<p>可以处理GB、TB、PB级别数据</p>
</li>
</ul>
<p><strong>MapReduce局限性</strong></p>
<ul>
<li>实时计算性能差</li>
<li>不能进行流式计算</li>
</ul>
<h1 id="MapReduce实例进程"><a href="#MapReduce实例进程" class="headerlink" title="MapReduce实例进程"></a>MapReduce实例进程</h1><p>一个完整的MapReduce程序在分布式运行时有三类</p>
<ul>
<li>MRAppMaster：负责整个MR程序的过程调度及状态协调</li>
<li>MapTask：负责map阶段的整个数据处理流程</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213110013345.png" alt="image-20221213110013345"></p>
<h1 id="MapReduce阶段组成"><a href="#MapReduce阶段组成" class="headerlink" title="MapReduce阶段组成"></a>MapReduce阶段组成</h1><ul>
<li>一个MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，或者只有Map阶段。</li>
<li>不能有很多个Map阶段、多个Reduce阶段的情形。</li>
<li>如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序串行运行。</li>
</ul>
<img src="/2021/08/14/Hadoop-MapReduce/image-20221213111404853.png" alt="image-20221213111404853" style="zoom: 80%;">



<h1 id="MapReduce数据类型"><a href="#MapReduce数据类型" class="headerlink" title="MapReduce数据类型"></a>MapReduce数据类型</h1><p>整个MapReduce程序中，数据都是以KV兼职对的形式流转的。</p>
<p>在实际编程解决各种业务问题中，需要考虑每个阶段的输入输出kv分别是什么。</p>
<p>MapReduce中内置了很多默认属性，比如排序、分组等，都和数据的k有关。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213113122471.png" alt="image-20221213113122471"></p>
<h1 id="MapReduce执行流程"><a href="#MapReduce执行流程" class="headerlink" title="MapReduce执行流程"></a>MapReduce执行流程</h1><h2 id="MapReduce整体执行流程图"><a href="#MapReduce整体执行流程图" class="headerlink" title="MapReduce整体执行流程图"></a>MapReduce整体执行流程图</h2><p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213142024380.png" alt="image-20221213142024380"></p>
<h2 id="Map阶段执行流程"><a href="#Map阶段执行流程" class="headerlink" title="Map阶段执行流程"></a>Map阶段执行流程</h2><ul>
<li>第一阶段：把输入目录下文件按照一定的标准逐个进行逻辑切片，形成切片规划。默认Split size &#x3D; Block size （128M），每一个切片由一个MapTask处理。（getSplits）</li>
<li>第二阶段：对切片中的数据按照一定的规则读取解析返回&lt;key, value&gt;对。默认是按行读取数据。key是每一行的起始位置偏移量，value是本行的文本内容。（TextInutFormat）</li>
<li>第三阶段：调用Mapper类中的map方法处理数据。每读取解析出来的一个&lt;key, value&gt;，调用一次map方法。</li>
<li>第四阶段：按照一定的规则对map输出的键值对进行分区partition。默认不分区，因为只有一个reducetask。分区的数量就是reducetask运行的数量。</li>
<li>第五阶段：Map输出数据写入内存缓冲区，达到比例溢出到磁盘上。溢出spill的时候根据key进行排序sort。默认根据key字典排序。</li>
<li>第六阶段：对所有溢出文件进行最终的merge合并，成为一个文件。</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213142808652.png" alt="image-20221213142808652"></p>
<h2 id="Reduce阶段执行流程"><a href="#Reduce阶段执行流程" class="headerlink" title="Reduce阶段执行流程"></a>Reduce阶段执行流程</h2><ul>
<li>第一阶段：ReduceTask会主动从MapTask复制拉取属于需要自己处理的数据。</li>
<li>第二阶段：把拉取来的数据，全部进行merge合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</li>
<li>第三阶段：对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法。最后把这些输出的键值对写入到HDFS文件中。</li>
</ul>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213143229439.png" alt="image-20221213143229439"></p>
<h2 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h2><h3 id="shuffle概念"><a href="#shuffle概念" class="headerlink" title="shuffle概念"></a>shuffle概念</h3><p>Shuffle的本意是洗牌、混洗的意思，把一组有规则地数据尽量打乱成无规则地数据。</p>
<p>在MapReduce中，Shuffle更像是洗牌的逆过程，指的是将map端的无规则输出按指定的规则“打乱”成具有一定规则的数据，以便reduce端接收处理。</p>
<p>一般把从Map产生输出开始到Reduce取得数据作为输入之前的过程称之为shuffle。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213144448734.png" alt="image-20221213144448734"></p>
<h3 id="Map端Shuffle"><a href="#Map端Shuffle" class="headerlink" title="Map端Shuffle"></a>Map端Shuffle</h3><p>Collect阶段：将MapTask的结果收集输出到默认大小为100M的环形缓冲区，保存之前会对key进行分区的计算，默认Hash分区。</p>
<p>Spill阶段：当内存的数据达到一定的阈值的时候，就会将数据写入磁盘，在将数据写入磁盘之前需要对数据进行一次排序的操作，如果配置了combiner，还会将有相同分区号和key的数据进行排序。</p>
<p>Merge阶段：把所有溢出的文件进行一次合并操作，以确保一个MapTask最终只产生一个中间数据文件。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213144901309.png" alt="image-20221213144901309"></p>
<h3 id="Reduce端Shuffle"><a href="#Reduce端Shuffle" class="headerlink" title="Reduce端Shuffle"></a>Reduce端Shuffle</h3><p>Copy阶段：ReduceTask启动Fetcher线程到已经完成MapTask的节点上复制一份属于自己的数据。</p>
<p>Merge阶段：在ReduceTask远程复制数据的同时，会在后台开启两个线程对内存到本地的数据文件进行合并操作。</p>
<p>Sort阶段：在对数据进行合并的同时，会进行排序操作，由于MapTask阶段已经对数据进行了局部的排序，ReduceTask只需保证Copy的数据的最终整体有效性即可。</p>
<p><img src="/2021/08/14/Hadoop-MapReduce/image-20221213145258144.png" alt="image-20221213145258144"></p>
<h3 id="shuffle机制弊病"><a href="#shuffle机制弊病" class="headerlink" title="shuffle机制弊病"></a>shuffle机制弊病</h3><p>Shuffle是MapReduce成的核心与精髓，是MapReduce的灵魂所在。</p>
<p>Shuffle也是MapReduce被诟病最多的地方。MapReduce相比较于Spark、Flink计算引擎慢的原因，根Shuffle机制有很大的关系。Shuffle频繁涉及到数据在内存、磁盘之间的多次往复。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/13/Hadoop-HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/13/Hadoop-HDFS/" class="post-title-link" itemprop="url">Hadoop-HDFS</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-13 10:07:09" itemprop="dateCreated datePublished" datetime="2021-08-13T10:07:09+08:00">2021-08-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-22 11:57:30" itemprop="dateModified" datetime="2022-12-22T11:57:30+08:00">2022-12-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>数据</strong>：指存储的内容本身，比如文件、视频、图片等，这些数据底层最终是存储在磁盘等存储介质上的，一般用户无需关心，只需要基于目录树进行增删改查即可，实际针对数据的操作有文件系统完成。</p>
<p><strong>元数据</strong>：</p>
<p>元数据（metadata）又称之为解释性数据，记录数据的数据。</p>
<p>文件系统元数据一般指文件大小、最后修改时间、底层存储位置、属性、所属用户、权限等信息。</p>
<h2 id="分布式存储系统核心属性"><a href="#分布式存储系统核心属性" class="headerlink" title="分布式存储系统核心属性"></a>分布式存储系统核心属性</h2><ul>
<li><p>分布式存储</p>
<p>问题：数据量大，单机存储遇到瓶颈。</p>
<p>解决：</p>
<p>单机纵向扩展：增加磁盘</p>
<p>多机横向扩展：增加机器</p>
</li>
<li><p>元数据记录</p>
<p>问题：文件分布在不同机器上不利于查找</p>
<p>解决：</p>
<p>元数据记录下文件及其存储位置信息（文件名、大小、存储机器IP），快速定位文件位置</p>
</li>
<li><p>分块机制</p>
<p>问题：文件过大导致单机存不下、上传下载效率低</p>
<p>解决：文件分块存储在不同的机器，针对块并行操作提高效率</p>
</li>
<li><p>副本机制</p>
<p>问题：硬件出现故障，输入容易丢失</p>
<p>解决：不同机器设置备份，冗余存储，保障数据安全</p>
</li>
</ul>
<h1 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h1><p>HDFS（Hadoop Distributed File System），Hadoop分布式文件系统，其主要是解决大数据如何存储问题，适于存储大型数据（TB和PB），它使用多台计算机存储文件，并且提供统一的访问接口，像访问一个普通文件系统一样使用分布式文件系统。</p>
<h2 id="HDFS应用场景"><a href="#HDFS应用场景" class="headerlink" title="HDFS应用场景"></a>HDFS应用场景</h2><p>适合场景：</p>
<p>大文件、数据流式访问、一次写入多次读取、低成本部署（廉价PC）、高容错</p>
<p>不适合场景：</p>
<p>小文件、数据交互式访问、频繁任意修改、低延迟处理</p>
<h2 id="HDFS重要特性"><a href="#HDFS重要特性" class="headerlink" title="HDFS重要特性"></a>HDFS重要特性</h2><ul>
<li>主从架构</li>
<li>分块存储</li>
<li>副本机制</li>
<li>元数据记录</li>
<li>抽象统一的目录树结构（namespace）</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212155509725.png" alt="image-20221212155509725"></p>
<h3 id="主从架构"><a href="#主从架构" class="headerlink" title="主从架构"></a>主从架构</h3><ul>
<li>HDFS集群是标准的master&#x2F;slave主从架构集群</li>
<li>一般一个HDFS集群是有一个Namenode和一定数目的Datanode组成</li>
<li>Namenode是HDFS主节点，Datanode是HDFS从节点，两种角色各司其职，共同协调完成分布式的文件存储服务</li>
</ul>
<h3 id="分块存储"><a href="#分块存储" class="headerlink" title="分块存储"></a>分块存储</h3><ul>
<li>HDFS中的文件在物理上是分块存储（block）的，默认大小是128M，不足128M则本身就是一块。</li>
<li>块的大小可以通过配置参数来规定，参数位于hdfs-default.xml中： dfs.blocksize</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212160026689.png" alt="image-20221212160026689"></p>
<h3 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h3><ul>
<li>文件的所有block都会有副本。副本系数可以在文件创建的时候指定，也可以在之后通过命令改变</li>
<li>副本数由参数dfs.replication控制，默认是3，也就是会额外再复制2份，连同本身供3份</li>
</ul>
<h3 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h3><p>HDFS中，Namenode管理的元数据有两种类型：</p>
<p><strong>文件自身属性信息</strong></p>
<p>文件名称、权限、修改时间、文件大小、复制因子、数据块大小</p>
<p><strong>文件块位置映射信息</strong></p>
<p>记录文件块和DataNode之间的映射信息，即那块位于哪个节点上。</p>
<h3 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h3><p>HDFS支持传统的层次型文件组织结构。用户可以创建目录，然后将文件保存在这些目录里，文件系统名字空间的层次结构和大多数现有的文件系统类似，用户可以创建、修改、移动或重命名文件。</p>
<p>Namenode负责维护文件系统的namespace名称空间，任何文件系统名称空间或属性的修改都将被Namenode记录下来。</p>
<p>HDFS会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs:&#x2F;&#x2F;namenode:port&#x2F;dir&#x2F;file.data</p>
<h3 id="数据块存储"><a href="#数据块存储" class="headerlink" title="数据块存储"></a>数据块存储</h3><p>文件的各个block的具体存储管理由Datanode节点承担。</p>
<p>每一个block都可以在多个Datanode上存储。</p>
<h1 id="HDFS-shell"><a href="#HDFS-shell" class="headerlink" title="HDFS shell"></a>HDFS shell</h1><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs [generic options]</span><br></pre></td></tr></table></figure>



<h2 id="文件系统协议"><a href="#文件系统协议" class="headerlink" title="文件系统协议"></a>文件系统协议</h2><p>本地文件系统： file:&#x2F;&#x2F;&#x2F;</p>
<p>分布式文件系统： hdfs:&#x2F;&#x2F;&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls file:/// #操作本地文件系统</span><br><span class="line">hadoop fs -ls hdfs:///node1:8020/  #操作HDFS分布式文件系统</span><br><span class="line">hadoop hs -ls / #直接根目录，没有指定协议，将加载fs.defaultFS值</span><br></pre></td></tr></table></figure>



<p>hdfs dfs 只能操作HDFS文件系统相关（包括Local FS间的操作），常用。</p>
<p>hadoop fs可操作任意文件系统，不仅仅是hdfs文件系统，适用范围更广。</p>
<h1 id="HDFS工作流程与机制"><a href="#HDFS工作流程与机制" class="headerlink" title="HDFS工作流程与机制"></a>HDFS工作流程与机制</h1><h2 id="HDFS集群角色与职责"><a href="#HDFS集群角色与职责" class="headerlink" title="HDFS集群角色与职责"></a>HDFS集群角色与职责</h2><h3 id="主角色：namenode"><a href="#主角色：namenode" class="headerlink" title="主角色：namenode"></a>主角色：namenode</h3><p>NameNode是Hadoop分布式文件系统的核心，架构中的主角色。</p>
<p>NameNode维护和管理文件系统元数据，包括名称空间目录树结构、文件和块的位置信息、访问权限等信息。</p>
<p>NameNode成为了访问HDFS的唯一入口。</p>
<p>NameNode内部通过内存和磁盘文件两种方式管理元数据。</p>
<p>其中磁盘上的元数据文件包括Fsimage内存元数据镜像文件和edits log（Journal）编辑日志。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212162816232.png" alt="image-20221212162816232"></p>
<h3 id="从角色：datanode"><a href="#从角色：datanode" class="headerlink" title="从角色：datanode"></a>从角色：datanode</h3><p>DataNode具体负责数据块存储。</p>
<p>DataNode的数量决定了HDFS集群的整体数据存储能力。通过和NameNode配合维护着数据块。</p>
<h3 id="主角色辅助角色：secondarynamenode"><a href="#主角色辅助角色：secondarynamenode" class="headerlink" title="主角色辅助角色：secondarynamenode"></a>主角色辅助角色：secondarynamenode</h3><p>SecondaryNameNode充当NameNode的辅助节点，但不能替代NameNode。</p>
<p>主要是帮助主角色进行元数据文件的合并动作。</p>
<h3 id="namenode职责"><a href="#namenode职责" class="headerlink" title="namenode职责"></a>namenode职责</h3><p>NameNode仅存储HDFS的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件，不存储实际数据。</p>
<p>NameNode知道HDFS中任何给定文件的快列表及其位置。使用此信息NameNode知道如何从块中构建文件。</p>
<p>NameNode不持久化存储每个文件中各个块所在的datanode的位置信息，这些信息会在系统启动时从DataNode重建。</p>
<p>NameNode是Hadoop集群中的单点故障。</p>
<p>NameNode所在机器通常会配置有大量内存（RAM）</p>
<h3 id="datanode职责"><a href="#datanode职责" class="headerlink" title="datanode职责"></a>datanode职责</h3><p>DataNode负责最终数据块block的存储。是集群的从角色，也称为Slave。</p>
<p>DataNode启动时，会将自己注册到NameNode并汇报自己负责持有的块列表。</p>
<p>当某个DataNode关闭时，不会影响数据的可用性。NameNode将安排由其他DataNode管理的块进行副本复制。</p>
<p>DataNode所在机器通常配置有大量的硬盘空间，因为实际数据存储在DataNode中。</p>
<h2 id="HDFS写数据流程（上传文件）"><a href="#HDFS写数据流程（上传文件）" class="headerlink" title="HDFS写数据流程（上传文件）"></a>HDFS写数据流程（上传文件）</h2><h3 id="Pipeline管道"><a href="#Pipeline管道" class="headerlink" title="Pipeline管道"></a>Pipeline管道</h3><p>Pipeline是HDFS在上传文件写数据过程中采用的一种数据传输方式。</p>
<p>客户端将数据写入第一个数据节点，第一个数据节点保存数据之后再将块复制到第二个数据节点，后者保存后将其复制到第三个数据节点。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212230023760.png" alt="image-20221212230023760"></p>
<p>数据以管道的方式，顺序的沿着一个方向传输，这样能够充分利用每个机器的带宽，避免网络瓶颈和高延迟时的连接，最小化推送所有数据的延时。</p>
<p>在线性推送模式下，每台机器所有的出口带宽都用于以最快的速度传输数据，而不是在多个接受者之间分配带宽。</p>
<h3 id="ACK应答响应"><a href="#ACK应答响应" class="headerlink" title="ACK应答响应"></a>ACK应答响应</h3><p>ACK（Acknowledge character）即是确认字符，在数据通信中，接收方发送给发送方的一种传输类控制字符。表示发来的数据已确认接收无误。</p>
<p>在HDFS pipeline管道传输数据的过程中，传输的反方向会进行ACK校验，确保数据传输安全。</p>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212230559137.png" alt="image-20221212230559137"></p>
<h3 id="默认3副本存储策略"><a href="#默认3副本存储策略" class="headerlink" title="默认3副本存储策略"></a>默认3副本存储策略</h3><p>默认副本存储策略是由BlockPlacementPolicyDefault指定。</p>
<ul>
<li>第一块副本：优先客户端本地，否则随机</li>
<li>第二块副本：不同于第一块副本的不同机架</li>
<li>第三块副本：第二块副本相同机架不通过机器</li>
</ul>
<p><img src="/2021/08/13/Hadoop-HDFS/image-20221212232028347.png" alt="image-20221212232028347"></p>
<h3 id="写数据完整流程图"><a href="#写数据完整流程图" class="headerlink" title="写数据完整流程图"></a>写数据完整流程图</h3><p><img src="/2021/08/13/Hadoop-HDFS/image-20221212225725826.png" alt="image-20221212225725826"></p>
<h3 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h3><ol>
<li>HDFS客户端创建对象实例DistributedFileSystem，该对象中封装了与HDFS文件系统操作相关的方法。</li>
<li>调用DistributedFileSystem对象的create()方法，通过RPC请求NameNode创建文件。NameNode执行各种检查判断：目标文件是否存在、父目录是否存在、客户端是否具有创建该文件的权限。检查通过，NameNode就会为本次请求记下一条记录，返回FSDataOutputStream输出流对象给客户端用于写数据。</li>
<li>客户端通过FSDataOutputStream输出流开始写入数据。</li>
<li>客户端写入数据时，将数据分成一个个数据包（packet默认64K），内部组件DataStreamer请求NameNode挑选出适合存储数据副本的一组DataNode地址，默认是3副本存储。DataStreamer将数据包流式传输到pipeline的第一个DataNode，该DataNode存储数据包并将它们发送到pipeline的第二个DataNode。同样，第二个DataNode存储数据包并且发送给第三个DataNode。</li>
<li>传输的反方向上，会通过ACK机制校验数据包传输是否成功。</li>
<li>客户端完成数据写入后，在FSDataOutputStream输出流上调用close()方法关闭。</li>
<li>DistributedFileSystem联系NameNode告知其文件写入完成，等待NameNode确认。因为NameNode已经知道文件是由哪些块组成（DataStream请求分配数据块），因此仅需等待最小复制块即可成功返回。最小复制是由参数dfs.namenode.replication.min指定，默认是1。</li>
</ol>
<h2 id="HDFS读数据流程（下载文件）"><a href="#HDFS读数据流程（下载文件）" class="headerlink" title="HDFS读数据流程（下载文件）"></a>HDFS读数据流程（下载文件）</h2><h3 id="读数据完整流程图"><a href="#读数据完整流程图" class="headerlink" title="读数据完整流程图"></a>读数据完整流程图</h3><p><img src="/2021/08/13/Hadoop-HDFS/image-20221213094517559.png" alt="image-20221213094517559"></p>
<h3 id="读数据流程"><a href="#读数据流程" class="headerlink" title="读数据流程"></a>读数据流程</h3><ol>
<li>HDFS客户端创建对象实例DistributedFileSystem，调用该对象的open()方法来打开希望读取的文件。</li>
<li>DistributedFileSystem使用RPC调用namenode来确定文件中前几块的块位置（分批次读取）信息。对于每个块，namenode返回具体有该模块所有副本的datanode位置地址列表，并且该地址列表是排序好的，与客户端的网络拓扑距离近的排序靠前。</li>
<li>DistributedFileSystem将FSDataInputStream输入流返回到客户端以供其读取数据。</li>
<li>客户端在FSDataInputStream输入流上调用read()方法。然后，已存储DataNode地址的InputStream连接到文件中第一个块的最近的DataNode。数据从DataNode流回客户端，结果客户端可以在流上重复调用read()。</li>
<li>当该块结束时，FSDataInputStream将关闭与DataNode的连接，然后寻找下一个block块的最佳datanode位置。这些操作对用户来说是透明的。所以用户感觉起来它一直在读取一个连续的流。客户端从流中读取数据时，也会根据需要询问NameNode来检索下一批数据块的DataNode位置信息。</li>
<li>一旦客户端完成读取，就对FSDataInputStream调用close()方法。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/12/Hadoop-%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/12/Hadoop-%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">Hadoop-部署</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-12 11:13:02" itemprop="dateCreated datePublished" datetime="2021-08-12T11:13:02+08:00">2021-08-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-29 14:13:55" itemprop="dateModified" datetime="2023-01-29T14:13:55+08:00">2023-01-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>操作系统：Centos 7.7</p>
<p>安装目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /export/server</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Hadoop集群分布式安装"><a href="#Hadoop集群分布式安装" class="headerlink" title="Hadoop集群分布式安装"></a>Hadoop集群分布式安装</h1><h2 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h2><table>
<thead>
<tr>
<th>主机</th>
<th>角色</th>
</tr>
</thead>
<tbody><tr>
<td>node1</td>
<td>NN    DN   RM  NM</td>
</tr>
<tr>
<td>node2</td>
<td>SNN  DN           NM</td>
</tr>
<tr>
<td>node3</td>
<td>DN          NM</td>
</tr>
</tbody></table>
<h2 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h2><blockquote>
<p>3台机器都需要操作</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">主机名</span> </span><br><span class="line">cat /etc/hostname</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hosts映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.88.151 node1.itcast.cn node1</span><br><span class="line">192.168.88.152 node2.itcast.cn node2</span><br><span class="line">192.168.88.153 node3.itcast.cn node3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JDK 1.8安装  上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下</span></span><br><span class="line">cd /export/server/</span><br><span class="line">tar zxvf jdk-8u241-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">	</span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="meta prompt_">	</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新加载环境变量文件</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">集群时间同步</span></span><br><span class="line">ntpdate ntp5.aliyun.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">防火墙关闭</span></span><br><span class="line">firewall-cmd --state	#查看防火墙状态</span><br><span class="line">systemctl stop firewalld.service  #停止firewalld服务</span><br><span class="line">systemctl disable firewalld.service  #开机禁用firewalld服务</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh免密登录（只需要配置node1至node1、node2、node3即可）</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">node1生成公钥私钥 (一路回车)</span></span><br><span class="line">ssh-keygen  </span><br><span class="line"><span class="meta prompt_">	</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">node1配置免密登录到node1 node2 node3</span></span><br><span class="line">ssh-copy-id node1</span><br><span class="line">ssh-copy-id node2</span><br><span class="line">ssh-copy-id node3</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><p>上传Hadoop安装包到node1 &#x2F;export&#x2F;server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</span><br></pre></td></tr></table></figure>



<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>修改配置文件(配置文件路径 hadoop-3.3.0&#x2F;etc&#x2F;hadoop)</p>
<ul>
<li><p>hadoop-env.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件最后添加</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line"></span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root </span><br></pre></td></tr></table></figure>
</li>
<li><p>core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置Hadoop本地保存数据路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/data/hadoop-3.3.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS web UI用户身份 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 整合hive 用户代理设置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 文件系统垃圾桶保存时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node2:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施物理内存限制 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn历史服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node1:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史日志保存的时间 7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>workers</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node1.itcast.cn</span><br><span class="line">node2.itcast.cn</span><br><span class="line">node3.itcast.cn</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="同步到node2和node3节点"><a href="#同步到node2和node3节点" class="headerlink" title="同步到node2和node3节点"></a>同步到node2和node3节点</h2><p>分发同步hadoop安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server</span><br><span class="line"></span><br><span class="line">scp -r hadoop-3.3.0 root@node2:$PWD</span><br><span class="line">scp -r hadoop-3.3.0 root@node3:$PWD</span><br></pre></td></tr></table></figure>



<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>将hadoop添加到环境变量（3台机器）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop-3.3.0</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">别忘了scp给其他两台机器哦</span></span><br></pre></td></tr></table></figure>



<h2 id="Hadoop集群启动"><a href="#Hadoop集群启动" class="headerlink" title="Hadoop集群启动"></a>Hadoop集群启动</h2><ul>
<li><p>（&#x3D;&#x3D;首次启动&#x3D;&#x3D;）格式化namenode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>脚本一键启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# start-dfs.sh </span><br><span class="line">Starting namenodes on [node1]</span><br><span class="line">Last login: Thu Nov  5 10:44:10 CST 2020 on pts/0</span><br><span class="line">Starting datanodes</span><br><span class="line">Last login: Thu Nov  5 10:45:02 CST 2020 on pts/0</span><br><span class="line">Starting secondary namenodes [node2]</span><br><span class="line">Last login: Thu Nov  5 10:45:04 CST 2020 on pts/0</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# start-yarn.sh </span><br><span class="line">Starting resourcemanager</span><br><span class="line">Last login: Thu Nov  5 10:45:08 CST 2020 on pts/0</span><br><span class="line">Starting nodemanagers</span><br><span class="line">Last login: Thu Nov  5 10:45:44 CST 2020 on pts/0</span><br></pre></td></tr></table></figure>
</li>
<li><p>Web  UI页面</p>
<ul>
<li>HDFS集群：<a target="_blank" rel="noopener" href="http://node1:9870/">http://node1:9870/</a></li>
<li>YARN集群：<a target="_blank" rel="noopener" href="http://node1:8088/">http://node1:8088/</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>运行hadoop3官方自带mr示例出错。</p>
<ul>
<li><p>错误信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</span><br><span class="line"></span><br><span class="line">Please check whether your etc/hadoop/mapred-site.xml contains the below configuration:</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;full path of your hadoop distribution directory&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>解决  mapred-site.xml,增加以下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h1 id="Hadoop编译安装（了解）"><a href="#Hadoop编译安装（了解）" class="headerlink" title="Hadoop编译安装（了解）"></a>Hadoop编译安装（了解）</h1><ul>
<li><p>安装编译相关的依赖</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install gcc gcc-c++ make autoconf automake libtool curl lzo-devel zlib-devel openssl openssl-devel ncurses-devel snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop libXtst zlib -y</span><br><span class="line"></span><br><span class="line">yum install -y doxygen cyrus-sasl* saslwrapper-devel*</span><br></pre></td></tr></table></figure>
</li>
<li><p>手动安装cmake </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">yum卸载已安装cmake 版本低</span></span><br><span class="line">yum erase cmake</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar zxvf CMake-3.19.4.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/CMake-3.19.4</span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证</span></span><br><span class="line">[root@node4 ~]# cmake -version</span><br><span class="line">cmake version 3.19.4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果没有正确显示版本 请断开SSH连接 重写登录</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>手动安装snappy</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载已经安装的</span></span><br><span class="line"></span><br><span class="line">rm -rf /usr/local/lib/libsnappy*</span><br><span class="line">rm -rf /lib64/libsnappy*</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传解压</span></span><br><span class="line">tar zxvf snappy-1.1.3.tar.gz </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/snappy-1.1.3</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装</span></span><br><span class="line">[root@node4 snappy-1.1.3]# ls -lh /usr/local/lib |grep snappy</span><br><span class="line">-rw-r--r-- 1 root root 511K Nov  4 17:13 libsnappy.a</span><br><span class="line">-rwxr-xr-x 1 root root  955 Nov  4 17:13 libsnappy.la</span><br><span class="line">lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so -&gt; libsnappy.so.1.3.0</span><br><span class="line">lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so.1 -&gt; libsnappy.so.1.3.0</span><br><span class="line">-rwxr-xr-x 1 root root 253K Nov  4 17:13 libsnappy.so.1.3.0</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装配置JDK 1.8</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压安装包</span></span><br><span class="line">tar zxvf jdk-8u65-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">java -version</span><br><span class="line"></span><br><span class="line">java version &quot;1.8.0_241&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_241-b07)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装配置maven</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压安装包</span></span><br><span class="line">tar zxvf apache-maven-3.5.4-bin.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export MAVEN_HOME=/export/server/apache-maven-3.5.4</span><br><span class="line">export MAVEN_OPTS=&quot;-Xms4096m -Xmx4096m&quot;</span><br><span class="line">export PATH=:$MAVEN_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">[root@node4 ~]# mvn -v</span><br><span class="line">Apache Maven 3.5.4</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加maven 阿里云仓库地址 加快国内编译速度</span></span><br><span class="line">vim /export/server/apache-maven-3.5.4/conf/settings.xml</span><br><span class="line"></span><br><span class="line">&lt;mirrors&gt;</span><br><span class="line">     &lt;mirror&gt;</span><br><span class="line">           &lt;id&gt;alimaven&lt;/id&gt;</span><br><span class="line">           &lt;name&gt;aliyun maven&lt;/name&gt;</span><br><span class="line">           &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;</span><br><span class="line">           &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</span><br><span class="line">      &lt;/mirror&gt;</span><br><span class="line">&lt;/mirrors&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装ProtocolBuffer 3.7.1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载之前版本的protobuf</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar zxvf protobuf-3.7.1.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译安装</span></span><br><span class="line">cd /export/server/protobuf-3.7.1</span><br><span class="line">./autogen.sh</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">验证是否安装成功</span></span><br><span class="line">[root@node4 protobuf-3.7.1]# protoc --version</span><br><span class="line">libprotoc 3.7.1</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传解压源码包</span></span><br><span class="line">tar zxvf hadoop-3.3.0-src.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">编译</span></span><br><span class="line">cd /root/hadoop-3.3.0-src</span><br><span class="line"></span><br><span class="line">mvn clean package -Pdist,native -DskipTests -Dtar -Dbundle.snappy -Dsnappy.lib=/usr/local/lib</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">参数说明：</span></span><br><span class="line"></span><br><span class="line">Pdist,native ：把重新编译生成的hadoop动态库；</span><br><span class="line">DskipTests ：跳过测试</span><br><span class="line">Dtar ：最后把文件以tar打包</span><br><span class="line">Dbundle.snappy ：添加snappy压缩支持【默认官网下载的是不支持的】</span><br><span class="line">Dsnappy.lib=/usr/local/lib ：指snappy在编译机器上安装后的库路径</span><br></pre></td></tr></table></figure>
</li>
<li><p>编译之后的安装包路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/root/hadoop-3.3.0-src/hadoop-dist/target</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">Hadoop-基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-08-10 21:10:22" itemprop="dateCreated datePublished" datetime="2021-08-10T21:10:22+08:00">2021-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-29 13:53:58" itemprop="dateModified" datetime="2023-01-29T13:53:58+08:00">2023-01-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hadoop介绍"><a href="#Hadoop介绍" class="headerlink" title="Hadoop介绍"></a>Hadoop介绍</h1><p>Hadoop是指Apache的一款开源软件，Java实现。它允许用户使用简单的编程模型实现跨机器集群对海量数据进行分布式计算处理。</p>
<h2 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h2><p>HDFS（分布式文件存储系统）：解决海量数据存储</p>
<p>YARN（集群资源管理和任务调度框架）：解决资源调度任务</p>
<p>MapReduce（分布式计算框架）：解决海量数据计算</p>
<h2 id="Hadoop特性"><a href="#Hadoop特性" class="headerlink" title="Hadoop特性"></a>Hadoop特性</h2><ol>
<li><p>scalability（扩容能力）</p>
<p>Hadoop是在可用的计算机集群间分配数据并完成计算任务的，这些集群可方便灵活的方式扩展到数以千计的节点</p>
</li>
<li><p>Economical （成本低）</p>
<p>Hadoop集群允许通过部署普通廉价的机器组成集群来处理大数据，以至于成本很低，看重的集群整体能力</p>
</li>
<li><p>efficiency（效率高）</p>
<p>通过并发数据，Hadoop可以在节点之间动态并行的移动数据，使得速度非常快</p>
</li>
<li><p>reliablility（可靠性）</p>
<p>能自动维护数据的多份复制，并且在任务失败后能自动的重新部署计算任务</p>
</li>
</ol>
<h2 id="Hadoop集群概述"><a href="#Hadoop集群概述" class="headerlink" title="Hadoop集群概述"></a>Hadoop集群概述</h2><p>Hadoop集群包括两个集群：HDFS集群、YARN集群。</p>
<p>两个集群逻辑上分离、通常物理上在一起。它们相互之间没有依赖、互不影响。某些角色进程部署在同一台物理服务器上。</p>
<p>两个集群都是标准的主从架构集群。</p>
<p><img src="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/image-20221212112847844.png" alt="image-20221212112847844"></p>
<p>Hadoop集群 &#x3D; HDFS集群 + YARN集群</p>
<p><img src="/2021/08/10/Hadoop%E5%9F%BA%E7%A1%80/hdfs-yarn%E9%9B%86%E7%BE%A4.png" alt="hdfs-yarn集群"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/07/14/Spring-Boot-%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/14/Spring-Boot-%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95/" class="post-title-link" itemprop="url">Spring Boot 知识清单</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-07-14 14:44:55" itemprop="dateCreated datePublished" datetime="2021-07-14T14:44:55+08:00">2021-07-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-14 16:43:15" itemprop="dateModified" datetime="2021-08-14T16:43:15+08:00">2021-08-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Spring-Ioc-容器"><a href="#Spring-Ioc-容器" class="headerlink" title="Spring Ioc 容器"></a>Spring Ioc 容器</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/04/15/Android-Jetpack%E4%B9%8BLiveData/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/15/Android-Jetpack%E4%B9%8BLiveData/" class="post-title-link" itemprop="url">Android Jetpack之LiveData</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-04-15 09:31:20 / 修改时间：18:53:34" itemprop="dateCreated datePublished" datetime="2021-04-15T09:31:20+08:00">2021-04-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="LiveData介绍"><a href="#LiveData介绍" class="headerlink" title="LiveData介绍"></a>LiveData介绍</h4><h5 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h5><p>LiveData是一个重要组件，也是一个同名抽象类。</p>
<blockquote>
<p>LiveData是一种可观察的数据存储器类。与常规的可观察类不同，LiveData具有生命周期感知能力，意指它遵循其他应用组件（如Activity&#x2F;Fragment）的生命周期。这种感知能力可确保LiveData仅更新处于活跃生命周期状态的应用组件观察者。</p>
</blockquote>
<p>解读：     </p>
<ol>
<li>LiveData是一个数据持有者，给源数据包装一层。</li>
<li>源数据使用LiveData包装后，可以被observer观察，数据有更新时observer可感知。</li>
<li>但observer的感知，只发生在（Activity&#x2F;Fragment）活跃生命周期状态（STARTED、RESUMED）。</li>
</ol>
<p>也就是说，<strong>LiveData使得数据的更新能以观察者模式被observer感知，且此感知只发生在LifecycleOwner的活跃生命周期状态</strong>。</p>
<h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><p>使用LiveData具有以下优势：</p>
<ul>
<li><strong>确保界面符合数据状态</strong>，当生命周期状态变化时，LiveData通知Observer，可以在observer中更新界面。观察者可以在生命周期状态更改时刷新界面，而不是在每次数据变化时刷新界面。</li>
<li><strong>不会发生内存泄漏</strong>，observer会在LifecycleOwner状态变为DESTROYED后自动remove。</li>
<li><strong>不会因Activity停止而导致崩溃</strong>，如果LifecycleOwner生命周期处于非活跃状态，则它不会接收任何LiveData事件。</li>
<li><strong>不需要手动解除观察</strong>，开发者不需要在onPause或onDestroy方法中解除对LiveData的观察，因为LiveData能感知生命周期状态变化，所以会自动管理所有这些操作。</li>
<li><strong>数据始终保持最新状态</strong>，数据更新时，若LifecycleOwner为非活跃状态，那么会在变为活跃时接收最新数据。例如，曾经在后台的Activity会在返回前台后，observer立即接收最新的数据。</li>
</ul>
<h4 id="LiveData的使用"><a href="#LiveData的使用" class="headerlink" title="LiveData的使用"></a>LiveData的使用</h4><h5 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h5><p>基本用法：</p>
<ol>
<li>创建LiveData实例，指定源数据类型。</li>
<li>创建Observer实例，实现onChanged()方法，用于接收源数据变化并刷新UI。</li>
<li>LiveData实例使用observe()方法添加观察者，并传入LifecycleOwner。</li>
<li>LiveData实例使用setVale()&#x2F;postVale()更新源数据（子线程要postValue()）。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LiveDataTestActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> MutableLiveData&lt;String&gt; mLiveData;</span><br><span class="line">   </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">       setContentView(R.layout.activity_lifecycle_test);</span><br><span class="line">       </span><br><span class="line">       <span class="comment">//liveData基本使用</span></span><br><span class="line">       mLiveData = <span class="keyword">new</span> <span class="title class_">MutableLiveData</span>&lt;&gt;();</span><br><span class="line">       mLiveData.observe(<span class="built_in">this</span>, <span class="keyword">new</span> <span class="title class_">Observer</span>&lt;String&gt;() &#123;</span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onChanged</span><span class="params">(String s)</span> &#123;</span><br><span class="line">               Log.i(TAG, <span class="string">&quot;onChanged: &quot;</span>+s);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onCreate: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onCreate&quot;</span>);<span class="comment">//activity是非活跃状态，不会回调onChanged。变为活跃时，value被onStart中的value覆盖</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onStart</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onStart();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onStart: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onStart&quot;</span>);<span class="comment">//活跃状态，会回调onChanged。并且value会覆盖onCreate、onStop中设置的value</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onResume</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onResume();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onResume: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onResume&quot;</span>);<span class="comment">//活跃状态，回调onChanged</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onPause</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onPause();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onPause: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onPause&quot;</span>);<span class="comment">//活跃状态，回调onChanged</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onStop</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onStop();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onStop: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onStop&quot;</span>);<span class="comment">//非活跃状态，不会回调onChanged。后面变为活跃时，value被onStart中的value覆盖</span></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onDestroy</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="built_in">super</span>.onDestroy();</span><br><span class="line">       Log.i(TAG, <span class="string">&quot;onDestroy: &quot;</span>);</span><br><span class="line">       mLiveData.setValue(<span class="string">&quot;onDestroy&quot;</span>);<span class="comment">//非活跃状态，且此时Observer已被移除，不会回调onChanged</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>注意到 LiveData实例mLiveData的创建是使用MutableLiveData，它是LiveData的实现类，且指定了源数据的类型为String。然后创建了接口Observer的实例，实现其onChanged()方法，用于接收源数据的变化。observer和Activity一起作为参数调用mLiveData的observe()方法，表示observer开始观察mLiveData。然后Activity的所有生命周期方法中都调用了mLiveData的setValue()方法。</p>
<p>另外，除了使用observe()方法添加观察者，也可以使用<strong>observeForever</strong>(Observer) 方法来注册未关联 LifecycleOwner的观察者。在这种情况下，观察者会被视为始终处于活跃状态。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2021/04/14/Android-Jetpack%E4%B9%8BLifecycle/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/14/Android-Jetpack%E4%B9%8BLifecycle/" class="post-title-link" itemprop="url">Android Jetpack之Lifecycle</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-04-14 13:48:19" itemprop="dateCreated datePublished" datetime="2021-04-14T13:48:19+08:00">2021-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-04-15 09:29:58" itemprop="dateModified" datetime="2021-04-15T09:29:58+08:00">2021-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="Android-Jepack介绍"><a href="#Android-Jepack介绍" class="headerlink" title="Android Jepack介绍"></a>Android Jepack介绍</h4><blockquote>
<p>Jetpack 是一个由多个库组成的套件，可帮助开发者遵循最佳做法，减少样板代码并编写可在各种Android版本和设备中一致运行的代码，让开发者精力集中编写重要的代码。</p>
</blockquote>
<p>使用Jetpack的好处：</p>
<ul>
<li><strong>遵循最佳做法</strong>，Android Jetpack 组件采用最新的设计方法构建，具有向后兼容性，可以减少崩溃和内存泄露。</li>
<li><strong>消除样本代码</strong>，Android Jetpack 可以管理各种繁琐的 Activity（如后台任务、导航和生命周期管理），以便您可以专注于打造出色的应用。</li>
<li><strong>减少不一致</strong>，这些库可在各种 Android 版本和设备中以一致的方式运作，助您降低复杂性。</li>
</ul>
<h4 id="Lifecycle"><a href="#Lifecycle" class="headerlink" title="Lifecycle"></a>Lifecycle</h4><p>Lifecycle是用来帮助开发者管理Activity和Fragment的生命周期。    </p>
<p>Lifecycle是一个库，它包含Lifecycle类，Lifecycle类用于存储有关组件（如Acitivity或Fragment）的生命周期状态的信息，并允许其他对象观察此状态。   </p>
<p>Lifycycle使用两种主要枚举跟踪其关联组件的生命周期状态：     </p>
<ul>
<li><p>事件     </p>
<p>从框架和Lifecycle类分派的生命周期事件。这些事件映射到Activity和Fragment中的回调事件。        </p>
</li>
<li><p>状态      </p>
<p>由Lifecyle对象跟踪的组件的当前状态</p>
</li>
</ul>
<p><img src="/2021/04/14/Android-Jetpack%E4%B9%8BLifecycle/lifecycle-states.svg" alt="构成 Android Activity 生命周期的状态和事件"></p>
<h5 id="Lifecycle的使用"><a href="#Lifecycle的使用" class="headerlink" title="Lifecycle的使用"></a>Lifecycle的使用</h5><h6 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h6><p>非androidx</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation &quot;android.arch.lifecycle:extensions:1.1.1&quot;</span><br></pre></td></tr></table></figure>



<p>androidx</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    <span class="type">def</span> <span class="variable">lifecycle_version</span> <span class="operator">=</span> <span class="string">&quot;2.3.0&quot;</span></span><br><span class="line">    <span class="type">def</span> <span class="variable">arch_version</span> <span class="operator">=</span> <span class="string">&quot;2.1.0&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// ViewModel</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-viewmodel:$lifecycle_version&quot;</span></span><br><span class="line">    <span class="comment">// LiveData</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-livedata:$lifecycle_version&quot;</span></span><br><span class="line">    <span class="comment">// Lifecycles only (without ViewModel or LiveData)</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-runtime:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Saved state module for ViewModel</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-viewmodel-savedstate:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Annotation processor</span></span><br><span class="line">    annotationProcessor <span class="string">&quot;androidx.lifecycle:lifecycle-compiler:$lifecycle_version&quot;</span></span><br><span class="line">    <span class="comment">// alternately - if using Java8, use the following instead of lifecycle-compiler</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-common-java8:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - helpers for implementing LifecycleOwner in a Service</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-service:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - ProcessLifecycleOwner provides a lifecycle for the whole application process</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-process:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - ReactiveStreams support for LiveData</span></span><br><span class="line">    implementation <span class="string">&quot;androidx.lifecycle:lifecycle-reactivestreams:$lifecycle_version&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// optional - Test helpers for LiveData</span></span><br><span class="line">    testImplementation <span class="string">&quot;androidx.arch.core:core-testing:$arch_version&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看着有很多，实际上如果只使用Lifecycle，只需要引入lifecycle-runtime即可。但通常都是和 ViewModel、 LiveData 配套使用的，所以lifecycle-viewmodel、lifecycle-livedata 一般也会引入。</p>
<h6 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h6><ol>
<li>生命周期拥有者使用getLifecycle()获取Lifecycle实例，然后用addObserve()添加观察者。    </li>
<li>观察者实现LifecycleObserve，方法上用OnLifecycleEvent注解关注对应生命周期，生命周期触发时就会执行对应方法。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyObserver</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">    <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_RESUME)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">connectListener</span><span class="params">()</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_PAUSE)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">disconnectListener</span><span class="params">()</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LifecycleTestActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">        setContentView(R.layout.activity_lifecycle_test);</span><br><span class="line">        <span class="comment">//Lifecycle 生命周期</span></span><br><span class="line">        getLifecycle().addObserver(<span class="keyword">new</span> <span class="title class_">MyObserver</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>Activity（或Fragment）是生命周期的拥有者，通过getLifecycle()方法获取到生命周期Lifecycle对象，Lifecycle对象使用addObserver方法 给自己添加观察者，即MyObserver对象。当Lifecycle的生命周期发生变化时，MyObserver就可以感知到。</p>
<h6 id="MVP架构中的使用"><a href="#MVP架构中的使用" class="headerlink" title="MVP架构中的使用"></a>MVP架构中的使用</h6><p>如果在MVP架构中，可以把presenter作为观察者。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LifecycleTestActivity</span> <span class="keyword">extends</span> <span class="title class_">AppCompatActivity</span> <span class="keyword">implements</span> <span class="title class_">IView</span> &#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="type">String</span> <span class="variable">TAG</span> <span class="operator">=</span> <span class="string">&quot;Lifecycle_Test&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line">        setContentView(R.layout.activity_lifecycle_test);</span><br><span class="line">        <span class="comment">//Lifecycle 生命周期</span></span><br><span class="line"><span class="comment">//        getLifecycle().addObserver(new MyObserver());</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//MVP中使用Lifecycle</span></span><br><span class="line">        getLifecycle().addObserver(<span class="keyword">new</span> <span class="title class_">MyPresenter</span>(<span class="built_in">this</span>));</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;onCreate: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onResume</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onResume();</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;onResume: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onPause</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onPause();</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;onPause: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">showView</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">hideView</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Presenter</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyPresenter</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TAG</span> <span class="operator">=</span> <span class="string">&quot;Lifecycle_Test&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IView mView;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyPresenter</span><span class="params">(IView view)</span> &#123;mView = view;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnLifecycleEvent(value = Lifecycle.Event.ON_START)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">getDataOnStart</span><span class="params">(LifecycleOwner owner)</span>&#123;</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;getDataOnStart: &quot;</span>);</span><br><span class="line">        </span><br><span class="line">        Util.checkUserStatus(result -&gt; &#123;</span><br><span class="line">                <span class="comment">//checkUserStatus是耗时操作，回调后检查当前生命周期状态</span></span><br><span class="line">                <span class="keyword">if</span> (owner.getLifecycle().getCurrentState().isAtLeast(STARTED)) &#123;</span><br><span class="line">                	start();</span><br><span class="line">                    mView.showView();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@OnLifecycleEvent(value = Lifecycle.Event.ON_STOP)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">hideDataOnStop</span><span class="params">()</span>&#123;</span><br><span class="line">        Log.i(TAG, <span class="string">&quot;hideDataOnStop: &quot;</span>);</span><br><span class="line">        stop();</span><br><span class="line">        mView.hideView();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//IView</span></span><br><span class="line"><span class="keyword">interface</span> <span class="title class_">IView</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">showView</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">hideView</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>这里是让Presenter实现LifecycleObserver接口，同样在方法上注解要触发的生命周期，最后在Activity中作为观察者添加到Lifecycle中。</p>
<p>这样做好处是啥呢？ 当Activity生命周期发生变化时，MyPresenter就可以感知并执行方法，不需要在MainActivity的多个生命周期方法中调用MyPresenter的方法了。</p>
<ul>
<li><strong>所有方法调用操作都由组件本身管理</strong>：Presenter类自动感知生命周期，如果需要在其他的Activity&#x2F;Fragment也使用这个Presenter，只需添加其为观察者即可。</li>
<li><strong>让各个组件存储自己的逻辑，减轻Activity&#x2F;Fragment中代码，更易于管理</strong>；</li>
</ul>
<p>另外，注意到 getDataOnStart()中耗时校验回调后，对当前生命周期状态进行了检查：至少处于STARTED状态才会继续执行start()方法，也就是保证了Activity停止后不会走start()方法；</p>
<h6 id="自定义LifecycleOwner"><a href="#自定义LifecycleOwner" class="headerlink" title="自定义LifecycleOwner"></a>自定义LifecycleOwner</h6><p>在Activity中调用getLifecycle()能获取到Lifecycle实例，getLifecycle()是在接口LifecycleOwner中定义。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 生命周期拥有者</span></span><br><span class="line"><span class="comment"> * 生命周期事件可被 自定义的组件 用来 处理生命周期事件的变化，同时不会在Activity/Fragmen中写任何代码</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">LifecycleOwner</span> &#123;</span><br><span class="line">    <span class="meta">@NonNull</span></span><br><span class="line">    Lifecycle <span class="title function_">getLifecycle</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Support Library 26.1.0及以上、AndroidX的 Fragment 和 Activity 已实现 LifecycleOwner 接口，所以我们在Activity中可以直接使用getLifecycle()。</p>
<p>如果有一个自定义类并希望使其成为LifecycleOwner，可以使用LifecycleRegistry类，它是Lifecycle的实现类，但需要将事件转发到该类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyActivity</span> <span class="keyword">extends</span> <span class="title class_">Activity</span> <span class="keyword">implements</span> <span class="title class_">LifecycleOwner</span> &#123;</span><br><span class="line">       <span class="keyword">private</span> LifecycleRegistry lifecycleRegistry;</span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">(Bundle savedInstanceState)</span> &#123;</span><br><span class="line">           <span class="built_in">super</span>.onCreate(savedInstanceState);</span><br><span class="line"></span><br><span class="line">           lifecycleRegistry = <span class="keyword">new</span> <span class="title class_">LifecycleRegistry</span>(<span class="built_in">this</span>);</span><br><span class="line">           lifecycleRegistry.markState(Lifecycle.State.CREATED);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onStart</span><span class="params">()</span> &#123;</span><br><span class="line">           <span class="built_in">super</span>.onStart();</span><br><span class="line">           lifecycleRegistry.markState(Lifecycle.State.STARTED);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="meta">@NonNull</span></span><br><span class="line">       <span class="meta">@Override</span></span><br><span class="line">       <span class="keyword">public</span> Lifecycle <span class="title function_">getLifecycle</span><span class="params">()</span> &#123;</span><br><span class="line">           <span class="keyword">return</span> lifecycleRegistry;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>MyActivity实现LifecycleOwner，getLifecycle()返回lifecycleRegistry实例。lifecycleRegistry实例则是在onCreate创建，并且在各个生命周期内调用markState()方法完成生命周期事件的传递。这就完成了LifecycleOwner的自定义，也即MyActivity变成了LifecycleOwner，然后就可以和 实现了LifecycleObserver的组件配合使用了。</p>
<p>补充一点，<strong>观察者的方法可以接受一个参数LifecycleOwner</strong>，就可以用来获取当前状态、或者继续添加观察者。 若注解的是ON_ANY还可以接收Event，用于区分是哪个事件。如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">class</span> <span class="title class_">TestObserver</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_CREATE)</span></span><br><span class="line">        <span class="keyword">void</span> <span class="title function_">onCreated</span><span class="params">(LifecycleOwner owner)</span> &#123;</span><br><span class="line"><span class="comment">//            owner.getLifecycle().addObserver(anotherObserver);</span></span><br><span class="line"><span class="comment">//            owner.getLifecycle().getCurrentState();</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_ANY)</span></span><br><span class="line">        <span class="keyword">void</span> <span class="title function_">onAny</span><span class="params">(LifecycleOwner owner, Lifecycle.Event event)</span> &#123;</span><br><span class="line"><span class="comment">//            event.name()</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h6 id="Application生命周期-ProcessLifecycleOwner"><a href="#Application生命周期-ProcessLifecycleOwner" class="headerlink" title="Application生命周期 ProcessLifecycleOwner"></a>Application生命周期 ProcessLifecycleOwner</h6><p>之前对App进入前后台的判断是通过registerActivityLifecycleCallbacks(callback)方法，然后在callback中利用一个全局变量做计数，在onActivityStarted()中计数加1，在onActivityStopped方法中计数减1，从而判断前后台切换。</p>
<p>而使用ProcessLifecycleOwner可以直接获取应用前后台切换状态。（记得先引入lifecycle-process依赖）</p>
<p>使用方式和Activity中类似，只不过要使用ProcessLifecycleOwner.get()获取ProcessLifecycleOwner，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyApplication</span> <span class="keyword">extends</span> <span class="title class_">Application</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCreate</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>.onCreate();</span><br><span class="line"></span><br><span class="line">	<span class="comment">//注册App生命周期观察者</span></span><br><span class="line">        ProcessLifecycleOwner.get().getLifecycle().addObserver(<span class="keyword">new</span> <span class="title class_">ApplicationLifecycleObserver</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Application生命周期观察，提供整个应用进程的生命周期</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * Lifecycle.Event.ON_CREATE只会分发一次，Lifecycle.Event.ON_DESTROY不会被分发。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 第一个Activity进入时，ProcessLifecycleOwner将分派Lifecycle.Event.ON_START, Lifecycle.Event.ON_RESUME。</span></span><br><span class="line"><span class="comment">     * 而Lifecycle.Event.ON_PAUSE, Lifecycle.Event.ON_STOP，将在最后一个Activit退出后后延迟分发。如果由于配置更改而销毁并重新创建活动，则此延迟足以保证ProcessLifecycleOwner不会发送任何事件。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 作用：监听应用程序进入前台或后台</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ApplicationLifecycleObserver</span> <span class="keyword">implements</span> <span class="title class_">LifecycleObserver</span> &#123;</span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_START)</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">onAppForeground</span><span class="params">()</span> &#123;</span><br><span class="line">            Log.w(TAG, <span class="string">&quot;ApplicationObserver: app moved to foreground&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@OnLifecycleEvent(Lifecycle.Event.ON_STOP)</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">onAppBackground</span><span class="params">()</span> &#123;</span><br><span class="line">            Log.w(TAG, <span class="string">&quot;ApplicationObserver: app moved to background&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2020/12/12/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/12/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" class="post-title-link" itemprop="url">微服务</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-12 10:11:36" itemprop="dateCreated datePublished" datetime="2020-12-12T10:11:36+08:00">2020-12-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-12 10:37:07" itemprop="dateModified" datetime="2022-12-12T10:37:07+08:00">2022-12-12</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="微服务定义"><a href="#微服务定义" class="headerlink" title="微服务定义"></a>微服务定义</h4><p>微服务架构是一种架构风格和架构思想，它倡导我们在传统软件应用架构的基础上，将系统业务按照功能拆分为更加细粒度的服务，所拆分的每一个服务都是一个独立的应用，这些应用对外提供公共的API，可以独立承担对外服务的职责，通过此种思想方式所开发的软件服务实体就是“微服务”，而围绕着微服务思想构建的一系列体系结构(包括开发、测试、部署等)。</p>
<h5 id="微服务优缺点"><a href="#微服务优缺点" class="headerlink" title="微服务优缺点"></a>微服务优缺点</h5><h6 id="微服务特点一：快速响应需求变化"><a href="#微服务特点一：快速响应需求变化" class="headerlink" title="微服务特点一：快速响应需求变化"></a>微服务特点一：快速响应需求变化</h6><p>采用单体巨型非微服务架构有个问题，系统里面的业务模块非常多，大家一 起发布、修改、编译很难进行协调，很难做到敏捷开发、发 布、上线。</p>
<p>微服务本质上是小微程序，相比较来说，很重要的特点是拆分概念。微服务首先是拆分，把大的拆成小的，把整体拆成部分。每个部分单独开发迭代。</p>
<blockquote>
<p>微服务的优点：拆完以后更灵活，各个子系统可以独立开发、独立测试、独立部署、独立进程，最后再集成。</p>
</blockquote>
<p>独立开发拆分以后自主性更强了，独立开发、独立测试、独立部署、独立进程，是 微服务快速响应业务需求变化的重要特点。</p>
<h6 id="微服务特点二：敏捷开发、敏捷运维DevOps"><a href="#微服务特点二：敏捷开发、敏捷运维DevOps" class="headerlink" title="微服务特点二：敏捷开发、敏捷运维DevOps"></a>微服务特点二：敏捷开发、敏捷运维DevOps</h6><blockquote>
<p>微服务的优点：本质上是拆完以后更好开发。</p>
</blockquote>
<p>总结如下：</p>
<ol>
<li>易于替换；</li>
<li>独立部署；</li>
<li>专注某个任务；</li>
<li>高度解耦；</li>
<li>基于功能进行组织：商品、支付、评论、机票、新闻、酒店、游戏等；</li>
<li>服务可以使用不同的语言、系统、平台；</li>
<li>通信使用语言中立的协议，通常是http；</li>
<li>独立技术栈；</li>
<li>易于测试；</li>
</ol>
<h4 id="微服务Microservice的设计原则"><a href="#微服务Microservice的设计原则" class="headerlink" title="微服务Microservice的设计原则"></a>微服务Microservice的设计原则</h4><blockquote>
<p>需求第一</p>
</blockquote>
<p>一定要以需求为出发点。所有的架构好与坏一定是相对的，相对他处的一个需求背景。因为微服务架构能够在某些业务场景中具备优势，所以它相比传统的架构，他有一些优点但是同时也存在着缺点，它不完美。 </p>
<blockquote>
<p>单一职责</p>
</blockquote>
<p>我们的服务尽量是体现单一职责的思想，粒度不是越细越好，也不是越 粗越好。</p>
<blockquote>
<p>协议统一</p>
</blockquote>
<p>尽量去统一协议，目前的协议主要是 rest。</p>
<blockquote>
<p>独立开发</p>
</blockquote>
<p>独立开发一般咱们这里面提到的我们说的是模块拆分以后开发人员一般是独立我们按照模块进行拆分，然后每个人负责一块，每个人熟悉一块代码和逻辑业务逻辑这样的话开发时间都会相对来说高很多。</p>
<blockquote>
<p>独立部署</p>
</blockquote>
<p>独立部署这也是微服架构的很重要的一个原则，微服务架构拆分以后又会出现可能很多程序很多进程，而且每一个模块不是所有的都更新只需要迭代我那一块就行了，就是体现了我们说叫分而治之的这样一个思想，大家一起统一部署。</p>
<h4 id="微服务Microservice的拆分原则"><a href="#微服务Microservice的拆分原则" class="headerlink" title="微服务Microservice的拆分原则"></a>微服务Microservice的拆分原则</h4><ol>
<li><p>按照业务模块拆分</p>
</li>
<li><p>DDD思路可以借鉴，不能照搬</p>
<p>DDD 本身不是架构设计模式，DDD 是一种但是在向对象设计的一个思想或者原则，它是用来解决复杂业务逻辑的一个拆分问题的，它本身并不解决整个架构层次的问题，它是解决业务层的，理解这一点。</p>
</li>
<li><p>单一职责（Single Responsibility）</p>
</li>
</ol>
<h4 id="微服务设计的关注点"><a href="#微服务设计的关注点" class="headerlink" title="微服务设计的关注点"></a>微服务设计的关注点</h4><ol>
<li>并发性</li>
<li>可用性</li>
<li>安全性</li>
<li>密等性</li>
<li>重用性</li>
</ol>
<h4 id="微服务架构设计的5大考量"><a href="#微服务架构设计的5大考量" class="headerlink" title="微服务架构设计的5大考量"></a>微服务架构设计的5大考量</h4><ol>
<li>微服务拆分</li>
<li>微服务高可用</li>
<li>微数据安全</li>
<li>微服务数据同步</li>
<li>微服务监控</li>
</ol>
<h4 id="微服务的经典设计模式"><a href="#微服务的经典设计模式" class="headerlink" title="微服务的经典设计模式"></a>微服务的经典设计模式</h4><h5 id="微服务架构设计模式"><a href="#微服务架构设计模式" class="headerlink" title="微服务架构设计模式"></a>微服务架构设计模式</h5><ol>
<li>业务分解：DDD模式</li>
<li>DataBase PerService 每数据库单服务</li>
<li>API Gateway pattern API网关模式</li>
<li>Client-side 和 Remote Procedure Invocation 模式</li>
<li>Messaging 和 Procedure Invocation 模式</li>
<li>Single Service per Host 和 Multiple Services per Host 模式</li>
<li>AOP: Microservice chassis pattern</li>
<li>Externalized Configuration</li>
<li>Service Component Test 和 Service Integration Contract Test</li>
<li>Circuit Breaker 断路器模式</li>
<li>Access Token 访问令牌模式</li>
<li>观察者模式： Distributed tracing、 Health check API</li>
<li>UI模式：MVC、MVP、MVVM模式</li>
</ol>
<p><img src="/2020/12/12/%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20210820095240441.png" alt="image-20210820095240441"></p>
<p>如图所示，以微服务架构为中心向外发散，有许多设计模式，正下方有两个，一个叫客户端发现，一个叫服务端发现，服务的注册和发现机制也是一个设计模式，微服架构属于更复杂的分布架构，里面也会用到消息通信，通过消息和数据库、其他微服务进行消息补偿。 </p>
<p>网关的微服务太多，只有一个出口，需要给它同一个代理；安全问题，如图中Access token，和令牌相关的；另外还有高并发的熔断限流，circuit breaker 叫断路器模式，熔断相关，分布式日志、分布式加策、追踪、服务拆分模式、单数据库模式、单实例、单数据库模式多服务共享数据库模式、服务编排模式、统一配置模式等等。</p>
<p>这里主要是分布式架构领域相关的设计模式，还有分布式事务模式，一般用的都是补偿的方式。 </p>
<p>服务拆分的一般借鉴 DDD 模式，但不是照搬，不能完全等同。</p>
<h5 id="微服务设计模式分类"><a href="#微服务设计模式分类" class="headerlink" title="微服务设计模式分类"></a>微服务设计模式分类</h5><h6 id="应用架构模式"><a href="#应用架构模式" class="headerlink" title="应用架构模式"></a>应用架构模式</h6><ol>
<li>单点登录</li>
<li>注册发现</li>
<li>熔断限流</li>
<li>断路器</li>
<li>网关模式</li>
<li>消息补偿模式</li>
<li>令牌模式</li>
</ol>
<h6 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h6><ol>
<li>分库 Single Service</li>
<li>共库多 Service</li>
<li>多库同步</li>
<li>事务性补偿</li>
</ol>
<h6 id="日志追踪模式"><a href="#日志追踪模式" class="headerlink" title="日志追踪模式"></a>日志追踪模式</h6><ol>
<li><p>观察者模式 paterns</p>
</li>
<li><p>Log aggregation</p>
</li>
<li><p>Application metrics</p>
</li>
<li><p>Audit logging</p>
</li>
<li><p>Distributed tracing</p>
</li>
<li><p>Exception tracking</p>
</li>
<li><p>Health check API</p>
</li>
<li><p>Log deployments and changes</p>
</li>
<li><p>分布式链路追踪模式</p>
</li>
</ol>
<h6 id="UI模式"><a href="#UI模式" class="headerlink" title="UI模式"></a>UI模式</h6><ol>
<li>MVC</li>
<li>MVP</li>
<li>MVVM</li>
<li>Server-side page fragment composition</li>
<li>Client-side UI composition</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2020/11/01/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/01/Redis/" class="post-title-link" itemprop="url">Redis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-11-01 10:10:29" itemprop="dateCreated datePublished" datetime="2020-11-01T10:10:29+08:00">2020-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-01-08 17:41:41" itemprop="dateModified" datetime="2023-01-08T17:41:41+08:00">2023-01-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Redis（Remote Dictionary Server），即远程字典服务。</p>
<p>redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push&#x2F;pop、add&#x2F;remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。</p>
<p>Redis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/memcached">memcached</a>这类key&#x2F;value存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Java，C&#x2F;C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。 </p>
<p>Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布&#x2F;订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。</p>
<p><code>读的速度是110000次/s,写的速度是81000次/s 。</code></p>
<p><strong>Redis能干嘛？</strong></p>
<p>1、 内存存储、持久化</p>
<p>2、 效率高，可以用于高速存储</p>
<p>3、 法边订阅系统</p>
<p>4、 地图信息分析</p>
<p>5、 计时器、计数器（浏览量）</p>
<p>6、 ……</p>
<p><strong>特性</strong></p>
<p>1、 多样的数据类型</p>
<p>2、 持久化</p>
<p>3、 集群</p>
<p>4、 事务</p>
<p>5、 ……</p>
<h3 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h3><h4 id="Windows安装"><a href="#Windows安装" class="headerlink" title="Windows安装"></a>Windows安装</h4><p>1、下载 <a target="_blank" rel="noopener" href="https://github.com/microsoftarchive/redis/releases">https://github.com/microsoftarchive/redis/releases</a></p>
<p>2、 解压</p>
<p>3、 cmd下执行</p>
<blockquote>
<p>redis-server redis.windows.conf</p>
</blockquote>
<h4 id="Linux安装"><a href="#Linux安装" class="headerlink" title="Linux安装"></a>Linux安装</h4><h5 id="下载Redis"><a href="#下载Redis" class="headerlink" title="下载Redis"></a>下载Redis</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://download.redis.io/releases/redis-6.2.5.tar.gz</span><br></pre></td></tr></table></figure>



<h5 id="解压Redis"><a href="#解压Redis" class="headerlink" title="解压Redis"></a>解压Redis</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf redis-6.2.5.tar.gz </span><br></pre></td></tr></table></figure>



<h5 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> redis-6.2.5</span><br><span class="line"></span><br><span class="line">make </span><br><span class="line"></span><br><span class="line">make install PREFIX=/usr/bin/redis</span><br></pre></td></tr></table></figure>



<h5 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> /opt/redis-6.2.5/redis.conf /usr/bin/redis/</span><br><span class="line"></span><br><span class="line">vim redis.conf    <span class="comment">#修改daemonize no 改成 yes</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/local/redis/bin</span><br><span class="line"></span><br><span class="line">./redis-server ./redis.conf</span><br><span class="line"></span><br><span class="line">ps -ef |grep redis</span><br></pre></td></tr></table></figure>



<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>1、 Redis默认有16个数据库，默认使用第0个，可以使用select切换数据库</p>
<blockquote>
<p>set key value  #设置key value</p>
<p>get key  #获取key对应的value</p>
<p>keys *   #列出所有keys</p>
<p>DBSIZE  #数量</p>
<p>select #切换数据库</p>
<p>flushdb  #清空数据库</p>
<p>flushall  #清空所有数据库</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name zhangsan</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">&quot;zhangsan&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name1 lisi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name1</span><br><span class="line"><span class="string">&quot;lisi&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) <span class="string">&quot;name1&quot;</span></span><br><span class="line">2) <span class="string">&quot;name&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; select 3</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; keys *</span><br><span class="line">(empty array)</span><br><span class="line">127.0.0.1:6379[3]&gt; DBSIZE</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379[3]&gt; </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ping</span><br><span class="line">PONG</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;name1&quot;</span><br><span class="line">2) &quot;name&quot;</span><br><span class="line">127.0.0.1:6379&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; set x y</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;x&quot;</span><br><span class="line">127.0.0.1:6379&gt; select 3</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379[3]&gt; set a b</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; keys *</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379[3]&gt; flushall</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[3]&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379[3]&gt; select 0</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; DBSIZE</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>



<blockquote>
<p>Redis是单线程的</p>
</blockquote>
<p>Redis是基于内存操作，CPU不是Redis行能瓶颈，Redis的瓶颈是根据机器的内存和网络带宽</p>
<h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> key1 v1   <span class="comment">#设置值</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get key1</span><br><span class="line"><span class="string">&quot;v1&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; EXISTS key1   <span class="comment">#判断是否存在</span></span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; APPEND key1 <span class="string">&quot;hello&quot;</span>   <span class="comment">#追加字符串</span></span><br><span class="line">(<span class="built_in">integer</span>) 7</span><br><span class="line">127.0.0.1:6379&gt; get key1</span><br><span class="line"><span class="string">&quot;v1hello&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; STRLEN key1    <span class="comment">#获取字符串长度</span></span><br><span class="line">(<span class="built_in">integer</span>) 7</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2020/10/29/Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/29/Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/" class="post-title-link" itemprop="url">Elasticsearch面试题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-29 20:06:28" itemprop="dateCreated datePublished" datetime="2020-10-29T20:06:28+08:00">2020-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-07 17:19:45" itemprop="dateModified" datetime="2023-02-07T17:19:45+08:00">2023-02-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="为什么要使用-Elasticsearch"><a href="#为什么要使用-Elasticsearch" class="headerlink" title="为什么要使用 Elasticsearch?"></a>为什么要使用 Elasticsearch?</h1><p>系统中的数据，随着业务的发展，时间的推移，将会非常多，而业务中往往采用模糊查询进行数据的搜索，而模糊查询会导致查询引擎放弃索引，导致系统查询数据时都是全表扫描，在百万级别的数据库中，查询效率是非常低下的，而我们使用 ES 做一个全文索引，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有 id 这些字段我们放入 ES 索引库里，可以提高查询速度。</p>
<h1 id="Elasticsearch-的-master-选举流程？"><a href="#Elasticsearch-的-master-选举流程？" class="headerlink" title="Elasticsearch 的 master 选举流程？"></a>Elasticsearch 的 master 选举流程？</h1><ul>
<li>Elasticsearch 的选主是 ZenDiscovery 模块负责的，主要包含 Ping（节点之间通过这个 RPC 来发现彼此）和 Unicast（单播模块包含一个主机列表以控制哪些节点需要 ping 通）这两部分</li>
<li>对所有可以成为 master 的节点（node.master: true）根据 nodeId 字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第 0 位）节点，暂且认为它是 master 节点。</li>
<li>如果对某个节点的投票数达到一定的值（可以成为 master 节点数 n&#x2F;2+1）并且该节点自己也选举自己，那这个节点就是 master。否则重新选举一直到满足上述条件。</li>
<li>master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data 节点可以关闭 http功能。</li>
</ul>
<h1 id="Elasticsearch-集群脑裂问题？"><a href="#Elasticsearch-集群脑裂问题？" class="headerlink" title="Elasticsearch 集群脑裂问题？"></a>Elasticsearch 集群脑裂问题？</h1><p><strong>“脑裂”问题可能的成因:</strong></p>
<ul>
<li>网络问题：集群间的网络延迟导致一些节点访问不到 master，认为 master 挂掉了从而选举出新的master，并对 master 上的分片和副本标红，分配新的主分片</li>
<li>节点负载：主节点的角色既为 master 又为 data，访问量较大时可能会导致 ES 停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。</li>
<li>内存回收：data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。</li>
</ul>
<p><strong>脑裂问题解决方案：</strong></p>
<ul>
<li>减少误判：discovery.zen.ping_timeout 节点状态的响应时间，默认为 3s，可以适当调大，如果 master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如 6s，discovery.zen.ping_timeout:6），可适当减少误判。</li>
<li>选举触发: discovery.zen.minimum_master_nodes:1<br>该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n&#x2F;2）+1，n 为主节点个数（即有资格成为主节点的节点个数）</li>
<li>角色分离：即 master 节点与 data 节点分离，限制角色<br>主节点配置为：node.master: true node.data: false<br>从节点配置为：node.master: false node.data: true</li>
</ul>
<h1 id="Elasticsearch-索引文档的流程？"><a href="#Elasticsearch-索引文档的流程？" class="headerlink" title="Elasticsearch 索引文档的流程？"></a>Elasticsearch 索引文档的流程？</h1><p><img src="/2020/10/29/Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/image-20230207164746081.png" alt="image-20230207164746081"></p>
<ul>
<li>协调节点默认使用文档 ID 参与计算（也支持通过 routing），以便为路由提供合适的分片：<br>shard &#x3D; hash(document_id) % (num_of_primary_shards)</li>
<li>当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然后定时（默认是每隔 1 秒）写入到 Filesystem Cache，这个从 Memory Buffer 到 Filesystem Cache 的过程就叫做 refresh；</li>
<li>当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失，ES 是通过 translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystem<br>cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；</li>
<li>在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。</li>
<li>flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）时；</li>
</ul>
<h1 id="Elasticsearch-更新和删除文档的流程？"><a href="#Elasticsearch-更新和删除文档的流程？" class="headerlink" title="Elasticsearch 更新和删除文档的流程？"></a>Elasticsearch 更新和删除文档的流程？</h1><ul>
<li>删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更；</li>
<li>磁盘上的每个段都有一个相应的.del 文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del 文件中被标记为删除的文档将不会被写入新段。</li>
<li>在新的文档被创建时，Elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</li>
</ul>
<h1 id="Elasticsearch-搜索的流程？"><a href="#Elasticsearch-搜索的流程？" class="headerlink" title="Elasticsearch 搜索的流程？"></a>Elasticsearch 搜索的流程？</h1><p><img src="/2020/10/29/Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/image-20230207165625645.png" alt="image-20230207165625645"></p>
<ul>
<li>搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</li>
<li>在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache 的，但是有部分数据还在 Memory Buffer，所以搜索是近实时的。</li>
<li>每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</li>
<li>接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
<li>Query Then Fetch 的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch 增加了一个预查询的处理，询问 Term 和 Document frequency，这个评分更准确，但是性能会变差。</li>
</ul>
<h1 id="Elasticsearch-在部署时，对-Linux-的设置有哪些优化方法？"><a href="#Elasticsearch-在部署时，对-Linux-的设置有哪些优化方法？" class="headerlink" title="Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法？"></a>Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法？</h1><ul>
<li>64 GB 内存的机器是非常理想的，但是 32 GB 和 16 GB 机器也是很常见的。少于 8 GB 会适得其反。</li>
<li>如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</li>
<li>如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起，SSD 是一个好的选择。</li>
<li>即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。</li>
<li>请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 Elasticsearch 的几个地方，使用 Java 的本地序列化。</li>
<li>通过设置 gateway.recover_after_nodes、gateway.expected_nodes、gateway.recover_after_time 可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。</li>
<li>Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。</li>
<li>不要随意修改垃圾回收器（CMS）和各个线程池的大小。</li>
<li>把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过 ES_HEAP_SIZE 环境变量设置。</li>
<li>内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。</li>
<li>Lucene 使用了大量的文件。同时，Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。</li>
</ul>
<p><strong>补充：索引阶段性能提升方法</strong></p>
<ul>
<li>使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。</li>
<li>存储：使用 SSD</li>
<li>段和合并：Elasticsearch 默认值是 20 MB&#x2F;s，对机械磁盘应该是个不错的设置。如果你用的是 SSD，可以考虑提高到 100–200 MB&#x2F;s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。另外还可以增加 index.translog.flush_threshold_size 设置，从默认的 512 MB 到更大一些的值，比如 1 GB，这可以在一次清空触发的时候在事务日志里积累出更大的段。</li>
<li>如果你的搜索结果不需要近实时的准确度，考虑把每个索引的 index.refresh_interval 改到 30s。</li>
<li>如果你在做大批量导入，考虑通过设置 index.number_of_replicas: 0 关闭副本。</li>
</ul>
<h1 id="GC-方面，在使用-Elasticsearch-时要注意什么？"><a href="#GC-方面，在使用-Elasticsearch-时要注意什么？" class="headerlink" title="GC 方面，在使用 Elasticsearch 时要注意什么？"></a>GC 方面，在使用 Elasticsearch 时要注意什么？</h1><ul>
<li>倒排词典的索引需要常驻内存，无法 GC，需要监控 data node 上 segment memory 增长趋势。</li>
<li>各类缓存，field cache, filter cache, indexing cache, bulk queue 等等，要设置合理的大小，并且要应该根据最坏的情况来看 heap 是否够用，也就是各类缓存全部占满的时候，还有 heap 空间可以分配给其他任务吗？避免采用 clear cache 等“自欺欺人”的方式来释放内存。</li>
<li>避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用 scan &amp; scroll api 来实现。</li>
<li>cluster stats 驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过 tribe node 连接。</li>
<li>想知道 heap 够不够，必须结合实际应用场景，并对集群的 heap 使用情况做持续的监控。</li>
</ul>
<h1 id="Elasticsearch-对于大数据量（上亿量级）的聚合如何实现？"><a href="#Elasticsearch-对于大数据量（上亿量级）的聚合如何实现？" class="headerlink" title="Elasticsearch 对于大数据量（上亿量级）的聚合如何实现？"></a>Elasticsearch 对于大数据量（上亿量级）的聚合如何实现？</h1><p>Elasticsearch 提供的首个近似聚合是 cardinality 度量。它提供一个字段的基数，即该字段的 distinct或者 unique 值的数目。它是基于 HLL 算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。</p>
<h1 id="在并发情况下，Elasticsearch-如果保证读写一致？"><a href="#在并发情况下，Elasticsearch-如果保证读写一致？" class="headerlink" title="在并发情况下，Elasticsearch 如果保证读写一致？"></a>在并发情况下，Elasticsearch 如果保证读写一致？</h1><ul>
<li>可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</li>
<li>另外对于写操作，一致性级别支持 quorum&#x2F;one&#x2F;all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</li>
<li>对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。</li>
</ul>
<h1 id="如何监控-Elasticsearch-集群状态？"><a href="#如何监控-Elasticsearch-集群状态？" class="headerlink" title="如何监控 Elasticsearch 集群状态？"></a>如何监控 Elasticsearch 集群状态？</h1><p>elasticsearch-head 插件。<br>通过 Kibana 监控 Elasticsearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标。</p>
<h1 id="是否了解字典树？"><a href="#是否了解字典树？" class="headerlink" title="是否了解字典树？"></a>是否了解字典树？</h1><ul>
<li><p>常用字典数据结构如下所示:</p>
<p><img src="/2020/10/29/Elasticsearch%E9%9D%A2%E8%AF%95%E9%A2%98/image-20230207170857422.png" alt="image-20230207170857422"></p>
<p>字典树又称单词查找树，Trie 树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。</p>
</li>
<li><p>Trie 的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有 3 个基本性质:<br>a. 根节点不包含字符，除根节点外每一个节点都只包含一个字符。<br>b. 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。<br>c. 每个节点的所有子节点包含的字符都不相同。对于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度 O(1)。</p>
</li>
</ul>
<h1 id="Elasticsearch-中的集群、节点、索引、文档、类型是什么？"><a href="#Elasticsearch-中的集群、节点、索引、文档、类型是什么？" class="headerlink" title="Elasticsearch 中的集群、节点、索引、文档、类型是什么？"></a>Elasticsearch 中的集群、节点、索引、文档、类型是什么？</h1><ul>
<li>集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</li>
<li>节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</li>
<li>索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一<br>个或多个主分片，并且可以有零个或多个副本分片。 MySQL &#x3D;&gt;数据库 Elasticsearch &#x3D;&gt;索引</li>
<li>文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL &#x3D;&gt; Databases &#x3D;&gt; Tables &#x3D;&gt; Columns &#x2F; Rows Elasticsearch &#x3D;&gt; Indices &#x3D;&gt; Types &#x3D;&gt;具有属性的文档</li>
<li>类型是索引的逻辑类别&#x2F;分区，其语义完全取决于用户。</li>
</ul>
<h1 id="Elasticsearch-中的倒排索引是什么？"><a href="#Elasticsearch-中的倒排索引是什么？" class="headerlink" title="Elasticsearch 中的倒排索引是什么？"></a>Elasticsearch 中的倒排索引是什么？</h1><p>倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。ES中的倒排索引其实就是 lucene 的倒排索引，区别于传统的正向索引，倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  <div>
  
  </div>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">117</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
