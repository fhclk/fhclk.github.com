<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Spark框架概述定义Apache Spark是用于大规模数据处理的统一分析引擎。 RDD：弹性分布式数据集。RDD是一种分布式内存抽象，其使得程序员能够在大规模集群中做内存运算，并且有一定的容错方式。而这也是整个Spark的核心数据结构，Spark整个平台都围绕着RDD进行。  Spark的特点是对任意类型的数据进行自定义计算。它可以计算结构化、半结构化、非结构化等各种类型的数据结构。同时也支持">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark基础">
<meta property="og:url" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:description" content="Spark框架概述定义Apache Spark是用于大规模数据处理的统一分析引擎。 RDD：弹性分布式数据集。RDD是一种分布式内存抽象，其使得程序员能够在大规模集群中做内存运算，并且有一定的容错方式。而这也是整个Spark的核心数据结构，Spark整个平台都围绕着RDD进行。  Spark的特点是对任意类型的数据进行自定义计算。它可以计算结构化、半结构化、非结构化等各种类型的数据结构。同时也支持">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221426265.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221847274.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208223515333.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208223922127.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208225238293.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208225924296.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210151603188.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210152323860.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210155620073.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210155700797.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210163520123.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210172323763.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180238773.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210182646551.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180341609.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210181813615.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180524025.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210202831245.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210202906475.png">
<meta property="article:published_time" content="2022-02-01T13:07:40.000Z">
<meta property="article:modified_time" content="2022-12-10T12:29:30.366Z">
<meta property="article:author" content="fhclk">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221426265.png">

<link rel="canonical" href="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Spark基础 | 拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/01/Spark%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark基础
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-01 21:07:40" itemprop="dateCreated datePublished" datetime="2022-02-01T21:07:40+08:00">2022-02-01</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Spark框架概述"><a href="#Spark框架概述" class="headerlink" title="Spark框架概述"></a>Spark框架概述</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>Apache Spark是用于大规模数据处理的统一分析引擎。</p>
<p>RDD：弹性分布式数据集。RDD是一种分布式内存抽象，其使得程序员能够在大规模集群中做内存运算，并且有一定的容错方式。而这也是整个Spark的核心数据结构，Spark整个平台都围绕着RDD进行。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221426265.png" alt="image-20221208221426265"></p>
<p>Spark的特点是对任意类型的数据进行自定义计算。它可以计算结构化、半结构化、非结构化等各种类型的数据结构。同时也支持使用Python、Java、Scala、R及SQL语言去开发应用程序计算数据。</p>
<h2 id="Spark-VS-Hadoop-MapReduce"><a href="#Spark-VS-Hadoop-MapReduce" class="headerlink" title="Spark VS Hadoop(MapReduce)"></a>Spark VS Hadoop(MapReduce)</h2><p>Spark和Hadoop技术栈的区别：</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208221847274.png" alt="image-20221208221847274"></p>
<p>尽管Spark相对Hadoop具有较大优势，但Spark并不能完全替代Hadoop。</p>
<ul>
<li>在计算层面，Spark相比较MapReduce有巨大的性能优势，但至今仍有许多计算工具基于MapReduce架构，比如非常成熟的Hive</li>
<li>Spark仅做计算，而Hadoop生态圈不仅有计算（MapReduce），也有存储（HDFS）和资源管理调度（YARN），HDFS和YARN仍是许多大数据体系的核心架构。</li>
</ul>
<h2 id="Spark四大特点"><a href="#Spark四大特点" class="headerlink" title="Spark四大特点"></a>Spark四大特点</h2><h3 id="速度快"><a href="#速度快" class="headerlink" title="速度快"></a>速度快</h3><p>Spark支持内存计算，并且通过DAG（有向无环图）执行引擎支持无环数据流，其在内存中运行速度比MapReduce快（官方宣称比MapReduce快100倍，在硬盘中快10倍）。</p>
<p>Spark处理数据与MapReduce处理数据相比，有两个不同点：</p>
<ul>
<li>Spark处理数据时，可以将中间处理结果存储到内存中。</li>
<li>Spark提供了非常丰富的算子（API），可以做到复杂任务在一个Spark程序中完成。</li>
</ul>
<h3 id="易于使用"><a href="#易于使用" class="headerlink" title="易于使用"></a>易于使用</h3><p>Spark支持使用Python、Java、Scala、R及SQL语言去开发应用程序</p>
<h3 id="通用性强"><a href="#通用性强" class="headerlink" title="通用性强"></a>通用性强</h3><p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208223515333.png" alt="image-20221208223515333"></p>
<p>可以在一个应用中无缝地使用这些工具库。</p>
<h3 id="运行方式"><a href="#运行方式" class="headerlink" title="运行方式"></a>运行方式</h3><p>Spark支持多种运行方式。包括Hadoop和Mesos，也支持Standalone的独立运行模式，也可以运行在云Kubernetes上。</p>
<p>对于数据源，Spark支持HDFS、HBase、Cassandra及Kafka等。</p>
<h2 id="Spark框架模块"><a href="#Spark框架模块" class="headerlink" title="Spark框架模块"></a>Spark框架模块</h2><p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208223922127.png" alt="image-20221208223922127"></p>
<p><strong>Spark Core</strong></p>
<p>Spark的核心，提供Spark核心功能，是Spark运行的基础。Spark Core以RDD为数据抽象，提供Python、Java、Scala、R语言的API，可以编程进行海量离线数据批处理计算。</p>
<p><strong>SparkSQL</strong></p>
<p>基于SparkCore之上，提供结构化数据的处理模块，SparkSQL支持以SQL语言对数据进行处理，SparkSQL本身针对离线计算场景。同时基于SparkSQL，Spark提供了StructedStreaming模块，进行数据流式计算。</p>
<p><strong>SparkStreaming</strong></p>
<p>以SparkCore为基础，提供数据流式计算的功能。</p>
<p><strong>MLlib</strong></p>
<p>以SparkCore为基础，进行机器学习，内置大量机器学习卡和API算法。</p>
<p><strong>GraphX</strong></p>
<p>以SparkCore为基础，进行图计算</p>
<h2 id="Spark运行模式"><a href="#Spark运行模式" class="headerlink" title="Spark运行模式"></a>Spark运行模式</h2><p><strong>本地模式（单机）</strong></p>
<p>以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行环境</p>
<p><strong>Standalone模式（集群）</strong></p>
<p>Spark中各个角色以独立进程的形式存在，并组成Spark集群环境</p>
<p><strong>Hadoop YARN模式（集群）</strong></p>
<p>Spark中的各个角色运行在YARN的容器内部，并组成Spark集群环境</p>
<p><strong>Kubernetes模式（容器集群）</strong></p>
<p>Spark中的各个角色运行在Kubernetes的容器内部，并组成Spark集群环境</p>
<h3 id="Spark的架构角色"><a href="#Spark的架构角色" class="headerlink" title="Spark的架构角色"></a>Spark的架构角色</h3><h4 id="YARN角色"><a href="#YARN角色" class="headerlink" title="YARN角色"></a>YARN角色</h4><p>资源管理层面：</p>
<ul>
<li>集群资源管理者（Master）：ResourceManager</li>
<li>单机资源管理者（Worker）：NodeManager</li>
</ul>
<p>任务计算层面：</p>
<ul>
<li>单任务管理者（Master）：ApplicationMaster</li>
<li>单任务执行者（Worder）：Task（容器内计算框架的工作角色）</li>
</ul>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208225238293.png" alt="image-20221208225238293"></p>
<h4 id="Spark运行角色"><a href="#Spark运行角色" class="headerlink" title="Spark运行角色"></a>Spark运行角色</h4><p>资源管理层面：</p>
<ul>
<li>管理者：Master角色（管理整个集群的资源），YARN是ResourceManager</li>
<li>工作者：Worker角色（管理单个服务器的资源），YARN是NodeManager</li>
</ul>
<p>任务执行层面</p>
<ul>
<li>某任务管理者：Driver角色（管理单个任务在运行的时候的工作），YARN是ApplicationMaster</li>
<li>某任务执行者：Executor角色（单个任务运行的时候的一堆工作者，干活的），YARN是容器中运行的具体工作进程（TASK）</li>
</ul>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221208225924296.png" alt="image-20221208225924296"></p>
<h1 id="Spark部署方式"><a href="#Spark部署方式" class="headerlink" title="Spark部署方式"></a>Spark部署方式</h1><h2 id="Local"><a href="#Local" class="headerlink" title="Local"></a>Local</h2><p>Local模式是以一个独立进程配合其内部线程来提供完成Spark运行时环境。Local模式可以通过spark-shell&#x2F;pyspark&#x2F;spark-submit等来开启。</p>
<h2 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h2><h3 id="Standalone架构"><a href="#Standalone架构" class="headerlink" title="Standalone架构"></a>Standalone架构</h3><p>Standalone模式是Sark自带的一种集群模式，不同于本地模式启动多个进程来模拟集群环境，Standalone模式是真实的在多个机器之间搭建Spark集群的环境，完全可以利用该模式搭建多机器机器，用于实际的大数据处理。</p>
<p>Standalone是完整的Spark运行环境，其中Master角色以Master进程存在，Worker角色以Worker进程存在。Driver和Executor运行于Worker进程内，由Worker提供资源供给它们运行。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210151603188.png" alt="image-20221210151603188"></p>
<p>Standalone集群在进程上主要有3类进程：</p>
<ol>
<li><p>主节点Master进程</p>
<p>Master角色，管理整个集群资源，并托管运行各个任务的Driver。</p>
</li>
<li><p>从节点Workers</p>
<p>Worker角色，管理每个集群的资源，分配对应的资源来运行Executor（TASK）；每个从节点分配资源信息给Worker管理，资源信息包含Memory和CPU Cores核数</p>
</li>
<li><p>历史服务器HistoryServer（可选）</p>
<p>Spark Application运行完成后，保存事件日志数据至HDFS，启动HistoryServer可以查看应用运行相关信息</p>
</li>
</ol>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210152323860.png" alt="image-20221210152323860"></p>
<h3 id="Spark应用架构"><a href="#Spark应用架构" class="headerlink" title="Spark应用架构"></a>Spark应用架构</h3><p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210155620073.png" alt="image-20221210155620073"></p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210155700797.png" alt="image-20221210155700797"></p>
<p>从上图可以看出Spark Application运行到集群上时，由两部分组成：Driver Program和Excutors。</p>
<p><strong>Driver Program</strong></p>
<p>相当于AppMaster，整个应用的管理者，负责应用中所有Job的调度执行。</p>
<p>运行JVM Process，运行程序的main函数，必须建立SparkContext上下文对象。</p>
<p>一个SparkApplication仅有一个。</p>
<p><strong>Executors</strong></p>
<p>相当于一个线程池，运行JVM Process，其中有很多线程，每个线程运行一个Task任务，一个Task任务运行需要1 core CPU，所以可以认为Executor中线程数就等于CPU core核数。</p>
<p>一个Spark Application中可以有多个Executors，可以设置个数和资源信息。</p>
<p><strong>执行流程</strong></p>
<p>用户程序从最开始的提交到最终的计算执行，需要经历一下几个阶段：</p>
<ol>
<li>用户程序创建SparkContext时，新创建的SparkContext实例会连接到ClusterManager。 ClusterManager会根据用户提交时设置的CPU和内存等信息为本次提交分配计算资源，启动Executor。</li>
<li>Driver会将用户程序划分为不同的执行阶段Stage，每个执行阶段Stage由一组完全相同的Task组成，这些Task分别作用于待处理数据的不同分区。在接到划分完成和Task创建后，Driver会向Executor发送Task。</li>
<li>Executor在接收到Task后，会下载Task的运行时依赖，在准备好Task的执行环境后，会开始执行Task，并且将Task的运行状态汇报给Driver。</li>
<li>Driver会根据收到的Task的运行状态来处理不同的状态更新。Task分两种：一种时Shuffle Map Task，它实现数据的重新洗牌，洗牌的结果保存到Executor所在节点的文件系统中；另外一种是Result Task，它负责生成结果数据。</li>
<li>Driver会不断地调用Task，将Task发送到Executor执行，在所有地Task都正确执行或者超过执行次数地限制仍然没有执行成功时停止。</li>
</ol>
<p><strong>Spark程序运行层次结构</strong></p>
<p>Spark Application程序运行时三个核心概念：Job、Stage、Task。</p>
<ul>
<li><strong>Job</strong> ：由多个Task地并行计算部分，一般Spark中的action操作（如save、collect）会生成一个Job</li>
<li><strong>Stage</strong> ：Job的组成单位，一个Job会切分成多个Stage，Stage彼此之间互相依赖顺序执行，而每个Stage是多个Task的集合，类似map和reduce stage</li>
<li><strong>Task</strong> ：被分配到Executor的单位工作内容，它是Spark中的最小执行单位，一般来说有多少个paritition，就会有多少个Task，就会有多少个Task，每个Task只会处理单一分支上的数据。</li>
</ul>
<blockquote>
<p>一个Spark Application中，包含多个Job，每个Job有多个Stage组成，每个Job的执行安装DAG图进行的。其中每个Satge中包含多个Task任务，每个Task以线程方式执行。</p>
</blockquote>
<p><strong>端口</strong></p>
<ul>
<li>4040：是一个运行的Application在运行的过程中临时绑定的端口，用以查看当前的任务状态。4040被占用会顺延到4041、4042等。4040是一个临时端口，当程序运行完成后，4040就会被注销。</li>
<li>8080：默认时Standalone下，Master角色的web端口，用以查看当前Master（集群）的状态</li>
<li>18080：默认时历史服务器的端口，由于每个程序运行完成后，4040端口就被注销了，可以通过历史服务费回看某个程序的运行状态。</li>
</ul>
<h2 id="Standalone-HA"><a href="#Standalone-HA" class="headerlink" title="Standalone HA"></a>Standalone HA</h2><p>基于Zookeeper实现HA</p>
<p>Zookeeer提供了一个Leader Election机制，利用这个机制可以保证虽然集群存在多个Master，但是只有一个是Active，其他的都是Standby。当Active的Master出现故障时，另外的一个Standy Master会被选举出来。由于集群的信息，及woker、driver和Application的信息都已经持久化到文件系统，因此在切换的过程中只会影响新Job的提交，对于正在进行的Job没有任何影响。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210163520123.png" alt="image-20221210163520123"></p>
<h2 id="Spark-On-YARN"><a href="#Spark-On-YARN" class="headerlink" title="Spark On YARN"></a>Spark On YARN</h2><p>多数情况下，各企业都会有Haddop集群，为了节约服务器资源，将Spark运行到YARN集群中，不需要再单独部署Spark Standalone集群。</p>
<p>在Spark on YARN中，无需部署Spark集群，只要一个服务器充当Spark客户端，即可提交任务到YARN集群中运行。</p>
<h3 id="Spark-On-YARN的本质"><a href="#Spark-On-YARN的本质" class="headerlink" title="Spark On YARN的本质"></a>Spark On YARN的本质</h3><p>Master角色由YARN的ResourceManager担任。</p>
<p>Worker角色由YARN的NodeManager担任。</p>
<p>Driver角色运行在YARN容器内或提交任务的客户端进程中。</p>
<p>真正干活的Executor运行在YARN提供的容器内。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210172323763.png" alt="image-20221210172323763"></p>
<h3 id="部署模式DeloyMode"><a href="#部署模式DeloyMode" class="headerlink" title="部署模式DeloyMode"></a>部署模式DeloyMode</h3><p><strong>Cluster模式</strong></p>
<p>Driver运行在YARN容器内部，和ApplicationMaster在同一个容器内</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180238773.png" alt="image-20221210180238773"></p>
<p>详细流程：</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210182646551.png" alt="image-20221210182646551"></p>
<p>具体流程步骤：</p>
<ol>
<li>任务提交后会和ResourceManager通讯申请启动ApplicationMaster；</li>
<li>随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster就是Driver；</li>
<li>Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后在合适的NodeManager上启动Executor进程；</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将Task分发到各个Executor上执行</li>
</ol>
<p><strong>Client模式</strong></p>
<p>Driver运行在客户端进程中，比如Driver运行在spark-submit程序的进程中</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180341609.png" alt="image-20221210180341609"></p>
<p>详细流程：</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210181813615.png" alt="image-20221210181813615"></p>
<p>具体流程步骤：</p>
<ol>
<li>Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster；</li>
<li>随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存；</li>
<li>ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程；</li>
<li>Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；</li>
<li>之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将Task分发到各个Executor上执行</li>
</ol>
<p><strong>两种模式的区别</strong></p>
<img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210180524025.png" alt="image-20221210180524025" style="zoom:80%;">



<p><strong>使用方式</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME = /export/server/spark</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">&#123;SPARK_HOME&#125;/bin/spark-submit --master yarn -- deploy-mode client|cluster test.py</span></span><br></pre></td></tr></table></figure>





<h1 id="PySpark"><a href="#PySpark" class="headerlink" title="PySpark"></a>PySpark</h1><p>PySpark是Spark官方提供的一个Python类库，内置了完全的Spark API，可以通过PySpark类库来编写Spark应用程序，并将其提交到Spark集群中运行。</p>
<p>Python On Spark执行原理</p>
<p>PySark宗旨是在不破坏Spark已有的运行时架构，在Spark架构外层包装一层Python API，借助Py4j实现Python和Java的交互，进而实现通过Python编写Spark应用程序，其运行时架构如图所示。</p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210202831245.png" alt="image-20221210202831245"></p>
<p><img src="/2022/02/01/Spark%E5%9F%BA%E7%A1%80/image-20221210202906475.png" alt="image-20221210202906475"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <!-- <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a> -->
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i>  大数据</a>
              <!-- <a href="/tags/Spark/" rel="tag"># Spark</a> -->
              <a href="/tags/Spark/" rel="tag"><i class="fa fa-tag"></i>  Spark</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/13/%E5%81%9A%E4%B8%80%E4%B8%AA%E6%9C%89%E6%B8%A9%E5%BA%A6%E6%9C%89%E6%9D%A1%E7%90%86%E7%9A%84%E8%A1%A8%E8%BE%BE%E8%80%85/" rel="prev" title="做一个有温度有条理的表达者">
      <i class="fa fa-chevron-left"></i> 做一个有温度有条理的表达者
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/" rel="next" title="Spark核心编程">
      Spark核心编程 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  <div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:1rem;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  
  </div>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">Spark框架概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89"><span class="nav-number">1.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-VS-Hadoop-MapReduce"><span class="nav-number">1.2.</span> <span class="nav-text">Spark VS Hadoop(MapReduce)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark%E5%9B%9B%E5%A4%A7%E7%89%B9%E7%82%B9"><span class="nav-number">1.3.</span> <span class="nav-text">Spark四大特点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9F%E5%BA%A6%E5%BF%AB"><span class="nav-number">1.3.1.</span> <span class="nav-text">速度快</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%98%93%E4%BA%8E%E4%BD%BF%E7%94%A8"><span class="nav-number">1.3.2.</span> <span class="nav-text">易于使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E6%80%A7%E5%BC%BA"><span class="nav-number">1.3.3.</span> <span class="nav-text">通用性强</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F"><span class="nav-number">1.3.4.</span> <span class="nav-text">运行方式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark%E6%A1%86%E6%9E%B6%E6%A8%A1%E5%9D%97"><span class="nav-number">1.4.</span> <span class="nav-text">Spark框架模块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.5.</span> <span class="nav-text">Spark运行模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark%E7%9A%84%E6%9E%B6%E6%9E%84%E8%A7%92%E8%89%B2"><span class="nav-number">1.5.1.</span> <span class="nav-text">Spark的架构角色</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#YARN%E8%A7%92%E8%89%B2"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">YARN角色</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark%E8%BF%90%E8%A1%8C%E8%A7%92%E8%89%B2"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">Spark运行角色</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F"><span class="nav-number">2.</span> <span class="nav-text">Spark部署方式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Local"><span class="nav-number">2.1.</span> <span class="nav-text">Local</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Standalone"><span class="nav-number">2.2.</span> <span class="nav-text">Standalone</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Standalone%E6%9E%B6%E6%9E%84"><span class="nav-number">2.2.1.</span> <span class="nav-text">Standalone架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84"><span class="nav-number">2.2.2.</span> <span class="nav-text">Spark应用架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Standalone-HA"><span class="nav-number">2.3.</span> <span class="nav-text">Standalone HA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-On-YARN"><span class="nav-number">2.4.</span> <span class="nav-text">Spark On YARN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-On-YARN%E7%9A%84%E6%9C%AC%E8%B4%A8"><span class="nav-number">2.4.1.</span> <span class="nav-text">Spark On YARN的本质</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8FDeloyMode"><span class="nav-number">2.4.2.</span> <span class="nav-text">部署模式DeloyMode</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PySpark"><span class="nav-number">3.</span> <span class="nav-text">PySpark</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">160</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
