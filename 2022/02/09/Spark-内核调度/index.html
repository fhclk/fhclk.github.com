<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fhclk.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="DAGSpark的核心是根据RDD来实现的，Spark Scheduler则为Spark核心实现的重要一环，其作用就是任务调度。Spark的任务调度就是如何组织任务去处理RDD中每个分区的数据，根据RDD的依赖关系构建DAG，基于DAG划分Stage，将每个Stage中的任务发到指定的节点运行。基于Spark的任务调度原理，可以合理规划资源利用，做到尽可能最少的资源高效地完成任务计算。 WordC">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark内核调度">
<meta property="og:url" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/index.html">
<meta property="og:site_name" content="拾荒者">
<meta property="og:description" content="DAGSpark的核心是根据RDD来实现的，Spark Scheduler则为Spark核心实现的重要一环，其作用就是任务调度。Spark的任务调度就是如何组织任务去处理RDD中每个分区的数据，根据RDD的依赖关系构建DAG，基于DAG划分Stage，将每个Stage中的任务发到指定的节点运行。基于Spark的任务调度原理，可以合理规划资源利用，做到尽可能最少的资源高效地完成任务计算。 WordC">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207141854497.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207142235571.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207142737106.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143426357.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143755864.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143830716.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208092610241.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208094448308.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208100811888.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208103531463.png">
<meta property="og:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208103955136.png">
<meta property="article:published_time" content="2022-02-09T06:07:07.000Z">
<meta property="article:modified_time" content="2022-12-08T03:02:06.532Z">
<meta property="article:author" content="fhclk">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207141854497.png">

<link rel="canonical" href="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Spark内核调度 | 拾荒者</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">拾荒者</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">昨夜西风凋碧树，独上高楼，望尽天涯路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://fhclk.github.io/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.png">
      <meta itemprop="name" content="fhclk">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="拾荒者">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark内核调度
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-09 14:07:07" itemprop="dateCreated datePublished" datetime="2022-02-09T14:07:07+08:00">2022-02-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h1><p>Spark的核心是根据RDD来实现的，Spark Scheduler则为Spark核心实现的重要一环，其作用就是任务调度。Spark的任务调度就是如何组织任务去处理RDD中每个分区的数据，根据RDD的依赖关系构建DAG，基于DAG划分Stage，将每个Stage中的任务发到指定的节点运行。基于Spark的任务调度原理，可以合理规划资源利用，做到尽可能最少的资源高效地完成任务计算。</p>
<p>WordCount的DAG图：</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207141854497.png" alt="image-20221207141854497"></p>
<h2 id="DAG-1"><a href="#DAG-1" class="headerlink" title="DAG"></a>DAG</h2><p>DAG：有向无环图（有方向没有形成闭环的一个执行流程图），标识代码的逻辑执行流程。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207142235571.png" alt="image-20221207142235571"></p>
<p><strong>JOB和Action</strong></p>
<p>Action：返回值不是RDD的算子。它的作用是一个出发开关，会将Action算子之前的一串rdd依赖链条执行起来。一个Action会产生一个DAG图。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207142737106.png" alt="image-20221207142737106"></p>
<blockquote>
<p>1个Action会产生一个DAG，会在程序运行中产生一个JOB。 <code>1个Action = 1个DAG = 1个JOB</code></p>
<p>一个代码运行起来，在Spark中称之为Application。1个Application中，可以有多个JOB，每个JOB内含有一个DAG，同时每个JOB都是由一个Action产生的。</p>
</blockquote>
<p><strong>DAG和分区</strong></p>
<p>Spark是分布式（多分区）的，那么DAG和分区之间也是有关联的。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143426357.png" alt="image-20221207143426357"></p>
<h1 id="DAG的宽窄依赖和阶段划分"><a href="#DAG的宽窄依赖和阶段划分" class="headerlink" title="DAG的宽窄依赖和阶段划分"></a>DAG的宽窄依赖和阶段划分</h1><p>SparkRDD前后之间的关系分为<code>宽依赖</code>和<code>窄依赖</code>。</p>
<p>窄依赖：父RDD的一个分区，全部将数据发给子RDD的一个分区。</p>
<p>宽依赖：父RDD的一个分区，将数据发给RDD的多个分区。</p>
<p>宽依赖还有一个别名：shuffle</p>
<h2 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h2><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143755864.png" alt="image-20221207143755864"></p>
<h2 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h2><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221207143830716.png" alt="image-20221207143830716"></p>
<h2 id="阶段划分"><a href="#阶段划分" class="headerlink" title="阶段划分"></a>阶段划分</h2><p>对于Spark来说，会根据DAG，按照宽依赖，划分不同的DAG阶段。</p>
<p>划分依据：从后向前，遇到宽依赖，就划分出一个阶段，称之为stage。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208092610241.png" alt="image-20221208092610241"></p>
<p>在stage内部，一定都是窄依赖。</p>
<h1 id="内存迭代计算"><a href="#内存迭代计算" class="headerlink" title="内存迭代计算"></a>内存迭代计算</h1><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208094448308.png" alt="image-20221208094448308"></p>
<p>如图，基于带有分区的DAG，从图中可以得到逻辑上的最优task分配。一个task是一个线程来具体执行。图中task1中rdd1、rdd2和rdd3的迭代计算，都是由一个task（线程）完成，这一阶段的这条线，是纯内存计算。task1、task2和task3形成了3个并行的内存计算管道。</p>
<p>Spark默认受全局并行度的限制，除了个别算子有特殊分区情况，大部分算子，都会遵循全局并行的要求，来规划自己的分区数。如果全局并行度是3，其实大部分算子分区都是3。</p>
<blockquote>
<p>在Spark中，推荐只设置全局并行度，不要在算子上设置并行度</p>
</blockquote>
<h1 id="Spark并行度"><a href="#Spark并行度" class="headerlink" title="Spark并行度"></a>Spark并行度</h1><p>Spark的并行：在同一时间内，有多少个task在同时运行。</p>
<p>并行度：并行能力的设置。</p>
<p>比如：设置并行度是6，就有6个task并行执行，rdd的分区就被规划成6个分区。</p>
<h2 id="如何设置并行度"><a href="#如何设置并行度" class="headerlink" title="如何设置并行度"></a>如何设置并行度</h2><p>可以在代码中和配置文件中以及提交程序的客户端参数中设置。</p>
<p>优先级从高到低：</p>
<ol>
<li>代码中</li>
<li>客户端提交参数中</li>
<li>配置文件中</li>
<li>默认（1，但是不会全部以1来执行，多数情况下基于读取文件的分片数量来作为默认并行度）</li>
</ol>
<p>全局并行度配置参数</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spark.default.parallelism</span></span><br></pre></td></tr></table></figure>

<p><strong>推荐全局设置并行度</strong></p>
<p>配置文件中：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">conf/spark-defaults.conf中设置</span></span><br><span class="line"><span class="attr">spark.default.parallelism</span> <span class="string">100</span></span><br></pre></td></tr></table></figure>

<p>在客户端提交参数中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --conf &quot;spark.default.parallelism=100&quot;</span><br></pre></td></tr></table></figure>

<p>在代码中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf()</span><br><span class="line">conf.<span class="built_in">set</span>(<span class="string">&quot;spark.default.parallelism&quot;</span>, <span class="string">&quot;100&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>全局并行度是推荐设置，不要针对RDD改分区，可能会影响内存迭代管道的构建，或者会产生额外的shuffle</p>
</blockquote>
<h2 id="集群中如何规划并行度"><a href="#集群中如何规划并行度" class="headerlink" title="集群中如何规划并行度"></a>集群中如何规划并行度</h2><p>设置为cpu总核的2<del>10倍。比如集群可用cpu核心是100个，建议并行度是200</del>1000。</p>
<p>设置成cpu核心的倍数，目的是让cpu尽量不空闲，执行完一个task后有其他task可以继续执行，提高cpu利用率。</p>
<h1 id="Spark任务调度"><a href="#Spark任务调度" class="headerlink" title="Spark任务调度"></a>Spark任务调度</h1><p>Spark的任务，由Driver进行调度，这个工作包括：</p>
<ol>
<li>逻辑DAG产生</li>
<li>分区DAG产生</li>
<li>Task划分</li>
<li>将Task分配给Executor并监控其工作</li>
</ol>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208100811888.png" alt="image-20221208100811888"></p>
<p>如图：Spark程序的调度流程：</p>
<ol>
<li>构建Driver</li>
<li>构建SparkContext（执行环境入口对象）</li>
<li>基于DAG Scheduler（DAG调度器）构建逻辑Task分配</li>
<li>基于TaskScheduler（Task调度器）将逻辑Task分配到各个Executor上干活，并监控它们。</li>
<li>Worker（Executor），被TaskScheduler管理监控，听从它们的指令干活，并定期汇报进度。</li>
</ol>
<p>Driver内的两个组件：</p>
<ol>
<li>DAG调度器：将逻辑DAG图进行处理，最终得到逻辑上的Task划分。</li>
<li>TASK调度器：基于DAG Scheduler的产出，类规划这些逻辑TASK应该在哪些物理的Executor上运行，以及监控管理它们的运行。</li>
</ol>
<h1 id="Spark概念名词大全"><a href="#Spark概念名词大全" class="headerlink" title="Spark概念名词大全"></a>Spark概念名词大全</h1><ul>
<li>ClusterManager：在Standalone模式中即为Master（主节点），控制整个集群，监控Worker。在YARN模式中为资源管理器。</li>
<li>Worker：从节点，负责控制计算节点，启动Executor。在YARN模式中为NodeManager，负责计算节点的控制。</li>
<li>Driver：运行Application的main()函数并创建SparkContext。</li>
<li>Executor：执行器，在worker node上执行任务的组件、用于启动线程池运行任务。每个Application拥有独立的一组Executors。</li>
<li>SparkContext：整个应用的上下文，控制应用的生命周期。</li>
<li>RDD：Spark的基本计算单元，一组RDD可形成执行的有向无环图RDD Graph。</li>
<li>DAG Scheduler：实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</li>
<li>TaskScheduler：将任务（Task）分发给Executor执行。（所以Executor执行的就是我们的代码）</li>
<li>Stage：一个Spark作业一般包含一到多个Stage。</li>
<li>Task：一个Stage包含一到多个Task，通过多个Task实现并行运行的功能。</li>
<li>Transformations：转换(Transformations) (如：map, filter, groupBy, join等)，Transformations操作是Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算。（后面的wc例子就会有很好的说明）</li>
<li>Actions：操作(Actions) (如：count, collect, save等)，Actions操作会返回结果或把RDD数据写到存储系统中。Actions是触发Spark启动计算的动因。</li>
<li>SparkEnv：线程级别的上下文，存储运行时的重要组件的引用。SparkEnv内创建并包含如下一些重要组件的引用。</li>
<li>MapOutPutTracker：负责Shuffle元信息的存储。</li>
<li>BroadcastManager：负责广播变量的控制与元信息的存储。</li>
<li>BlockManager：负责存储管理、创建和查找块。</li>
<li>MetricsSystem：监控运行时性能指标信息。</li>
<li>SparkConf：负责存储配置信息。</li>
</ul>
<h2 id="Spark层级梳理"><a href="#Spark层级梳理" class="headerlink" title="Spark层级梳理"></a>Spark层级梳理</h2><ol>
<li>一个Spark环境可以运行多个Application。</li>
<li>一个代码运行起来，会称为一个Application。</li>
<li>Application内部可以有多个Job</li>
<li>每个Job由一个Action产生，并且每个Job有自己的DAG执行图</li>
<li>一个Job的DAG图，会基于窄依赖和宽依赖划分成不同的阶段</li>
<li>不同阶段内基于分区数量，形成多个并行的内存迭代管道</li>
<li>每个内存迭代管道形成一个Task（DAG调度器划分将JOB内划分出具体的Task任务，一个JOB被划分出来的task在逻辑上称之为这个job的taskset）</li>
</ol>
<h2 id="Spark-Shuffle"><a href="#Spark-Shuffle" class="headerlink" title="Spark Shuffle"></a>Spark Shuffle</h2><h3 id="MapReduce-Shuffle"><a href="#MapReduce-Shuffle" class="headerlink" title="MapReduce Shuffle"></a>MapReduce Shuffle</h3><p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208103531463.png" alt="image-20221208103531463"></p>
<h3 id="Spark-Shuffle-1"><a href="#Spark-Shuffle-1" class="headerlink" title="Spark Shuffle"></a>Spark Shuffle</h3><p>Spark在DAG调度阶段会将一个Job划分成多个Stage，上游Stage做map工作，下游Stage做Reduce工作，其本质上还是MapReduce计算框架。</p>
<p>Shuffle是连接map和reduce之间的桥梁，它将map的输出对应到reduce输入中，涉及到序列化、跨节点网络IO以及磁盘读写IO等。</p>
<p><img src="/2022/02/09/Spark-%E5%86%85%E6%A0%B8%E8%B0%83%E5%BA%A6/image-20221208103955136.png" alt="image-20221208103955136"></p>
<p>Spark的Shuffle分为Write和Read两个阶段，分属于两个不同的Stage，前者是Parent Stage的最后一步，后者是Child Stage的第一步。</p>
<p>执行Shuffle的主体是Stage中的并发任务，这些任务份ShuffleMapTask和ResultTask两种，ShuffleMapTask要进行Shuffle，ResultTask负责返回计算结果，一个Job中只有最后的Stage采用ResultTask，其他的均为ShuffleMapTask。如果要按照map段和reduce端来分析的话，ShuffleMapTask可以即是map端任务，又是reduce端任务，因为Spark中Shuffle是可以串行的；ResultTask则只能充当reduce端任务的角色。</p>
<h3 id="ShuffleManager（Shuffle管理器）"><a href="#ShuffleManager（Shuffle管理器）" class="headerlink" title="ShuffleManager（Shuffle管理器）"></a>ShuffleManager（Shuffle管理器）</h3><p>ShuffleManager：负责Shuffle过程的执行、计算和处理。</p>
<p>实现方式有两种：HashShuffleManager和SortShuffleManager</p>
<h4 id="HashShuffleManager"><a href="#HashShuffleManager" class="headerlink" title="HashShuffleManager"></a>HashShuffleManager</h4><p>Spark1.2以前，默认的shuffle计算引擎，其缺点是会产生大量的中间磁盘文件，进而有大量的磁盘IO操作影响了性能。</p>
<h4 id="SortShuffleManager"><a href="#SortShuffleManager" class="headerlink" title="SortShuffleManager"></a>SortShuffleManager</h4><p>Spark1.2后，默认的ShuffleManager。对比HashShuffleManager的改进，每个task在进行shuffle操作时，虽然也会产生大量的中间磁盘文件，但是最后会将所有的临时文件合并（merge）成一个磁盘文件，因此每个task就只有一个磁盘文件。在下一次读取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <!-- <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a> -->
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i>  大数据</a>
              <!-- <a href="/tags/Spark/" rel="tag"># Spark</a> -->
              <a href="/tags/Spark/" rel="tag"><i class="fa fa-tag"></i>  Spark</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/05/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/" rel="prev" title="Spark核心编程">
      <i class="fa fa-chevron-left"></i> Spark核心编程
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/02/18/SparkSQL/" rel="next" title="SparkSQL">
      SparkSQL <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  <div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:22px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  
  </div>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#DAG"><span class="nav-number">1.</span> <span class="nav-text">DAG</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#DAG-1"><span class="nav-number">1.1.</span> <span class="nav-text">DAG</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DAG%E7%9A%84%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96%E5%92%8C%E9%98%B6%E6%AE%B5%E5%88%92%E5%88%86"><span class="nav-number">2.</span> <span class="nav-text">DAG的宽窄依赖和阶段划分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AA%84%E4%BE%9D%E8%B5%96"><span class="nav-number">2.1.</span> <span class="nav-text">窄依赖</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%BD%E4%BE%9D%E8%B5%96"><span class="nav-number">2.2.</span> <span class="nav-text">宽依赖</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%98%B6%E6%AE%B5%E5%88%92%E5%88%86"><span class="nav-number">2.3.</span> <span class="nav-text">阶段划分</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E8%BF%AD%E4%BB%A3%E8%AE%A1%E7%AE%97"><span class="nav-number">3.</span> <span class="nav-text">内存迭代计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="nav-number">4.</span> <span class="nav-text">Spark并行度</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="nav-number">4.1.</span> <span class="nav-text">如何设置并行度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E4%B8%AD%E5%A6%82%E4%BD%95%E8%A7%84%E5%88%92%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="nav-number">4.2.</span> <span class="nav-text">集群中如何规划并行度</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6"><span class="nav-number">5.</span> <span class="nav-text">Spark任务调度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark%E6%A6%82%E5%BF%B5%E5%90%8D%E8%AF%8D%E5%A4%A7%E5%85%A8"><span class="nav-number">6.</span> <span class="nav-text">Spark概念名词大全</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark%E5%B1%82%E7%BA%A7%E6%A2%B3%E7%90%86"><span class="nav-number">6.1.</span> <span class="nav-text">Spark层级梳理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-Shuffle"><span class="nav-number">6.2.</span> <span class="nav-text">Spark Shuffle</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce-Shuffle"><span class="nav-number">6.2.1.</span> <span class="nav-text">MapReduce Shuffle</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Shuffle-1"><span class="nav-number">6.2.2.</span> <span class="nav-text">Spark Shuffle</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ShuffleManager%EF%BC%88Shuffle%E7%AE%A1%E7%90%86%E5%99%A8%EF%BC%89"><span class="nav-number">6.2.3.</span> <span class="nav-text">ShuffleManager（Shuffle管理器）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HashShuffleManager"><span class="nav-number">6.2.3.1.</span> <span class="nav-text">HashShuffleManager</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SortShuffleManager"><span class="nav-number">6.2.3.2.</span> <span class="nav-text">SortShuffleManager</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="fhclk"
      src="/images/avatar1.png">
  <p class="site-author-name" itemprop="name">fhclk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fhclk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fhclk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">fhclk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
